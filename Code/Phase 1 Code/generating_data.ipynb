{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8dd7c18-273d-4682-a5e4-b00ae3a643f8",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8f9455-a090-41a6-9aa1-295eb5758db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40d7858-c595-4820-9ddc-2067f68e3642",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7563c36-2558-4444-b546-08e942f1d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Features:\n",
    "\"\"\" Images should be sent in RGB format \"\"\"\n",
    "    \n",
    "def resize(img,size):\n",
    "    \"\"\"size is a tuple\"\"\"\n",
    "    \"\"\" returns resized images\"\"\"\n",
    "    return cv2.resize(img,size)\n",
    "\n",
    "def to_hsv(img):\n",
    "    \"\"\"return image in HSV space\"\"\"\n",
    "    return cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def to_gray(img):\n",
    "    \"\"\"return image in gray space\"\"\"\n",
    "    return cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def sum(arr):\n",
    "    \"\"\"returns sum and no. of pixels between 20 and 240\"\"\"\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for i in arr:\n",
    "        for j in i:\n",
    "            if(j>20 and j<240): #only pixels whose value is between 20 and 240\n",
    "                sum+=j\n",
    "                count+=1\n",
    "\n",
    "    return (sum,count)\n",
    "\n",
    "def pooling(image, pool_size, code, padding):\n",
    "    \"\"\"\n",
    "    different codes for different pooling\n",
    "    code min :min pooling\n",
    "    code max :max pooling \n",
    "    code mean :mean pooling \n",
    "    code std :standard deviation pooling\n",
    "    returns a image with padding operation and pooling operation\n",
    "    \"\"\"\n",
    "\n",
    "    padded = arr = np.zeros((image.shape[0] + padding*2, \n",
    "                       image.shape[1] + padding*2))\n",
    "    \n",
    "    #  inserting image into zero array\n",
    "    padded[int(padding):-int(padding), int(padding):-int(padding)] = image\n",
    "    \n",
    "    \n",
    "    # print(f'original image size: {image.shape}')\n",
    "    # print(f'padded image size: {padded.shape}')\n",
    "\n",
    "    input_height, input_width = padded.shape\n",
    "    pool_height, pool_width = pool_size\n",
    "\n",
    "    # Calculate the output dimensions\n",
    "    output_height = input_height - pool_height + 1\n",
    "    output_width = input_width - pool_width + 1\n",
    "\n",
    "    # Initialize the output data\n",
    "    output_data = np.zeros((output_height, output_width))\n",
    "\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            # Extract the region of interest (ROI)\n",
    "            roi = padded[i : i + pool_height, j : j + pool_width]\n",
    "            \n",
    "            if code=='min':\n",
    "                # Apply min pooling within the ROI\n",
    "                output_data[i, j] = np.min(roi)\n",
    "\n",
    "            if code=='max':\n",
    "                # Apply max pooling within the ROI\n",
    "                output_data[i, j] = np.max(roi)\n",
    "\n",
    "            if code=='mean':\n",
    "                # Apply mean pooling within the ROI\n",
    "                output_data[i, j] = np.mean(roi)\n",
    "\n",
    "            if code=='std':\n",
    "                # Apply min pooling within the ROI\n",
    "                output_data[i, j] = np.std(roi)\n",
    "\n",
    "\n",
    "    # print(f'{code} pooled image size: {output_data.shape}')\n",
    "    return output_data\n",
    "\n",
    "def feature(data):\n",
    "    \"\"\"Return all the 12 features as a numpy array\"\"\"\n",
    "    number,img,label = data\n",
    "    img = resize(img,(250,250))\n",
    "\n",
    "    #RGB SPACE\n",
    "    r, g, b = cv2.split(img)\n",
    "    sum_img = [sum(r),sum(g),sum(b),sum(r-g)]\n",
    "    mean_features = [i[0]/i[1] for i in sum_img]\n",
    "    mean_r,mean_g,mean_b,mean_rg = mean_features\n",
    "    # 4 features done in RGB SPACE\n",
    "\n",
    "    \n",
    "    #HSV SPACE\n",
    "    hsv = to_hsv(img)\n",
    "    h,s,v = cv2.split(hsv)\n",
    "    h = h/h.max()\n",
    "    nH = np.count_nonzero(h>0.95)\n",
    "    HHR = nH/h.size\n",
    "    # HHR found\n",
    "\n",
    "    \n",
    "    #GRAY SPACE\n",
    "    gray = to_gray(img)\n",
    "    B_sum, B_size = sum(gray)\n",
    "    B = B_sum/B_size # FOUND B\n",
    "\n",
    "    #ENTROPY in gray space\n",
    "    eq = cv2.equalizeHist(gray)\n",
    "    unique, counts = np.unique(eq, return_counts=True)\n",
    "    #only pixels whose value is between 20 and 240\n",
    "    total_counts = counts[21:240].sum() \n",
    "    Ent = np.sum(np.array([-i*(i/total_counts)*math.log((i/total_counts),2) for i in counts[21:240]])) #Found Entropy\n",
    "\n",
    "    #Calculating the 'G' features\n",
    "    Ixy = gray\n",
    "    min_Ixy = pooling(image=Ixy, pool_size=(3,3), code='min', padding=1)\n",
    "    max_Ixy = pooling(image=Ixy, pool_size=(3,3), code='max', padding=1)\n",
    "    mean_Ixy = pooling(image=Ixy, pool_size=(3,3), code='mean', padding=1)\n",
    "    std_Ixy = pooling(image=Ixy, pool_size=(3,3), code='std', padding=1)\n",
    "    \n",
    "    g1 = Ixy - min_Ixy\n",
    "    g2 = max_Ixy - Ixy\n",
    "    g3 = Ixy - mean_Ixy\n",
    "    g4 = std_Ixy\n",
    "    g5 = Ixy\n",
    "    \n",
    "    G1 = g1.sum()/g1.size\n",
    "    G2 = g2.sum()/g2.size\n",
    "    G3 = g3.sum()/g3.size\n",
    "    G4 = g4.sum()/g4.size\n",
    "    G5 = g5.sum()/g5.size\n",
    "\n",
    "    feature_all = [number,mean_r,mean_g,mean_b,mean_rg,HHR,Ent,B,G1,G2,G3,G4,G5,label]\n",
    "    return feature_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b157730-b738-4ff3-b60d-0e17c6cbe935",
   "metadata": {},
   "source": [
    "# Accessing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deebd9db-2de2-401c-bf5e-2e317d4d0259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Intelehealth\\Code\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "training_0_list = os.listdir('../India_95/training_data_0.7/non_anemic_0/')\n",
    "training_1_list = os.listdir('../India_95/training_data_0.7/anemic_1/')\n",
    "testing_0_list = os.listdir('../India_95/testing_data_0.3/non_anemic_0/')\n",
    "testing_1_list = os.listdir('../India_95/testing_data_0.3/anemic_1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d78d876-e26e-4854-8167-19d88f608ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "path = []\n",
    "path.append('../India_95/training_data_0.7/non_anemic_0/')\n",
    "path.append('../India_95/training_data_0.7/anemic_1/')\n",
    "path.append('../India_95/testing_data_0.3/non_anemic_0/')\n",
    "path.append( '../India_95/testing_data_0.3/anemic_1/')\n",
    "\n",
    "data = [training_0_list,training_1_list,testing_0_list,testing_1_list]\n",
    "for i in range(4):\n",
    "    curr_data,curr_path = data[i], path[i]\n",
    "    for j in curr_data:\n",
    "        filepath = curr_path + j\n",
    "        img = cv2.imread(filepath)        \n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        label = i%2\n",
    "        data_input = [j.split('.')[0],img,label]\n",
    "        if i==0 or i==1:\n",
    "            training.append(data_input)\n",
    "        else:\n",
    "            testing.append(data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc9bbed-e966-4652-868b-f85e4bbbdc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Data 65\n",
      "Length of Testing Data 30\n"
     ]
    }
   ],
   "source": [
    "print('Length of Training Data',len(training))\n",
    "print('Length of Testing Data',len(testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcce3ab-0421-481e-b7ec-ecf671c46b25",
   "metadata": {},
   "source": [
    "# Generating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbff8ea-f887-4170-9127-a550b24ef2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "404505bd-71f2-4880-a629-6d51f8d291bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "for i in training:\n",
    "    training_list.append(feature(i))\n",
    "\n",
    "print(len(training_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe05199-9268-41b7-8569-f4bf391c0366",
   "metadata": {},
   "source": [
    "# Generating Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d7335f-40b7-43e2-9c44-2759c4cfbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b01b474-f34d-4bb7-a4e0-d88ed03b00a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "for i in testing:\n",
    "    testing_list.append(feature(i))\n",
    "\n",
    "print(len(testing_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c308f9-9c76-4778-ae0a-b0991722f657",
   "metadata": {},
   "source": [
    "# Final CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09fb1ca-66f9-47f0-b583-5230c40ccc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['number','mean_r','mean_g','mean_b','mean_rg','HHR','Ent','B','G1','G2','G3','G4','G5','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d03ff2ab-1882-4d74-b29e-6e81f7e12fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.DataFrame(training_list,columns=cols)\n",
    "df_testing = pd.DataFrame(testing_list,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfac60b-b169-4634-8a3c-bac870481c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_training.to_csv('training.csv',index=False)\n",
    "# df_testing.to_csv('testing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f5aa0-81dc-4491-acd9-5fd3f9ea5401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
