{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Features:\n",
    "\"\"\" Images should be sent in RGB format \"\"\"\n",
    "    \n",
    "def resize(img,size):\n",
    "    \"\"\"size is a tuple\"\"\"\n",
    "    \"\"\" returns resized images\"\"\"\n",
    "    return cv2.resize(img,size)\n",
    "\n",
    "def to_hsv(img):\n",
    "    \"\"\"return image in HSV space\"\"\"\n",
    "    return cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def to_gray(img):\n",
    "    \"\"\"return image in gray space\"\"\"\n",
    "    return cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def sum(arr):\n",
    "    \"\"\"returns sum and no. of pixels between 20 and 240\"\"\"\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for i in arr:\n",
    "        for j in i:\n",
    "            if(j>20 and j<240): #only pixels whose value is between 20 and 240\n",
    "                sum+=j\n",
    "                count+=1\n",
    "\n",
    "    return (sum,count)\n",
    "\n",
    "def pooling(image, pool_size, code, padding):\n",
    "    \"\"\"\n",
    "    different codes for different pooling\n",
    "    code min :min pooling\n",
    "    code max :max pooling \n",
    "    code mean :mean pooling \n",
    "    code std :standard deviation pooling\n",
    "    returns a image with padding operation and pooling operation\n",
    "    \"\"\"\n",
    "\n",
    "    padded = arr = np.zeros((image.shape[0] + padding*2, \n",
    "                       image.shape[1] + padding*2))\n",
    "    \n",
    "    #  inserting image into zero array\n",
    "    padded[int(padding):-int(padding), int(padding):-int(padding)] = image\n",
    "    \n",
    "    \n",
    "    # print(f'original image size: {image.shape}')\n",
    "    # print(f'padded image size: {padded.shape}')\n",
    "\n",
    "    input_height, input_width = padded.shape\n",
    "    pool_height, pool_width = pool_size\n",
    "\n",
    "    # Calculate the output dimensions\n",
    "    output_height = input_height - pool_height + 1\n",
    "    output_width = input_width - pool_width + 1\n",
    "\n",
    "    # Initialize the output data\n",
    "    output_data = np.zeros((output_height, output_width))\n",
    "\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            # Extract the region of interest (ROI)\n",
    "            roi = padded[i : i + pool_height, j : j + pool_width]\n",
    "            \n",
    "            if code=='min':\n",
    "                # Apply min pooling within the ROI\n",
    "                output_data[i, j] = np.min(roi)\n",
    "\n",
    "            if code=='max':\n",
    "                # Apply max pooling within the ROI\n",
    "                output_data[i, j] = np.max(roi)\n",
    "\n",
    "            if code=='mean':\n",
    "                # Apply mean pooling within the ROI\n",
    "                output_data[i, j] = np.mean(roi)\n",
    "\n",
    "            if code=='std':\n",
    "                # Apply min pooling within the ROI\n",
    "                output_data[i, j] = np.std(roi)\n",
    "\n",
    "\n",
    "    # print(f'{code} pooled image size: {output_data.shape}')\n",
    "    return output_data\n",
    "\n",
    "def feature(data):\n",
    "    \"\"\"Return all the 12 features as a numpy array\"\"\"\n",
    "    number,img,label = data\n",
    "    img = resize(img,(250,250))\n",
    "\n",
    "    #RGB SPACE\n",
    "    r, g, b = cv2.split(img)\n",
    "    sum_img = [sum(r),sum(g),sum(b),sum(r-g)]\n",
    "    mean_features = [i[0]/i[1] for i in sum_img]\n",
    "    mean_r,mean_g,mean_b,mean_rg = mean_features\n",
    "    # 4 features done in RGB SPACE\n",
    "\n",
    "    \n",
    "    #HSV SPACE\n",
    "    hsv = to_hsv(img)\n",
    "    h,s,v = cv2.split(hsv)\n",
    "    h = h/h.max()\n",
    "    nH = np.count_nonzero(h>0.95)\n",
    "    HHR = nH/h.size\n",
    "    # HHR found\n",
    "\n",
    "    \n",
    "    #GRAY SPACE\n",
    "    gray = to_gray(img)\n",
    "    B_sum, B_size = sum(gray)\n",
    "    B = B_sum/B_size # FOUND B\n",
    "\n",
    "    #ENTROPY in gray space\n",
    "    eq = cv2.equalizeHist(gray)\n",
    "    unique, counts = np.unique(eq, return_counts=True)\n",
    "    #only pixels whose value is between 20 and 240\n",
    "    total_counts = counts[21:240].sum() \n",
    "    Ent = np.sum(np.array([-i*(i/total_counts)*math.log((i/total_counts),2) for i in counts[21:240]])) #Found Entropy\n",
    "\n",
    "    #Calculating the 'G' features\n",
    "    Ixy = gray\n",
    "    min_Ixy = pooling(image=Ixy, pool_size=(3,3), code='min', padding=1)\n",
    "    max_Ixy = pooling(image=Ixy, pool_size=(3,3), code='max', padding=1)\n",
    "    mean_Ixy = pooling(image=Ixy, pool_size=(3,3), code='mean', padding=1)\n",
    "    std_Ixy = pooling(image=Ixy, pool_size=(3,3), code='std', padding=1)\n",
    "    \n",
    "    g1 = Ixy - min_Ixy\n",
    "    g2 = max_Ixy - Ixy\n",
    "    g3 = Ixy - mean_Ixy\n",
    "    g4 = std_Ixy\n",
    "    g5 = Ixy\n",
    "    \n",
    "    G1 = g1.sum()/g1.size\n",
    "    G2 = g2.sum()/g2.size\n",
    "    G3 = g3.sum()/g3.size\n",
    "    G4 = g4.sum()/g4.size\n",
    "    G5 = g5.sum()/g5.size\n",
    "\n",
    "    feature_all = [number,mean_r,mean_g,mean_b,mean_rg,HHR,Ent,B,G1,G2,G3,G4,G5,label]\n",
    "    return feature_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Images = 95\n"
     ]
    }
   ],
   "source": [
    "folders = sorted(glob.glob(\"../India_95/complete/*\"))\n",
    "images = []\n",
    "for folder in folders:\n",
    "    all_images = []\n",
    "    for i in os.listdir(folder):\n",
    "        path = os.path.join(folder,i)\n",
    "        all_images.append(path)\n",
    "    images.append([i for i in all_images if \"forniceal_palpebral\" in i][0])\n",
    "print(f\"Total Number of Images = {len(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(filename):\n",
    "    input_image = Image.open(filename)\n",
    "    input_image.load()\n",
    "    image = Image.new(\"RGB\", input_image.size, (255, 255, 255))\n",
    "    image.paste(input_image, mask = input_image.split()[3])\n",
    "    return np.array(image)\n",
    "\n",
    "def canny_edge_detection(frame): \n",
    "    # Convert the frame to grayscale for edge detection \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) \n",
    "        \n",
    "    # Apply Gaussian blur to reduce noise and smoothen edges \n",
    "    # blurred = cv2.GaussianBlur(src=gray, ksize=(3, 5), sigmaX=0.5)  #CHANGE gray ---> blurred\n",
    "\n",
    "    # Perform Canny edge detection \n",
    "    edges = cv2.Canny(gray, 70, 135)\n",
    "      \n",
    "    return edges\n",
    "\n",
    "def get_contours(image,edges):\n",
    "\n",
    "    # # define a (3, 3) structuring element\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # # apply the dilation operation to the edged image\n",
    "    # dilate = cv2.dilate(edges, kernel, iterations=1) #CHANGE edge --> dilate\n",
    "\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_contours=sorted(contours, key=cv2.contourArea, reverse= True)\n",
    "    \n",
    "    image_copy = image.copy()\n",
    "    \n",
    "    # draw the contours on a copy of the original image\n",
    "    cv2.drawContours(image_copy, sorted_contours, -1, (0, 255, 0), 2) \n",
    "    # print(len(contours), \"object was found in this image.\")\n",
    "\n",
    "    return image_copy,contours\n",
    "\n",
    "def crop(image,contours):\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    # cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 1)\n",
    "\n",
    "    img_copy = image.copy()\n",
    "    cropped_img=img_copy[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../India_95/India.xlsx\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img_folder = []\n",
    "for i in range(len(images)):\n",
    "\n",
    "    img = mask(images[i])\n",
    "    edges = canny_edge_detection(img)\n",
    "    img_copy,contours = get_contours(img,edges)\n",
    "    cropped_img = crop(img,contours)\n",
    "\n",
    "    number = int(images[i].split(\"/\")[-2]) \n",
    "    \n",
    "    label = df.loc[df['Number'] == int(number)]['Hgb'].tolist()[0]\n",
    "    \n",
    "    data = [number,cropped_img,label]\n",
    "    \n",
    "    cropped_img_folder.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "All_Data = []\n",
    "\n",
    "for i in cropped_img_folder:\n",
    "    All_Data.append(feature(i))\n",
    "\n",
    "print(len(All_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['number','mean_r','mean_g','mean_b','mean_rg','HHR','Ent','B','G1','G2','G3','G4','G5','label']\n",
    "\n",
    "complete_data = pd.DataFrame(All_Data,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>mean_r</th>\n",
       "      <th>mean_g</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>mean_rg</th>\n",
       "      <th>HHR</th>\n",
       "      <th>Ent</th>\n",
       "      <th>B</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>G4</th>\n",
       "      <th>G5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>166.115510</td>\n",
       "      <td>84.085488</td>\n",
       "      <td>118.026636</td>\n",
       "      <td>82.950664</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>16530.859714</td>\n",
       "      <td>112.137698</td>\n",
       "      <td>8.106592</td>\n",
       "      <td>4.140496</td>\n",
       "      <td>1.349161</td>\n",
       "      <td>4.895221</td>\n",
       "      <td>191.313664</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>160.143607</td>\n",
       "      <td>88.695460</td>\n",
       "      <td>120.634118</td>\n",
       "      <td>72.781835</td>\n",
       "      <td>0.235520</td>\n",
       "      <td>15663.471752</td>\n",
       "      <td>113.683637</td>\n",
       "      <td>8.385424</td>\n",
       "      <td>4.904768</td>\n",
       "      <td>1.255196</td>\n",
       "      <td>5.044717</td>\n",
       "      <td>178.182672</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>167.294504</td>\n",
       "      <td>106.190649</td>\n",
       "      <td>144.654703</td>\n",
       "      <td>61.616165</td>\n",
       "      <td>0.080352</td>\n",
       "      <td>16258.330210</td>\n",
       "      <td>128.833414</td>\n",
       "      <td>8.423712</td>\n",
       "      <td>4.667440</td>\n",
       "      <td>1.271712</td>\n",
       "      <td>4.985541</td>\n",
       "      <td>192.234128</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>175.469784</td>\n",
       "      <td>124.728785</td>\n",
       "      <td>156.774717</td>\n",
       "      <td>51.857562</td>\n",
       "      <td>0.096384</td>\n",
       "      <td>16015.872101</td>\n",
       "      <td>143.585054</td>\n",
       "      <td>7.037088</td>\n",
       "      <td>3.561568</td>\n",
       "      <td>1.227013</td>\n",
       "      <td>4.158212</td>\n",
       "      <td>210.090256</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>174.038383</td>\n",
       "      <td>113.084957</td>\n",
       "      <td>149.969145</td>\n",
       "      <td>61.577065</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>16105.892531</td>\n",
       "      <td>135.513296</td>\n",
       "      <td>7.608624</td>\n",
       "      <td>3.746800</td>\n",
       "      <td>1.337888</td>\n",
       "      <td>4.442796</td>\n",
       "      <td>189.553616</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number      mean_r      mean_g      mean_b    mean_rg       HHR  \\\n",
       "0       1  166.115510   84.085488  118.026636  82.950664  0.200800   \n",
       "1      10  160.143607   88.695460  120.634118  72.781835  0.235520   \n",
       "2      11  167.294504  106.190649  144.654703  61.616165  0.080352   \n",
       "3      12  175.469784  124.728785  156.774717  51.857562  0.096384   \n",
       "4      13  174.038383  113.084957  149.969145  61.577065  0.077600   \n",
       "\n",
       "            Ent           B        G1        G2        G3        G4  \\\n",
       "0  16530.859714  112.137698  8.106592  4.140496  1.349161  4.895221   \n",
       "1  15663.471752  113.683637  8.385424  4.904768  1.255196  5.044717   \n",
       "2  16258.330210  128.833414  8.423712  4.667440  1.271712  4.985541   \n",
       "3  16015.872101  143.585054  7.037088  3.561568  1.227013  4.158212   \n",
       "4  16105.892531  135.513296  7.608624  3.746800  1.337888  4.442796   \n",
       "\n",
       "           G5  label  \n",
       "0  191.313664   12.2  \n",
       "1  178.182672   11.3  \n",
       "2  192.234128   13.2  \n",
       "3  210.090256   10.6  \n",
       "4  189.553616   10.6  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(complete_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable in train data\n",
    "X_train = train_data.drop(columns=['number','label'])\n",
    "y_train = train_data['label']\n",
    "\n",
    "# Separate features and target variable in test data\n",
    "X_test = test_data.drop(columns=['number','label'])\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVM Regression': SVR(kernel='poly'),  # Adjust kernel as needed\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'Gradient Boost': GradientBoostingRegressor(),\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'LGBM': LGBMRegressor(),\n",
    "    'CatBoost': CatBoostRegressor(),\n",
    "    'Kernel Ridge Regressor': KernelRidge(),\n",
    "    'Elastic Net': ElasticNet(),\n",
    "    'Bayesian Ridge': BayesianRidge(),\n",
    "    'XG Boost': XGBRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric tables\n",
    "metric_table_train = pd.DataFrame()\n",
    "metric_table_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 276\n",
      "[LightGBM] [Info] Number of data points in the train set: 66, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 11.193939\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Learning rate set to 0.026648\n",
      "0:\tlearn: 2.0269278\ttotal: 49.4ms\tremaining: 49.4s\n",
      "1:\tlearn: 2.0134547\ttotal: 50.8ms\tremaining: 25.3s\n",
      "2:\tlearn: 1.9986412\ttotal: 51.9ms\tremaining: 17.3s\n",
      "3:\tlearn: 1.9831412\ttotal: 52.8ms\tremaining: 13.2s\n",
      "4:\tlearn: 1.9668940\ttotal: 53.7ms\tremaining: 10.7s\n",
      "5:\tlearn: 1.9473545\ttotal: 54.5ms\tremaining: 9.03s\n",
      "6:\tlearn: 1.9273212\ttotal: 57.9ms\tremaining: 8.21s\n",
      "7:\tlearn: 1.9115185\ttotal: 58.7ms\tremaining: 7.28s\n",
      "8:\tlearn: 1.8939510\ttotal: 59.5ms\tremaining: 6.55s\n",
      "9:\tlearn: 1.8790364\ttotal: 60.2ms\tremaining: 5.96s\n",
      "10:\tlearn: 1.8623984\ttotal: 61ms\tremaining: 5.48s\n",
      "11:\tlearn: 1.8475207\ttotal: 61.8ms\tremaining: 5.08s\n",
      "12:\tlearn: 1.8318914\ttotal: 62.5ms\tremaining: 4.75s\n",
      "13:\tlearn: 1.8206645\ttotal: 63.3ms\tremaining: 4.45s\n",
      "14:\tlearn: 1.8076966\ttotal: 64ms\tremaining: 4.2s\n",
      "15:\tlearn: 1.7922410\ttotal: 64.8ms\tremaining: 3.98s\n",
      "16:\tlearn: 1.7781180\ttotal: 65.5ms\tremaining: 3.79s\n",
      "17:\tlearn: 1.7652841\ttotal: 66.3ms\tremaining: 3.62s\n",
      "18:\tlearn: 1.7495539\ttotal: 67ms\tremaining: 3.46s\n",
      "19:\tlearn: 1.7392911\ttotal: 67.8ms\tremaining: 3.32s\n",
      "20:\tlearn: 1.7284417\ttotal: 68.5ms\tremaining: 3.19s\n",
      "21:\tlearn: 1.7155098\ttotal: 69.3ms\tremaining: 3.08s\n",
      "22:\tlearn: 1.7024617\ttotal: 70.1ms\tremaining: 2.98s\n",
      "23:\tlearn: 1.6913674\ttotal: 70.8ms\tremaining: 2.88s\n",
      "24:\tlearn: 1.6778188\ttotal: 71.5ms\tremaining: 2.79s\n",
      "25:\tlearn: 1.6649272\ttotal: 72.2ms\tremaining: 2.71s\n",
      "26:\tlearn: 1.6538507\ttotal: 73ms\tremaining: 2.63s\n",
      "27:\tlearn: 1.6409828\ttotal: 73.7ms\tremaining: 2.56s\n",
      "28:\tlearn: 1.6306193\ttotal: 74.5ms\tremaining: 2.49s\n",
      "29:\tlearn: 1.6210608\ttotal: 75.3ms\tremaining: 2.43s\n",
      "30:\tlearn: 1.6168966\ttotal: 75.6ms\tremaining: 2.36s\n",
      "31:\tlearn: 1.6054769\ttotal: 76.3ms\tremaining: 2.31s\n",
      "32:\tlearn: 1.5949107\ttotal: 77.1ms\tremaining: 2.26s\n",
      "33:\tlearn: 1.5850369\ttotal: 77.8ms\tremaining: 2.21s\n",
      "34:\tlearn: 1.5727763\ttotal: 78.5ms\tremaining: 2.17s\n",
      "35:\tlearn: 1.5624435\ttotal: 79.3ms\tremaining: 2.12s\n",
      "36:\tlearn: 1.5509168\ttotal: 80ms\tremaining: 2.08s\n",
      "37:\tlearn: 1.5377791\ttotal: 80.8ms\tremaining: 2.04s\n",
      "38:\tlearn: 1.5260846\ttotal: 81.5ms\tremaining: 2.01s\n",
      "39:\tlearn: 1.5123742\ttotal: 82.3ms\tremaining: 1.97s\n",
      "40:\tlearn: 1.5027570\ttotal: 83ms\tremaining: 1.94s\n",
      "41:\tlearn: 1.4916977\ttotal: 83.8ms\tremaining: 1.91s\n",
      "42:\tlearn: 1.4837072\ttotal: 84.5ms\tremaining: 1.88s\n",
      "43:\tlearn: 1.4716043\ttotal: 85.3ms\tremaining: 1.85s\n",
      "44:\tlearn: 1.4645784\ttotal: 86ms\tremaining: 1.82s\n",
      "45:\tlearn: 1.4583698\ttotal: 86.8ms\tremaining: 1.8s\n",
      "46:\tlearn: 1.4518075\ttotal: 87.5ms\tremaining: 1.77s\n",
      "47:\tlearn: 1.4422768\ttotal: 88.3ms\tremaining: 1.75s\n",
      "48:\tlearn: 1.4354401\ttotal: 89ms\tremaining: 1.73s\n",
      "49:\tlearn: 1.4261605\ttotal: 89.7ms\tremaining: 1.7s\n",
      "50:\tlearn: 1.4160388\ttotal: 90.4ms\tremaining: 1.68s\n",
      "51:\tlearn: 1.4093943\ttotal: 92.4ms\tremaining: 1.68s\n",
      "52:\tlearn: 1.4031823\ttotal: 92.8ms\tremaining: 1.66s\n",
      "53:\tlearn: 1.3940914\ttotal: 93.3ms\tremaining: 1.64s\n",
      "54:\tlearn: 1.3852021\ttotal: 94.1ms\tremaining: 1.62s\n",
      "55:\tlearn: 1.3765513\ttotal: 94.9ms\tremaining: 1.6s\n",
      "56:\tlearn: 1.3687224\ttotal: 95.7ms\tremaining: 1.58s\n",
      "57:\tlearn: 1.3599729\ttotal: 96.5ms\tremaining: 1.57s\n",
      "58:\tlearn: 1.3540269\ttotal: 97.3ms\tremaining: 1.55s\n",
      "59:\tlearn: 1.3463908\ttotal: 98.1ms\tremaining: 1.54s\n",
      "60:\tlearn: 1.3401248\ttotal: 99ms\tremaining: 1.52s\n",
      "61:\tlearn: 1.3303070\ttotal: 99.8ms\tremaining: 1.51s\n",
      "62:\tlearn: 1.3238946\ttotal: 101ms\tremaining: 1.5s\n",
      "63:\tlearn: 1.3151606\ttotal: 101ms\tremaining: 1.48s\n",
      "64:\tlearn: 1.3086829\ttotal: 102ms\tremaining: 1.47s\n",
      "65:\tlearn: 1.2991183\ttotal: 103ms\tremaining: 1.46s\n",
      "66:\tlearn: 1.2872997\ttotal: 104ms\tremaining: 1.45s\n",
      "67:\tlearn: 1.2811646\ttotal: 105ms\tremaining: 1.44s\n",
      "68:\tlearn: 1.2729081\ttotal: 106ms\tremaining: 1.42s\n",
      "69:\tlearn: 1.2642048\ttotal: 106ms\tremaining: 1.41s\n",
      "70:\tlearn: 1.2588025\ttotal: 107ms\tremaining: 1.4s\n",
      "71:\tlearn: 1.2520256\ttotal: 108ms\tremaining: 1.39s\n",
      "72:\tlearn: 1.2445678\ttotal: 109ms\tremaining: 1.38s\n",
      "73:\tlearn: 1.2374099\ttotal: 109ms\tremaining: 1.37s\n",
      "74:\tlearn: 1.2306206\ttotal: 110ms\tremaining: 1.36s\n",
      "75:\tlearn: 1.2228364\ttotal: 111ms\tremaining: 1.35s\n",
      "76:\tlearn: 1.2153362\ttotal: 111ms\tremaining: 1.34s\n",
      "77:\tlearn: 1.2089383\ttotal: 114ms\tremaining: 1.34s\n",
      "78:\tlearn: 1.2026721\ttotal: 114ms\tremaining: 1.33s\n",
      "79:\tlearn: 1.1952195\ttotal: 114ms\tremaining: 1.31s\n",
      "80:\tlearn: 1.1880893\ttotal: 115ms\tremaining: 1.3s\n",
      "81:\tlearn: 1.1821183\ttotal: 115ms\tremaining: 1.29s\n",
      "82:\tlearn: 1.1767291\ttotal: 116ms\tremaining: 1.28s\n",
      "83:\tlearn: 1.1738611\ttotal: 117ms\tremaining: 1.27s\n",
      "84:\tlearn: 1.1670993\ttotal: 117ms\tremaining: 1.26s\n",
      "85:\tlearn: 1.1613510\ttotal: 118ms\tremaining: 1.25s\n",
      "86:\tlearn: 1.1525990\ttotal: 118ms\tremaining: 1.24s\n",
      "87:\tlearn: 1.1490563\ttotal: 119ms\tremaining: 1.23s\n",
      "88:\tlearn: 1.1442124\ttotal: 119ms\tremaining: 1.22s\n",
      "89:\tlearn: 1.1359055\ttotal: 120ms\tremaining: 1.21s\n",
      "90:\tlearn: 1.1314944\ttotal: 120ms\tremaining: 1.2s\n",
      "91:\tlearn: 1.1256403\ttotal: 121ms\tremaining: 1.19s\n",
      "92:\tlearn: 1.1214612\ttotal: 121ms\tremaining: 1.18s\n",
      "93:\tlearn: 1.1176376\ttotal: 122ms\tremaining: 1.18s\n",
      "94:\tlearn: 1.1109797\ttotal: 122ms\tremaining: 1.17s\n",
      "95:\tlearn: 1.1069694\ttotal: 123ms\tremaining: 1.16s\n",
      "96:\tlearn: 1.0997455\ttotal: 123ms\tremaining: 1.15s\n",
      "97:\tlearn: 1.0953840\ttotal: 124ms\tremaining: 1.14s\n",
      "98:\tlearn: 1.0910634\ttotal: 124ms\tremaining: 1.13s\n",
      "99:\tlearn: 1.0861108\ttotal: 125ms\tremaining: 1.12s\n",
      "100:\tlearn: 1.0796946\ttotal: 125ms\tremaining: 1.11s\n",
      "101:\tlearn: 1.0728109\ttotal: 126ms\tremaining: 1.1s\n",
      "102:\tlearn: 1.0684786\ttotal: 126ms\tremaining: 1.1s\n",
      "103:\tlearn: 1.0637023\ttotal: 127ms\tremaining: 1.09s\n",
      "104:\tlearn: 1.0595869\ttotal: 127ms\tremaining: 1.08s\n",
      "105:\tlearn: 1.0530567\ttotal: 127ms\tremaining: 1.07s\n",
      "106:\tlearn: 1.0460846\ttotal: 128ms\tremaining: 1.07s\n",
      "107:\tlearn: 1.0405633\ttotal: 128ms\tremaining: 1.06s\n",
      "108:\tlearn: 1.0352904\ttotal: 129ms\tremaining: 1.05s\n",
      "109:\tlearn: 1.0297573\ttotal: 129ms\tremaining: 1.05s\n",
      "110:\tlearn: 1.0240938\ttotal: 130ms\tremaining: 1.04s\n",
      "111:\tlearn: 1.0170653\ttotal: 130ms\tremaining: 1.03s\n",
      "112:\tlearn: 1.0100219\ttotal: 131ms\tremaining: 1.03s\n",
      "113:\tlearn: 1.0047178\ttotal: 131ms\tremaining: 1.02s\n",
      "114:\tlearn: 0.9998849\ttotal: 132ms\tremaining: 1.01s\n",
      "115:\tlearn: 0.9963338\ttotal: 132ms\tremaining: 1.01s\n",
      "116:\tlearn: 0.9918139\ttotal: 132ms\tremaining: 1000ms\n",
      "117:\tlearn: 0.9885679\ttotal: 133ms\tremaining: 993ms\n",
      "118:\tlearn: 0.9840467\ttotal: 133ms\tremaining: 986ms\n",
      "119:\tlearn: 0.9796577\ttotal: 134ms\tremaining: 979ms\n",
      "120:\tlearn: 0.9747973\ttotal: 134ms\tremaining: 973ms\n",
      "121:\tlearn: 0.9709056\ttotal: 134ms\tremaining: 966ms\n",
      "122:\tlearn: 0.9669044\ttotal: 135ms\tremaining: 960ms\n",
      "123:\tlearn: 0.9610102\ttotal: 135ms\tremaining: 953ms\n",
      "124:\tlearn: 0.9580487\ttotal: 135ms\tremaining: 947ms\n",
      "125:\tlearn: 0.9526035\ttotal: 136ms\tremaining: 941ms\n",
      "126:\tlearn: 0.9482740\ttotal: 136ms\tremaining: 936ms\n",
      "127:\tlearn: 0.9434650\ttotal: 136ms\tremaining: 929ms\n",
      "128:\tlearn: 0.9375587\ttotal: 137ms\tremaining: 922ms\n",
      "129:\tlearn: 0.9338512\ttotal: 137ms\tremaining: 916ms\n",
      "130:\tlearn: 0.9290436\ttotal: 137ms\tremaining: 910ms\n",
      "131:\tlearn: 0.9258268\ttotal: 138ms\tremaining: 904ms\n",
      "132:\tlearn: 0.9223209\ttotal: 138ms\tremaining: 899ms\n",
      "133:\tlearn: 0.9186649\ttotal: 138ms\tremaining: 893ms\n",
      "134:\tlearn: 0.9147014\ttotal: 139ms\tremaining: 888ms\n",
      "135:\tlearn: 0.9105674\ttotal: 139ms\tremaining: 882ms\n",
      "136:\tlearn: 0.9077266\ttotal: 139ms\tremaining: 877ms\n",
      "137:\tlearn: 0.9032127\ttotal: 139ms\tremaining: 871ms\n",
      "138:\tlearn: 0.8979225\ttotal: 140ms\tremaining: 866ms\n",
      "139:\tlearn: 0.8948425\ttotal: 140ms\tremaining: 860ms\n",
      "140:\tlearn: 0.8890775\ttotal: 140ms\tremaining: 855ms\n",
      "141:\tlearn: 0.8858136\ttotal: 141ms\tremaining: 849ms\n",
      "142:\tlearn: 0.8813201\ttotal: 141ms\tremaining: 844ms\n",
      "143:\tlearn: 0.8781559\ttotal: 141ms\tremaining: 839ms\n",
      "144:\tlearn: 0.8727367\ttotal: 141ms\tremaining: 834ms\n",
      "145:\tlearn: 0.8690104\ttotal: 142ms\tremaining: 829ms\n",
      "146:\tlearn: 0.8668380\ttotal: 142ms\tremaining: 824ms\n",
      "147:\tlearn: 0.8639967\ttotal: 142ms\tremaining: 819ms\n",
      "148:\tlearn: 0.8601217\ttotal: 142ms\tremaining: 814ms\n",
      "149:\tlearn: 0.8567974\ttotal: 143ms\tremaining: 809ms\n",
      "150:\tlearn: 0.8526698\ttotal: 143ms\tremaining: 804ms\n",
      "151:\tlearn: 0.8473595\ttotal: 143ms\tremaining: 799ms\n",
      "152:\tlearn: 0.8455813\ttotal: 144ms\tremaining: 795ms\n",
      "153:\tlearn: 0.8434043\ttotal: 144ms\tremaining: 790ms\n",
      "154:\tlearn: 0.8394154\ttotal: 144ms\tremaining: 785ms\n",
      "155:\tlearn: 0.8346202\ttotal: 144ms\tremaining: 781ms\n",
      "156:\tlearn: 0.8303711\ttotal: 145ms\tremaining: 776ms\n",
      "157:\tlearn: 0.8262988\ttotal: 145ms\tremaining: 772ms\n",
      "158:\tlearn: 0.8215581\ttotal: 145ms\tremaining: 767ms\n",
      "159:\tlearn: 0.8169371\ttotal: 145ms\tremaining: 763ms\n",
      "160:\tlearn: 0.8147324\ttotal: 146ms\tremaining: 759ms\n",
      "161:\tlearn: 0.8095417\ttotal: 146ms\tremaining: 754ms\n",
      "162:\tlearn: 0.8063379\ttotal: 146ms\tremaining: 750ms\n",
      "163:\tlearn: 0.8019346\ttotal: 146ms\tremaining: 746ms\n",
      "164:\tlearn: 0.7973020\ttotal: 146ms\tremaining: 741ms\n",
      "165:\tlearn: 0.7919529\ttotal: 147ms\tremaining: 737ms\n",
      "166:\tlearn: 0.7870309\ttotal: 147ms\tremaining: 733ms\n",
      "167:\tlearn: 0.7852281\ttotal: 147ms\tremaining: 729ms\n",
      "168:\tlearn: 0.7809840\ttotal: 147ms\tremaining: 725ms\n",
      "169:\tlearn: 0.7787485\ttotal: 148ms\tremaining: 721ms\n",
      "170:\tlearn: 0.7755486\ttotal: 148ms\tremaining: 717ms\n",
      "171:\tlearn: 0.7710864\ttotal: 148ms\tremaining: 713ms\n",
      "172:\tlearn: 0.7663781\ttotal: 148ms\tremaining: 709ms\n",
      "173:\tlearn: 0.7624209\ttotal: 149ms\tremaining: 705ms\n",
      "174:\tlearn: 0.7588894\ttotal: 149ms\tremaining: 701ms\n",
      "175:\tlearn: 0.7566609\ttotal: 149ms\tremaining: 697ms\n",
      "176:\tlearn: 0.7525278\ttotal: 149ms\tremaining: 694ms\n",
      "177:\tlearn: 0.7483625\ttotal: 149ms\tremaining: 690ms\n",
      "178:\tlearn: 0.7453439\ttotal: 150ms\tremaining: 686ms\n",
      "179:\tlearn: 0.7409403\ttotal: 150ms\tremaining: 682ms\n",
      "180:\tlearn: 0.7372214\ttotal: 150ms\tremaining: 679ms\n",
      "181:\tlearn: 0.7334436\ttotal: 150ms\tremaining: 675ms\n",
      "182:\tlearn: 0.7311305\ttotal: 150ms\tremaining: 671ms\n",
      "183:\tlearn: 0.7272213\ttotal: 151ms\tremaining: 668ms\n",
      "184:\tlearn: 0.7237454\ttotal: 151ms\tremaining: 664ms\n",
      "185:\tlearn: 0.7196858\ttotal: 151ms\tremaining: 661ms\n",
      "186:\tlearn: 0.7161511\ttotal: 151ms\tremaining: 657ms\n",
      "187:\tlearn: 0.7113911\ttotal: 151ms\tremaining: 654ms\n",
      "188:\tlearn: 0.7085931\ttotal: 152ms\tremaining: 650ms\n",
      "189:\tlearn: 0.7052084\ttotal: 152ms\tremaining: 647ms\n",
      "190:\tlearn: 0.7017179\ttotal: 152ms\tremaining: 644ms\n",
      "191:\tlearn: 0.6999060\ttotal: 152ms\tremaining: 640ms\n",
      "192:\tlearn: 0.6954321\ttotal: 152ms\tremaining: 637ms\n",
      "193:\tlearn: 0.6921901\ttotal: 153ms\tremaining: 634ms\n",
      "194:\tlearn: 0.6900053\ttotal: 153ms\tremaining: 630ms\n",
      "195:\tlearn: 0.6879659\ttotal: 153ms\tremaining: 627ms\n",
      "196:\tlearn: 0.6851556\ttotal: 153ms\tremaining: 624ms\n",
      "197:\tlearn: 0.6826635\ttotal: 153ms\tremaining: 620ms\n",
      "198:\tlearn: 0.6797917\ttotal: 153ms\tremaining: 617ms\n",
      "199:\tlearn: 0.6765971\ttotal: 154ms\tremaining: 614ms\n",
      "200:\tlearn: 0.6721930\ttotal: 154ms\tremaining: 611ms\n",
      "201:\tlearn: 0.6678295\ttotal: 154ms\tremaining: 608ms\n",
      "202:\tlearn: 0.6634912\ttotal: 154ms\tremaining: 605ms\n",
      "203:\tlearn: 0.6617899\ttotal: 154ms\tremaining: 602ms\n",
      "204:\tlearn: 0.6593278\ttotal: 154ms\tremaining: 599ms\n",
      "205:\tlearn: 0.6567797\ttotal: 155ms\tremaining: 596ms\n",
      "206:\tlearn: 0.6518637\ttotal: 155ms\tremaining: 593ms\n",
      "207:\tlearn: 0.6499176\ttotal: 155ms\tremaining: 590ms\n",
      "208:\tlearn: 0.6477075\ttotal: 155ms\tremaining: 587ms\n",
      "209:\tlearn: 0.6429149\ttotal: 155ms\tremaining: 584ms\n",
      "210:\tlearn: 0.6389564\ttotal: 155ms\tremaining: 581ms\n",
      "211:\tlearn: 0.6358946\ttotal: 156ms\tremaining: 578ms\n",
      "212:\tlearn: 0.6341108\ttotal: 156ms\tremaining: 575ms\n",
      "213:\tlearn: 0.6325478\ttotal: 156ms\tremaining: 572ms\n",
      "214:\tlearn: 0.6302337\ttotal: 156ms\tremaining: 570ms\n",
      "215:\tlearn: 0.6277410\ttotal: 156ms\tremaining: 567ms\n",
      "216:\tlearn: 0.6251320\ttotal: 156ms\tremaining: 564ms\n",
      "217:\tlearn: 0.6206973\ttotal: 157ms\tremaining: 561ms\n",
      "218:\tlearn: 0.6170246\ttotal: 157ms\tremaining: 559ms\n",
      "219:\tlearn: 0.6142872\ttotal: 157ms\tremaining: 556ms\n",
      "220:\tlearn: 0.6119632\ttotal: 157ms\tremaining: 553ms\n",
      "221:\tlearn: 0.6083296\ttotal: 157ms\tremaining: 551ms\n",
      "222:\tlearn: 0.6037783\ttotal: 157ms\tremaining: 548ms\n",
      "223:\tlearn: 0.6002232\ttotal: 157ms\tremaining: 545ms\n",
      "224:\tlearn: 0.5973071\ttotal: 158ms\tremaining: 543ms\n",
      "225:\tlearn: 0.5930161\ttotal: 158ms\tremaining: 540ms\n",
      "226:\tlearn: 0.5903225\ttotal: 158ms\tremaining: 538ms\n",
      "227:\tlearn: 0.5868859\ttotal: 158ms\tremaining: 535ms\n",
      "228:\tlearn: 0.5847478\ttotal: 158ms\tremaining: 533ms\n",
      "229:\tlearn: 0.5802329\ttotal: 158ms\tremaining: 530ms\n",
      "230:\tlearn: 0.5764310\ttotal: 158ms\tremaining: 528ms\n",
      "231:\tlearn: 0.5731928\ttotal: 159ms\tremaining: 525ms\n",
      "232:\tlearn: 0.5697399\ttotal: 159ms\tremaining: 523ms\n",
      "233:\tlearn: 0.5668366\ttotal: 159ms\tremaining: 520ms\n",
      "234:\tlearn: 0.5628795\ttotal: 159ms\tremaining: 518ms\n",
      "235:\tlearn: 0.5594352\ttotal: 159ms\tremaining: 515ms\n",
      "236:\tlearn: 0.5569543\ttotal: 159ms\tremaining: 513ms\n",
      "237:\tlearn: 0.5528507\ttotal: 159ms\tremaining: 511ms\n",
      "238:\tlearn: 0.5492753\ttotal: 160ms\tremaining: 508ms\n",
      "239:\tlearn: 0.5456823\ttotal: 160ms\tremaining: 506ms\n",
      "240:\tlearn: 0.5435748\ttotal: 160ms\tremaining: 504ms\n",
      "241:\tlearn: 0.5409136\ttotal: 160ms\tremaining: 501ms\n",
      "242:\tlearn: 0.5376082\ttotal: 160ms\tremaining: 499ms\n",
      "243:\tlearn: 0.5360727\ttotal: 160ms\tremaining: 497ms\n",
      "244:\tlearn: 0.5320424\ttotal: 160ms\tremaining: 495ms\n",
      "245:\tlearn: 0.5299255\ttotal: 161ms\tremaining: 492ms\n",
      "246:\tlearn: 0.5265128\ttotal: 161ms\tremaining: 490ms\n",
      "247:\tlearn: 0.5234349\ttotal: 161ms\tremaining: 488ms\n",
      "248:\tlearn: 0.5201185\ttotal: 161ms\tremaining: 486ms\n",
      "249:\tlearn: 0.5165974\ttotal: 161ms\tremaining: 484ms\n",
      "250:\tlearn: 0.5141031\ttotal: 161ms\tremaining: 481ms\n",
      "251:\tlearn: 0.5113803\ttotal: 161ms\tremaining: 479ms\n",
      "252:\tlearn: 0.5095303\ttotal: 162ms\tremaining: 477ms\n",
      "253:\tlearn: 0.5075403\ttotal: 162ms\tremaining: 475ms\n",
      "254:\tlearn: 0.5049897\ttotal: 162ms\tremaining: 473ms\n",
      "255:\tlearn: 0.5034495\ttotal: 162ms\tremaining: 471ms\n",
      "256:\tlearn: 0.5009850\ttotal: 162ms\tremaining: 469ms\n",
      "257:\tlearn: 0.4986739\ttotal: 162ms\tremaining: 467ms\n",
      "258:\tlearn: 0.4965361\ttotal: 162ms\tremaining: 465ms\n",
      "259:\tlearn: 0.4943733\ttotal: 163ms\tremaining: 463ms\n",
      "260:\tlearn: 0.4909859\ttotal: 163ms\tremaining: 461ms\n",
      "261:\tlearn: 0.4884965\ttotal: 163ms\tremaining: 459ms\n",
      "262:\tlearn: 0.4862993\ttotal: 163ms\tremaining: 457ms\n",
      "263:\tlearn: 0.4834480\ttotal: 163ms\tremaining: 455ms\n",
      "264:\tlearn: 0.4802159\ttotal: 163ms\tremaining: 453ms\n",
      "265:\tlearn: 0.4770805\ttotal: 163ms\tremaining: 451ms\n",
      "266:\tlearn: 0.4756744\ttotal: 164ms\tremaining: 449ms\n",
      "267:\tlearn: 0.4730731\ttotal: 164ms\tremaining: 447ms\n",
      "268:\tlearn: 0.4712410\ttotal: 164ms\tremaining: 445ms\n",
      "269:\tlearn: 0.4681816\ttotal: 164ms\tremaining: 443ms\n",
      "270:\tlearn: 0.4656451\ttotal: 164ms\tremaining: 442ms\n",
      "271:\tlearn: 0.4629929\ttotal: 164ms\tremaining: 440ms\n",
      "272:\tlearn: 0.4619513\ttotal: 164ms\tremaining: 438ms\n",
      "273:\tlearn: 0.4591784\ttotal: 165ms\tremaining: 436ms\n",
      "274:\tlearn: 0.4557178\ttotal: 165ms\tremaining: 434ms\n",
      "275:\tlearn: 0.4527172\ttotal: 165ms\tremaining: 432ms\n",
      "276:\tlearn: 0.4506156\ttotal: 165ms\tremaining: 430ms\n",
      "277:\tlearn: 0.4479836\ttotal: 165ms\tremaining: 429ms\n",
      "278:\tlearn: 0.4453827\ttotal: 165ms\tremaining: 427ms\n",
      "279:\tlearn: 0.4419482\ttotal: 165ms\tremaining: 425ms\n",
      "280:\tlearn: 0.4391026\ttotal: 165ms\tremaining: 423ms\n",
      "281:\tlearn: 0.4366475\ttotal: 166ms\tremaining: 422ms\n",
      "282:\tlearn: 0.4341361\ttotal: 166ms\tremaining: 420ms\n",
      "283:\tlearn: 0.4319172\ttotal: 166ms\tremaining: 418ms\n",
      "284:\tlearn: 0.4306677\ttotal: 166ms\tremaining: 417ms\n",
      "285:\tlearn: 0.4286077\ttotal: 166ms\tremaining: 415ms\n",
      "286:\tlearn: 0.4263400\ttotal: 166ms\tremaining: 413ms\n",
      "287:\tlearn: 0.4238982\ttotal: 166ms\tremaining: 412ms\n",
      "288:\tlearn: 0.4212509\ttotal: 167ms\tremaining: 410ms\n",
      "289:\tlearn: 0.4193446\ttotal: 167ms\tremaining: 408ms\n",
      "290:\tlearn: 0.4173539\ttotal: 167ms\tremaining: 407ms\n",
      "291:\tlearn: 0.4154372\ttotal: 167ms\tremaining: 405ms\n",
      "292:\tlearn: 0.4130932\ttotal: 167ms\tremaining: 403ms\n",
      "293:\tlearn: 0.4107198\ttotal: 167ms\tremaining: 402ms\n",
      "294:\tlearn: 0.4097453\ttotal: 167ms\tremaining: 400ms\n",
      "295:\tlearn: 0.4074426\ttotal: 168ms\tremaining: 399ms\n",
      "296:\tlearn: 0.4054687\ttotal: 168ms\tremaining: 397ms\n",
      "297:\tlearn: 0.4035999\ttotal: 168ms\tremaining: 395ms\n",
      "298:\tlearn: 0.4010521\ttotal: 168ms\tremaining: 394ms\n",
      "299:\tlearn: 0.3997779\ttotal: 168ms\tremaining: 392ms\n",
      "300:\tlearn: 0.3975069\ttotal: 168ms\tremaining: 391ms\n",
      "301:\tlearn: 0.3965011\ttotal: 168ms\tremaining: 389ms\n",
      "302:\tlearn: 0.3934169\ttotal: 169ms\tremaining: 388ms\n",
      "303:\tlearn: 0.3912823\ttotal: 169ms\tremaining: 386ms\n",
      "304:\tlearn: 0.3895196\ttotal: 169ms\tremaining: 385ms\n",
      "305:\tlearn: 0.3865131\ttotal: 169ms\tremaining: 383ms\n",
      "306:\tlearn: 0.3835588\ttotal: 169ms\tremaining: 382ms\n",
      "307:\tlearn: 0.3821353\ttotal: 169ms\tremaining: 380ms\n",
      "308:\tlearn: 0.3806558\ttotal: 169ms\tremaining: 379ms\n",
      "309:\tlearn: 0.3792634\ttotal: 170ms\tremaining: 378ms\n",
      "310:\tlearn: 0.3780819\ttotal: 170ms\tremaining: 376ms\n",
      "311:\tlearn: 0.3766766\ttotal: 170ms\tremaining: 375ms\n",
      "312:\tlearn: 0.3746219\ttotal: 170ms\tremaining: 374ms\n",
      "313:\tlearn: 0.3728927\ttotal: 171ms\tremaining: 373ms\n",
      "314:\tlearn: 0.3700578\ttotal: 171ms\tremaining: 371ms\n",
      "315:\tlearn: 0.3680644\ttotal: 171ms\tremaining: 370ms\n",
      "316:\tlearn: 0.3664368\ttotal: 171ms\tremaining: 369ms\n",
      "317:\tlearn: 0.3653404\ttotal: 171ms\tremaining: 368ms\n",
      "318:\tlearn: 0.3636168\ttotal: 172ms\tremaining: 366ms\n",
      "319:\tlearn: 0.3619209\ttotal: 172ms\tremaining: 365ms\n",
      "320:\tlearn: 0.3602524\ttotal: 172ms\tremaining: 364ms\n",
      "321:\tlearn: 0.3585702\ttotal: 172ms\tremaining: 363ms\n",
      "322:\tlearn: 0.3558575\ttotal: 172ms\tremaining: 361ms\n",
      "323:\tlearn: 0.3542847\ttotal: 173ms\tremaining: 360ms\n",
      "324:\tlearn: 0.3533532\ttotal: 173ms\tremaining: 359ms\n",
      "325:\tlearn: 0.3523960\ttotal: 173ms\tremaining: 358ms\n",
      "326:\tlearn: 0.3514883\ttotal: 173ms\tremaining: 357ms\n",
      "327:\tlearn: 0.3497188\ttotal: 174ms\tremaining: 356ms\n",
      "328:\tlearn: 0.3488221\ttotal: 174ms\tremaining: 354ms\n",
      "329:\tlearn: 0.3469742\ttotal: 174ms\tremaining: 353ms\n",
      "330:\tlearn: 0.3453885\ttotal: 174ms\tremaining: 352ms\n",
      "331:\tlearn: 0.3435589\ttotal: 174ms\tremaining: 350ms\n",
      "332:\tlearn: 0.3420080\ttotal: 174ms\tremaining: 349ms\n",
      "333:\tlearn: 0.3404822\ttotal: 174ms\tremaining: 348ms\n",
      "334:\tlearn: 0.3379290\ttotal: 175ms\tremaining: 347ms\n",
      "335:\tlearn: 0.3363865\ttotal: 175ms\tremaining: 345ms\n",
      "336:\tlearn: 0.3351446\ttotal: 175ms\tremaining: 344ms\n",
      "337:\tlearn: 0.3336570\ttotal: 175ms\tremaining: 343ms\n",
      "338:\tlearn: 0.3324452\ttotal: 175ms\tremaining: 342ms\n",
      "339:\tlearn: 0.3309660\ttotal: 175ms\tremaining: 340ms\n",
      "340:\tlearn: 0.3302327\ttotal: 175ms\tremaining: 339ms\n",
      "341:\tlearn: 0.3294051\ttotal: 176ms\tremaining: 338ms\n",
      "342:\tlearn: 0.3279446\ttotal: 176ms\tremaining: 337ms\n",
      "343:\tlearn: 0.3265077\ttotal: 176ms\tremaining: 335ms\n",
      "344:\tlearn: 0.3256605\ttotal: 176ms\tremaining: 334ms\n",
      "345:\tlearn: 0.3242513\ttotal: 176ms\tremaining: 333ms\n",
      "346:\tlearn: 0.3231050\ttotal: 176ms\tremaining: 332ms\n",
      "347:\tlearn: 0.3223837\ttotal: 177ms\tremaining: 331ms\n",
      "348:\tlearn: 0.3212550\ttotal: 177ms\tremaining: 330ms\n",
      "349:\tlearn: 0.3200787\ttotal: 177ms\tremaining: 329ms\n",
      "350:\tlearn: 0.3187199\ttotal: 177ms\tremaining: 327ms\n",
      "351:\tlearn: 0.3176185\ttotal: 177ms\tremaining: 326ms\n",
      "352:\tlearn: 0.3161353\ttotal: 177ms\tremaining: 325ms\n",
      "353:\tlearn: 0.3137761\ttotal: 177ms\tremaining: 324ms\n",
      "354:\tlearn: 0.3130835\ttotal: 178ms\tremaining: 323ms\n",
      "355:\tlearn: 0.3107684\ttotal: 178ms\tremaining: 322ms\n",
      "356:\tlearn: 0.3084373\ttotal: 178ms\tremaining: 320ms\n",
      "357:\tlearn: 0.3070367\ttotal: 178ms\tremaining: 319ms\n",
      "358:\tlearn: 0.3056942\ttotal: 178ms\tremaining: 318ms\n",
      "359:\tlearn: 0.3034768\ttotal: 178ms\tremaining: 317ms\n",
      "360:\tlearn: 0.3027386\ttotal: 178ms\tremaining: 316ms\n",
      "361:\tlearn: 0.3020106\ttotal: 179ms\tremaining: 315ms\n",
      "362:\tlearn: 0.3013613\ttotal: 179ms\tremaining: 314ms\n",
      "363:\tlearn: 0.2998135\ttotal: 179ms\tremaining: 313ms\n",
      "364:\tlearn: 0.2985443\ttotal: 179ms\tremaining: 311ms\n",
      "365:\tlearn: 0.2975151\ttotal: 179ms\tremaining: 310ms\n",
      "366:\tlearn: 0.2959557\ttotal: 179ms\tremaining: 309ms\n",
      "367:\tlearn: 0.2944546\ttotal: 179ms\tremaining: 308ms\n",
      "368:\tlearn: 0.2929434\ttotal: 180ms\tremaining: 307ms\n",
      "369:\tlearn: 0.2914215\ttotal: 180ms\tremaining: 306ms\n",
      "370:\tlearn: 0.2902137\ttotal: 180ms\tremaining: 305ms\n",
      "371:\tlearn: 0.2879294\ttotal: 180ms\tremaining: 304ms\n",
      "372:\tlearn: 0.2856854\ttotal: 180ms\tremaining: 303ms\n",
      "373:\tlearn: 0.2834812\ttotal: 180ms\tremaining: 302ms\n",
      "374:\tlearn: 0.2813161\ttotal: 180ms\tremaining: 301ms\n",
      "375:\tlearn: 0.2796468\ttotal: 181ms\tremaining: 300ms\n",
      "376:\tlearn: 0.2781310\ttotal: 181ms\tremaining: 299ms\n",
      "377:\tlearn: 0.2762066\ttotal: 181ms\tremaining: 298ms\n",
      "378:\tlearn: 0.2750217\ttotal: 181ms\tremaining: 297ms\n",
      "379:\tlearn: 0.2737962\ttotal: 181ms\tremaining: 295ms\n",
      "380:\tlearn: 0.2717385\ttotal: 181ms\tremaining: 294ms\n",
      "381:\tlearn: 0.2712323\ttotal: 181ms\tremaining: 293ms\n",
      "382:\tlearn: 0.2699444\ttotal: 182ms\tremaining: 292ms\n",
      "383:\tlearn: 0.2682404\ttotal: 182ms\tremaining: 291ms\n",
      "384:\tlearn: 0.2658441\ttotal: 182ms\tremaining: 290ms\n",
      "385:\tlearn: 0.2641796\ttotal: 182ms\tremaining: 289ms\n",
      "386:\tlearn: 0.2636894\ttotal: 182ms\tremaining: 288ms\n",
      "387:\tlearn: 0.2632050\ttotal: 182ms\tremaining: 287ms\n",
      "388:\tlearn: 0.2622982\ttotal: 182ms\tremaining: 287ms\n",
      "389:\tlearn: 0.2609493\ttotal: 183ms\tremaining: 286ms\n",
      "390:\tlearn: 0.2594235\ttotal: 183ms\tremaining: 285ms\n",
      "391:\tlearn: 0.2579364\ttotal: 183ms\tremaining: 284ms\n",
      "392:\tlearn: 0.2566392\ttotal: 183ms\tremaining: 283ms\n",
      "393:\tlearn: 0.2543612\ttotal: 183ms\tremaining: 282ms\n",
      "394:\tlearn: 0.2523795\ttotal: 183ms\tremaining: 281ms\n",
      "395:\tlearn: 0.2501693\ttotal: 183ms\tremaining: 280ms\n",
      "396:\tlearn: 0.2487060\ttotal: 184ms\tremaining: 279ms\n",
      "397:\tlearn: 0.2467841\ttotal: 184ms\tremaining: 278ms\n",
      "398:\tlearn: 0.2459755\ttotal: 184ms\tremaining: 277ms\n",
      "399:\tlearn: 0.2442106\ttotal: 184ms\tremaining: 276ms\n",
      "400:\tlearn: 0.2428157\ttotal: 184ms\tremaining: 275ms\n",
      "401:\tlearn: 0.2412763\ttotal: 184ms\tremaining: 274ms\n",
      "402:\tlearn: 0.2398894\ttotal: 184ms\tremaining: 273ms\n",
      "403:\tlearn: 0.2385134\ttotal: 184ms\tremaining: 272ms\n",
      "404:\tlearn: 0.2371606\ttotal: 185ms\tremaining: 271ms\n",
      "405:\tlearn: 0.2361729\ttotal: 185ms\tremaining: 270ms\n",
      "406:\tlearn: 0.2348411\ttotal: 185ms\tremaining: 269ms\n",
      "407:\tlearn: 0.2338794\ttotal: 185ms\tremaining: 268ms\n",
      "408:\tlearn: 0.2327053\ttotal: 185ms\tremaining: 268ms\n",
      "409:\tlearn: 0.2309198\ttotal: 185ms\tremaining: 267ms\n",
      "410:\tlearn: 0.2296275\ttotal: 185ms\tremaining: 266ms\n",
      "411:\tlearn: 0.2283120\ttotal: 186ms\tremaining: 265ms\n",
      "412:\tlearn: 0.2267173\ttotal: 186ms\tremaining: 264ms\n",
      "413:\tlearn: 0.2252838\ttotal: 186ms\tremaining: 263ms\n",
      "414:\tlearn: 0.2244852\ttotal: 186ms\tremaining: 262ms\n",
      "415:\tlearn: 0.2232318\ttotal: 186ms\tremaining: 261ms\n",
      "416:\tlearn: 0.2225463\ttotal: 186ms\tremaining: 260ms\n",
      "417:\tlearn: 0.2208528\ttotal: 186ms\tremaining: 260ms\n",
      "418:\tlearn: 0.2196391\ttotal: 187ms\tremaining: 259ms\n",
      "419:\tlearn: 0.2189557\ttotal: 187ms\tremaining: 258ms\n",
      "420:\tlearn: 0.2172235\ttotal: 187ms\tremaining: 257ms\n",
      "421:\tlearn: 0.2165584\ttotal: 187ms\tremaining: 256ms\n",
      "422:\tlearn: 0.2155557\ttotal: 187ms\tremaining: 255ms\n",
      "423:\tlearn: 0.2138752\ttotal: 187ms\tremaining: 254ms\n",
      "424:\tlearn: 0.2124352\ttotal: 187ms\tremaining: 254ms\n",
      "425:\tlearn: 0.2109001\ttotal: 188ms\tremaining: 253ms\n",
      "426:\tlearn: 0.2092892\ttotal: 188ms\tremaining: 252ms\n",
      "427:\tlearn: 0.2077153\ttotal: 188ms\tremaining: 251ms\n",
      "428:\tlearn: 0.2070591\ttotal: 188ms\tremaining: 250ms\n",
      "429:\tlearn: 0.2059463\ttotal: 188ms\tremaining: 249ms\n",
      "430:\tlearn: 0.2045670\ttotal: 188ms\tremaining: 249ms\n",
      "431:\tlearn: 0.2039551\ttotal: 188ms\tremaining: 248ms\n",
      "432:\tlearn: 0.2028387\ttotal: 189ms\tremaining: 247ms\n",
      "433:\tlearn: 0.2022413\ttotal: 189ms\tremaining: 246ms\n",
      "434:\tlearn: 0.2016548\ttotal: 189ms\tremaining: 245ms\n",
      "435:\tlearn: 0.2003160\ttotal: 189ms\tremaining: 244ms\n",
      "436:\tlearn: 0.1988221\ttotal: 189ms\tremaining: 244ms\n",
      "437:\tlearn: 0.1977208\ttotal: 189ms\tremaining: 243ms\n",
      "438:\tlearn: 0.1971552\ttotal: 189ms\tremaining: 242ms\n",
      "439:\tlearn: 0.1967504\ttotal: 190ms\tremaining: 241ms\n",
      "440:\tlearn: 0.1955746\ttotal: 190ms\tremaining: 240ms\n",
      "441:\tlearn: 0.1951755\ttotal: 190ms\tremaining: 240ms\n",
      "442:\tlearn: 0.1938958\ttotal: 190ms\tremaining: 239ms\n",
      "443:\tlearn: 0.1928522\ttotal: 190ms\tremaining: 238ms\n",
      "444:\tlearn: 0.1923087\ttotal: 190ms\tremaining: 237ms\n",
      "445:\tlearn: 0.1917752\ttotal: 190ms\tremaining: 236ms\n",
      "446:\tlearn: 0.1908657\ttotal: 190ms\tremaining: 236ms\n",
      "447:\tlearn: 0.1903405\ttotal: 191ms\tremaining: 235ms\n",
      "448:\tlearn: 0.1899524\ttotal: 191ms\tremaining: 234ms\n",
      "449:\tlearn: 0.1885521\ttotal: 191ms\tremaining: 233ms\n",
      "450:\tlearn: 0.1881703\ttotal: 191ms\tremaining: 233ms\n",
      "451:\tlearn: 0.1876798\ttotal: 191ms\tremaining: 232ms\n",
      "452:\tlearn: 0.1864968\ttotal: 191ms\tremaining: 231ms\n",
      "453:\tlearn: 0.1854022\ttotal: 191ms\tremaining: 230ms\n",
      "454:\tlearn: 0.1847007\ttotal: 192ms\tremaining: 230ms\n",
      "455:\tlearn: 0.1843286\ttotal: 192ms\tremaining: 229ms\n",
      "456:\tlearn: 0.1834576\ttotal: 192ms\tremaining: 228ms\n",
      "457:\tlearn: 0.1829859\ttotal: 192ms\tremaining: 227ms\n",
      "458:\tlearn: 0.1821418\ttotal: 192ms\tremaining: 227ms\n",
      "459:\tlearn: 0.1816795\ttotal: 193ms\tremaining: 226ms\n",
      "460:\tlearn: 0.1808507\ttotal: 193ms\tremaining: 225ms\n",
      "461:\tlearn: 0.1803742\ttotal: 193ms\tremaining: 225ms\n",
      "462:\tlearn: 0.1795606\ttotal: 193ms\tremaining: 224ms\n",
      "463:\tlearn: 0.1791152\ttotal: 193ms\tremaining: 223ms\n",
      "464:\tlearn: 0.1784533\ttotal: 194ms\tremaining: 223ms\n",
      "465:\tlearn: 0.1776181\ttotal: 194ms\tremaining: 222ms\n",
      "466:\tlearn: 0.1771831\ttotal: 194ms\tremaining: 222ms\n",
      "467:\tlearn: 0.1761570\ttotal: 194ms\tremaining: 221ms\n",
      "468:\tlearn: 0.1755364\ttotal: 195ms\tremaining: 220ms\n",
      "469:\tlearn: 0.1751816\ttotal: 195ms\tremaining: 220ms\n",
      "470:\tlearn: 0.1745765\ttotal: 195ms\tremaining: 219ms\n",
      "471:\tlearn: 0.1742258\ttotal: 195ms\tremaining: 218ms\n",
      "472:\tlearn: 0.1736358\ttotal: 195ms\tremaining: 218ms\n",
      "473:\tlearn: 0.1732890\ttotal: 196ms\tremaining: 217ms\n",
      "474:\tlearn: 0.1729464\ttotal: 196ms\tremaining: 216ms\n",
      "475:\tlearn: 0.1723708\ttotal: 196ms\tremaining: 216ms\n",
      "476:\tlearn: 0.1720321\ttotal: 196ms\tremaining: 215ms\n",
      "477:\tlearn: 0.1714708\ttotal: 197ms\tremaining: 215ms\n",
      "478:\tlearn: 0.1711359\ttotal: 197ms\tremaining: 214ms\n",
      "479:\tlearn: 0.1707423\ttotal: 197ms\tremaining: 213ms\n",
      "480:\tlearn: 0.1704117\ttotal: 197ms\tremaining: 213ms\n",
      "481:\tlearn: 0.1692742\ttotal: 197ms\tremaining: 212ms\n",
      "482:\tlearn: 0.1687342\ttotal: 198ms\tremaining: 212ms\n",
      "483:\tlearn: 0.1683074\ttotal: 198ms\tremaining: 211ms\n",
      "484:\tlearn: 0.1679295\ttotal: 198ms\tremaining: 210ms\n",
      "485:\tlearn: 0.1670088\ttotal: 198ms\tremaining: 210ms\n",
      "486:\tlearn: 0.1664883\ttotal: 198ms\tremaining: 209ms\n",
      "487:\tlearn: 0.1660706\ttotal: 198ms\tremaining: 208ms\n",
      "488:\tlearn: 0.1655622\ttotal: 199ms\tremaining: 208ms\n",
      "489:\tlearn: 0.1651499\ttotal: 199ms\tremaining: 207ms\n",
      "490:\tlearn: 0.1647924\ttotal: 199ms\tremaining: 206ms\n",
      "491:\tlearn: 0.1643865\ttotal: 199ms\tremaining: 205ms\n",
      "492:\tlearn: 0.1634972\ttotal: 199ms\tremaining: 205ms\n",
      "493:\tlearn: 0.1630065\ttotal: 199ms\tremaining: 204ms\n",
      "494:\tlearn: 0.1626629\ttotal: 199ms\tremaining: 203ms\n",
      "495:\tlearn: 0.1622657\ttotal: 200ms\tremaining: 203ms\n",
      "496:\tlearn: 0.1617914\ttotal: 200ms\tremaining: 202ms\n",
      "497:\tlearn: 0.1614502\ttotal: 200ms\tremaining: 201ms\n",
      "498:\tlearn: 0.1610604\ttotal: 200ms\tremaining: 201ms\n",
      "499:\tlearn: 0.1607508\ttotal: 200ms\tremaining: 200ms\n",
      "500:\tlearn: 0.1598920\ttotal: 200ms\tremaining: 199ms\n",
      "501:\tlearn: 0.1594349\ttotal: 200ms\tremaining: 199ms\n",
      "502:\tlearn: 0.1590866\ttotal: 201ms\tremaining: 198ms\n",
      "503:\tlearn: 0.1587067\ttotal: 201ms\tremaining: 198ms\n",
      "504:\tlearn: 0.1576624\ttotal: 201ms\tremaining: 197ms\n",
      "505:\tlearn: 0.1573457\ttotal: 201ms\tremaining: 196ms\n",
      "506:\tlearn: 0.1563163\ttotal: 201ms\tremaining: 196ms\n",
      "507:\tlearn: 0.1560265\ttotal: 201ms\tremaining: 195ms\n",
      "508:\tlearn: 0.1557062\ttotal: 201ms\tremaining: 194ms\n",
      "509:\tlearn: 0.1547000\ttotal: 202ms\tremaining: 194ms\n",
      "510:\tlearn: 0.1542693\ttotal: 202ms\tremaining: 193ms\n",
      "511:\tlearn: 0.1539938\ttotal: 202ms\tremaining: 192ms\n",
      "512:\tlearn: 0.1537217\ttotal: 202ms\tremaining: 192ms\n",
      "513:\tlearn: 0.1534049\ttotal: 202ms\tremaining: 191ms\n",
      "514:\tlearn: 0.1524332\ttotal: 202ms\tremaining: 191ms\n",
      "515:\tlearn: 0.1521240\ttotal: 202ms\tremaining: 190ms\n",
      "516:\tlearn: 0.1511750\ttotal: 203ms\tremaining: 189ms\n",
      "517:\tlearn: 0.1509061\ttotal: 203ms\tremaining: 189ms\n",
      "518:\tlearn: 0.1506042\ttotal: 203ms\tremaining: 188ms\n",
      "519:\tlearn: 0.1496773\ttotal: 203ms\tremaining: 187ms\n",
      "520:\tlearn: 0.1486473\ttotal: 203ms\tremaining: 187ms\n",
      "521:\tlearn: 0.1483825\ttotal: 203ms\tremaining: 186ms\n",
      "522:\tlearn: 0.1476998\ttotal: 203ms\tremaining: 186ms\n",
      "523:\tlearn: 0.1474074\ttotal: 204ms\tremaining: 185ms\n",
      "524:\tlearn: 0.1464078\ttotal: 204ms\tremaining: 184ms\n",
      "525:\tlearn: 0.1459452\ttotal: 204ms\tremaining: 184ms\n",
      "526:\tlearn: 0.1456575\ttotal: 204ms\tremaining: 183ms\n",
      "527:\tlearn: 0.1453737\ttotal: 204ms\tremaining: 182ms\n",
      "528:\tlearn: 0.1444683\ttotal: 204ms\tremaining: 182ms\n",
      "529:\tlearn: 0.1438429\ttotal: 204ms\tremaining: 181ms\n",
      "530:\tlearn: 0.1434545\ttotal: 205ms\tremaining: 181ms\n",
      "531:\tlearn: 0.1429642\ttotal: 205ms\tremaining: 180ms\n",
      "532:\tlearn: 0.1424825\ttotal: 205ms\tremaining: 179ms\n",
      "533:\tlearn: 0.1416014\ttotal: 205ms\tremaining: 179ms\n",
      "534:\tlearn: 0.1411607\ttotal: 205ms\tremaining: 178ms\n",
      "535:\tlearn: 0.1406895\ttotal: 205ms\tremaining: 178ms\n",
      "536:\tlearn: 0.1403385\ttotal: 205ms\tremaining: 177ms\n",
      "537:\tlearn: 0.1394741\ttotal: 206ms\tremaining: 176ms\n",
      "538:\tlearn: 0.1385464\ttotal: 206ms\tremaining: 176ms\n",
      "539:\tlearn: 0.1380857\ttotal: 206ms\tremaining: 175ms\n",
      "540:\tlearn: 0.1372050\ttotal: 206ms\tremaining: 175ms\n",
      "541:\tlearn: 0.1363026\ttotal: 206ms\tremaining: 174ms\n",
      "542:\tlearn: 0.1358489\ttotal: 206ms\tremaining: 174ms\n",
      "543:\tlearn: 0.1354558\ttotal: 206ms\tremaining: 173ms\n",
      "544:\tlearn: 0.1346014\ttotal: 207ms\tremaining: 172ms\n",
      "545:\tlearn: 0.1338094\ttotal: 207ms\tremaining: 172ms\n",
      "546:\tlearn: 0.1330787\ttotal: 207ms\tremaining: 171ms\n",
      "547:\tlearn: 0.1323214\ttotal: 207ms\tremaining: 171ms\n",
      "548:\tlearn: 0.1315412\ttotal: 207ms\tremaining: 170ms\n",
      "549:\tlearn: 0.1307707\ttotal: 207ms\tremaining: 170ms\n",
      "550:\tlearn: 0.1303707\ttotal: 207ms\tremaining: 169ms\n",
      "551:\tlearn: 0.1300393\ttotal: 207ms\tremaining: 168ms\n",
      "552:\tlearn: 0.1292835\ttotal: 208ms\tremaining: 168ms\n",
      "553:\tlearn: 0.1285542\ttotal: 208ms\tremaining: 167ms\n",
      "554:\tlearn: 0.1282286\ttotal: 208ms\tremaining: 167ms\n",
      "555:\tlearn: 0.1274433\ttotal: 208ms\tremaining: 166ms\n",
      "556:\tlearn: 0.1267053\ttotal: 208ms\tremaining: 166ms\n",
      "557:\tlearn: 0.1260530\ttotal: 208ms\tremaining: 165ms\n",
      "558:\tlearn: 0.1254132\ttotal: 209ms\tremaining: 165ms\n",
      "559:\tlearn: 0.1246910\ttotal: 209ms\tremaining: 164ms\n",
      "560:\tlearn: 0.1238669\ttotal: 209ms\tremaining: 164ms\n",
      "561:\tlearn: 0.1231503\ttotal: 209ms\tremaining: 163ms\n",
      "562:\tlearn: 0.1224462\ttotal: 209ms\tremaining: 163ms\n",
      "563:\tlearn: 0.1220580\ttotal: 210ms\tremaining: 162ms\n",
      "564:\tlearn: 0.1217508\ttotal: 210ms\tremaining: 162ms\n",
      "565:\tlearn: 0.1210599\ttotal: 210ms\tremaining: 161ms\n",
      "566:\tlearn: 0.1204459\ttotal: 210ms\tremaining: 161ms\n",
      "567:\tlearn: 0.1197670\ttotal: 211ms\tremaining: 160ms\n",
      "568:\tlearn: 0.1191750\ttotal: 211ms\tremaining: 160ms\n",
      "569:\tlearn: 0.1185080\ttotal: 211ms\tremaining: 159ms\n",
      "570:\tlearn: 0.1178434\ttotal: 211ms\tremaining: 159ms\n",
      "571:\tlearn: 0.1171884\ttotal: 211ms\tremaining: 158ms\n",
      "572:\tlearn: 0.1166042\ttotal: 212ms\tremaining: 158ms\n",
      "573:\tlearn: 0.1160252\ttotal: 212ms\tremaining: 157ms\n",
      "574:\tlearn: 0.1153838\ttotal: 212ms\tremaining: 157ms\n",
      "575:\tlearn: 0.1147537\ttotal: 212ms\tremaining: 156ms\n",
      "576:\tlearn: 0.1141231\ttotal: 212ms\tremaining: 156ms\n",
      "577:\tlearn: 0.1133805\ttotal: 212ms\tremaining: 155ms\n",
      "578:\tlearn: 0.1127620\ttotal: 213ms\tremaining: 155ms\n",
      "579:\tlearn: 0.1122075\ttotal: 213ms\tremaining: 154ms\n",
      "580:\tlearn: 0.1117159\ttotal: 213ms\tremaining: 154ms\n",
      "581:\tlearn: 0.1110577\ttotal: 213ms\tremaining: 153ms\n",
      "582:\tlearn: 0.1105764\ttotal: 213ms\tremaining: 153ms\n",
      "583:\tlearn: 0.1100060\ttotal: 213ms\tremaining: 152ms\n",
      "584:\tlearn: 0.1095343\ttotal: 214ms\tremaining: 151ms\n",
      "585:\tlearn: 0.1088481\ttotal: 214ms\tremaining: 151ms\n",
      "586:\tlearn: 0.1083844\ttotal: 214ms\tremaining: 150ms\n",
      "587:\tlearn: 0.1080543\ttotal: 214ms\tremaining: 150ms\n",
      "588:\tlearn: 0.1075920\ttotal: 214ms\tremaining: 149ms\n",
      "589:\tlearn: 0.1069219\ttotal: 214ms\tremaining: 149ms\n",
      "590:\tlearn: 0.1065976\ttotal: 214ms\tremaining: 148ms\n",
      "591:\tlearn: 0.1062776\ttotal: 215ms\tremaining: 148ms\n",
      "592:\tlearn: 0.1059392\ttotal: 215ms\tremaining: 147ms\n",
      "593:\tlearn: 0.1056236\ttotal: 215ms\tremaining: 147ms\n",
      "594:\tlearn: 0.1053122\ttotal: 215ms\tremaining: 146ms\n",
      "595:\tlearn: 0.1049818\ttotal: 215ms\tremaining: 146ms\n",
      "596:\tlearn: 0.1046881\ttotal: 215ms\tremaining: 145ms\n",
      "597:\tlearn: 0.1041817\ttotal: 215ms\tremaining: 145ms\n",
      "598:\tlearn: 0.1038380\ttotal: 216ms\tremaining: 144ms\n",
      "599:\tlearn: 0.1034464\ttotal: 216ms\tremaining: 144ms\n",
      "600:\tlearn: 0.1031076\ttotal: 216ms\tremaining: 143ms\n",
      "601:\tlearn: 0.1027736\ttotal: 216ms\tremaining: 143ms\n",
      "602:\tlearn: 0.1024443\ttotal: 216ms\tremaining: 142ms\n",
      "603:\tlearn: 0.1021381\ttotal: 216ms\tremaining: 142ms\n",
      "604:\tlearn: 0.1018313\ttotal: 216ms\tremaining: 141ms\n",
      "605:\tlearn: 0.1015287\ttotal: 217ms\tremaining: 141ms\n",
      "606:\tlearn: 0.1010406\ttotal: 217ms\tremaining: 140ms\n",
      "607:\tlearn: 0.1007860\ttotal: 217ms\tremaining: 140ms\n",
      "608:\tlearn: 0.1004092\ttotal: 217ms\tremaining: 139ms\n",
      "609:\tlearn: 0.1001585\ttotal: 217ms\tremaining: 139ms\n",
      "610:\tlearn: 0.0995628\ttotal: 217ms\tremaining: 138ms\n",
      "611:\tlearn: 0.0989771\ttotal: 217ms\tremaining: 138ms\n",
      "612:\tlearn: 0.0983179\ttotal: 218ms\tremaining: 137ms\n",
      "613:\tlearn: 0.0977469\ttotal: 218ms\tremaining: 137ms\n",
      "614:\tlearn: 0.0969927\ttotal: 218ms\tremaining: 136ms\n",
      "615:\tlearn: 0.0966267\ttotal: 218ms\tremaining: 136ms\n",
      "616:\tlearn: 0.0958866\ttotal: 218ms\tremaining: 135ms\n",
      "617:\tlearn: 0.0955267\ttotal: 218ms\tremaining: 135ms\n",
      "618:\tlearn: 0.0951305\ttotal: 218ms\tremaining: 134ms\n",
      "619:\tlearn: 0.0947777\ttotal: 219ms\tremaining: 134ms\n",
      "620:\tlearn: 0.0940557\ttotal: 219ms\tremaining: 133ms\n",
      "621:\tlearn: 0.0937088\ttotal: 219ms\tremaining: 133ms\n",
      "622:\tlearn: 0.0930001\ttotal: 219ms\tremaining: 132ms\n",
      "623:\tlearn: 0.0925728\ttotal: 219ms\tremaining: 132ms\n",
      "624:\tlearn: 0.0923638\ttotal: 219ms\tremaining: 132ms\n",
      "625:\tlearn: 0.0919485\ttotal: 219ms\tremaining: 131ms\n",
      "626:\tlearn: 0.0916778\ttotal: 219ms\tremaining: 131ms\n",
      "627:\tlearn: 0.0909901\ttotal: 220ms\tremaining: 130ms\n",
      "628:\tlearn: 0.0907865\ttotal: 220ms\tremaining: 130ms\n",
      "629:\tlearn: 0.0905856\ttotal: 220ms\tremaining: 129ms\n",
      "630:\tlearn: 0.0901878\ttotal: 220ms\tremaining: 129ms\n",
      "631:\tlearn: 0.0899266\ttotal: 220ms\tremaining: 128ms\n",
      "632:\tlearn: 0.0892551\ttotal: 220ms\tremaining: 128ms\n",
      "633:\tlearn: 0.0889979\ttotal: 220ms\tremaining: 127ms\n",
      "634:\tlearn: 0.0883380\ttotal: 221ms\tremaining: 127ms\n",
      "635:\tlearn: 0.0881444\ttotal: 221ms\tremaining: 126ms\n",
      "636:\tlearn: 0.0877213\ttotal: 221ms\tremaining: 126ms\n",
      "637:\tlearn: 0.0873064\ttotal: 221ms\tremaining: 125ms\n",
      "638:\tlearn: 0.0871140\ttotal: 221ms\tremaining: 125ms\n",
      "639:\tlearn: 0.0868828\ttotal: 221ms\tremaining: 124ms\n",
      "640:\tlearn: 0.0864657\ttotal: 221ms\tremaining: 124ms\n",
      "641:\tlearn: 0.0861071\ttotal: 222ms\tremaining: 124ms\n",
      "642:\tlearn: 0.0857390\ttotal: 222ms\tremaining: 123ms\n",
      "643:\tlearn: 0.0855854\ttotal: 222ms\tremaining: 123ms\n",
      "644:\tlearn: 0.0853106\ttotal: 222ms\tremaining: 122ms\n",
      "645:\tlearn: 0.0847868\ttotal: 222ms\tremaining: 122ms\n",
      "646:\tlearn: 0.0844373\ttotal: 222ms\tremaining: 121ms\n",
      "647:\tlearn: 0.0841661\ttotal: 222ms\tremaining: 121ms\n",
      "648:\tlearn: 0.0839451\ttotal: 223ms\tremaining: 120ms\n",
      "649:\tlearn: 0.0836767\ttotal: 223ms\tremaining: 120ms\n",
      "650:\tlearn: 0.0832868\ttotal: 223ms\tremaining: 120ms\n",
      "651:\tlearn: 0.0830209\ttotal: 223ms\tremaining: 119ms\n",
      "652:\tlearn: 0.0828802\ttotal: 223ms\tremaining: 119ms\n",
      "653:\tlearn: 0.0824679\ttotal: 223ms\tremaining: 118ms\n",
      "654:\tlearn: 0.0822048\ttotal: 223ms\tremaining: 118ms\n",
      "655:\tlearn: 0.0819607\ttotal: 224ms\tremaining: 117ms\n",
      "656:\tlearn: 0.0817004\ttotal: 224ms\tremaining: 117ms\n",
      "657:\tlearn: 0.0815640\ttotal: 224ms\tremaining: 116ms\n",
      "658:\tlearn: 0.0810285\ttotal: 224ms\tremaining: 116ms\n",
      "659:\tlearn: 0.0808200\ttotal: 224ms\tremaining: 115ms\n",
      "660:\tlearn: 0.0805636\ttotal: 224ms\tremaining: 115ms\n",
      "661:\tlearn: 0.0803579\ttotal: 224ms\tremaining: 115ms\n",
      "662:\tlearn: 0.0801041\ttotal: 225ms\tremaining: 114ms\n",
      "663:\tlearn: 0.0795878\ttotal: 225ms\tremaining: 114ms\n",
      "664:\tlearn: 0.0793866\ttotal: 225ms\tremaining: 113ms\n",
      "665:\tlearn: 0.0788841\ttotal: 225ms\tremaining: 113ms\n",
      "666:\tlearn: 0.0786370\ttotal: 225ms\tremaining: 112ms\n",
      "667:\tlearn: 0.0784368\ttotal: 225ms\tremaining: 112ms\n",
      "668:\tlearn: 0.0781923\ttotal: 225ms\tremaining: 112ms\n",
      "669:\tlearn: 0.0780624\ttotal: 226ms\tremaining: 111ms\n",
      "670:\tlearn: 0.0777722\ttotal: 226ms\tremaining: 111ms\n",
      "671:\tlearn: 0.0775758\ttotal: 226ms\tremaining: 110ms\n",
      "672:\tlearn: 0.0770923\ttotal: 226ms\tremaining: 110ms\n",
      "673:\tlearn: 0.0768524\ttotal: 226ms\tremaining: 109ms\n",
      "674:\tlearn: 0.0767256\ttotal: 226ms\tremaining: 109ms\n",
      "675:\tlearn: 0.0762195\ttotal: 226ms\tremaining: 109ms\n",
      "676:\tlearn: 0.0759380\ttotal: 227ms\tremaining: 108ms\n",
      "677:\tlearn: 0.0757709\ttotal: 227ms\tremaining: 108ms\n",
      "678:\tlearn: 0.0756059\ttotal: 227ms\tremaining: 107ms\n",
      "679:\tlearn: 0.0753303\ttotal: 227ms\tremaining: 107ms\n",
      "680:\tlearn: 0.0751670\ttotal: 227ms\tremaining: 106ms\n",
      "681:\tlearn: 0.0749343\ttotal: 227ms\tremaining: 106ms\n",
      "682:\tlearn: 0.0748104\ttotal: 227ms\tremaining: 106ms\n",
      "683:\tlearn: 0.0745412\ttotal: 228ms\tremaining: 105ms\n",
      "684:\tlearn: 0.0743570\ttotal: 228ms\tremaining: 105ms\n",
      "685:\tlearn: 0.0741272\ttotal: 228ms\tremaining: 104ms\n",
      "686:\tlearn: 0.0739002\ttotal: 228ms\tremaining: 104ms\n",
      "687:\tlearn: 0.0736803\ttotal: 228ms\tremaining: 103ms\n",
      "688:\tlearn: 0.0734556\ttotal: 228ms\tremaining: 103ms\n",
      "689:\tlearn: 0.0731937\ttotal: 228ms\tremaining: 103ms\n",
      "690:\tlearn: 0.0730368\ttotal: 229ms\tremaining: 102ms\n",
      "691:\tlearn: 0.0729171\ttotal: 229ms\tremaining: 102ms\n",
      "692:\tlearn: 0.0726955\ttotal: 229ms\tremaining: 101ms\n",
      "693:\tlearn: 0.0724395\ttotal: 229ms\tremaining: 101ms\n",
      "694:\tlearn: 0.0722853\ttotal: 229ms\tremaining: 101ms\n",
      "695:\tlearn: 0.0719710\ttotal: 229ms\tremaining: 100ms\n",
      "696:\tlearn: 0.0716610\ttotal: 229ms\tremaining: 99.7ms\n",
      "697:\tlearn: 0.0714828\ttotal: 230ms\tremaining: 99.3ms\n",
      "698:\tlearn: 0.0713132\ttotal: 230ms\tremaining: 98.9ms\n",
      "699:\tlearn: 0.0710072\ttotal: 230ms\tremaining: 98.5ms\n",
      "700:\tlearn: 0.0708264\ttotal: 230ms\tremaining: 98.1ms\n",
      "701:\tlearn: 0.0706534\ttotal: 230ms\tremaining: 97.8ms\n",
      "702:\tlearn: 0.0703526\ttotal: 230ms\tremaining: 97.4ms\n",
      "703:\tlearn: 0.0701818\ttotal: 231ms\tremaining: 97ms\n",
      "704:\tlearn: 0.0698839\ttotal: 231ms\tremaining: 96.6ms\n",
      "705:\tlearn: 0.0695924\ttotal: 231ms\tremaining: 96.2ms\n",
      "706:\tlearn: 0.0694241\ttotal: 231ms\tremaining: 95.7ms\n",
      "707:\tlearn: 0.0692637\ttotal: 231ms\tremaining: 95.3ms\n",
      "708:\tlearn: 0.0689737\ttotal: 231ms\tremaining: 94.9ms\n",
      "709:\tlearn: 0.0687755\ttotal: 231ms\tremaining: 94.5ms\n",
      "710:\tlearn: 0.0686119\ttotal: 232ms\tremaining: 94.1ms\n",
      "711:\tlearn: 0.0684174\ttotal: 232ms\tremaining: 93.7ms\n",
      "712:\tlearn: 0.0682622\ttotal: 232ms\tremaining: 93.3ms\n",
      "713:\tlearn: 0.0679804\ttotal: 232ms\tremaining: 92.9ms\n",
      "714:\tlearn: 0.0678204\ttotal: 232ms\tremaining: 92.5ms\n",
      "715:\tlearn: 0.0676303\ttotal: 232ms\tremaining: 92.1ms\n",
      "716:\tlearn: 0.0674727\ttotal: 232ms\tremaining: 91.7ms\n",
      "717:\tlearn: 0.0673369\ttotal: 233ms\tremaining: 91.4ms\n",
      "718:\tlearn: 0.0671501\ttotal: 233ms\tremaining: 91ms\n",
      "719:\tlearn: 0.0670023\ttotal: 233ms\tremaining: 90.6ms\n",
      "720:\tlearn: 0.0665891\ttotal: 233ms\tremaining: 90.2ms\n",
      "721:\tlearn: 0.0663884\ttotal: 233ms\tremaining: 89.8ms\n",
      "722:\tlearn: 0.0659852\ttotal: 233ms\tremaining: 89.4ms\n",
      "723:\tlearn: 0.0657876\ttotal: 233ms\tremaining: 89ms\n",
      "724:\tlearn: 0.0656054\ttotal: 234ms\tremaining: 88.6ms\n",
      "725:\tlearn: 0.0654100\ttotal: 234ms\tremaining: 88.2ms\n",
      "726:\tlearn: 0.0650225\ttotal: 234ms\tremaining: 87.8ms\n",
      "727:\tlearn: 0.0648297\ttotal: 234ms\tremaining: 87.4ms\n",
      "728:\tlearn: 0.0644428\ttotal: 234ms\tremaining: 87ms\n",
      "729:\tlearn: 0.0642530\ttotal: 234ms\tremaining: 86.7ms\n",
      "730:\tlearn: 0.0640748\ttotal: 235ms\tremaining: 86.3ms\n",
      "731:\tlearn: 0.0638870\ttotal: 235ms\tremaining: 86ms\n",
      "732:\tlearn: 0.0636141\ttotal: 235ms\tremaining: 85.6ms\n",
      "733:\tlearn: 0.0634281\ttotal: 235ms\tremaining: 85.2ms\n",
      "734:\tlearn: 0.0632958\ttotal: 235ms\tremaining: 84.9ms\n",
      "735:\tlearn: 0.0631231\ttotal: 236ms\tremaining: 84.5ms\n",
      "736:\tlearn: 0.0629387\ttotal: 236ms\tremaining: 84.2ms\n",
      "737:\tlearn: 0.0628395\ttotal: 236ms\tremaining: 83.8ms\n",
      "738:\tlearn: 0.0624317\ttotal: 236ms\tremaining: 83.5ms\n",
      "739:\tlearn: 0.0622489\ttotal: 237ms\tremaining: 83.1ms\n",
      "740:\tlearn: 0.0621211\ttotal: 237ms\tremaining: 82.7ms\n",
      "741:\tlearn: 0.0619951\ttotal: 237ms\tremaining: 82.4ms\n",
      "742:\tlearn: 0.0618139\ttotal: 237ms\tremaining: 82ms\n",
      "743:\tlearn: 0.0616622\ttotal: 237ms\tremaining: 81.7ms\n",
      "744:\tlearn: 0.0612674\ttotal: 238ms\tremaining: 81.3ms\n",
      "745:\tlearn: 0.0609620\ttotal: 238ms\tremaining: 80.9ms\n",
      "746:\tlearn: 0.0607840\ttotal: 238ms\tremaining: 80.6ms\n",
      "747:\tlearn: 0.0603988\ttotal: 238ms\tremaining: 80.3ms\n",
      "748:\tlearn: 0.0600223\ttotal: 238ms\tremaining: 79.9ms\n",
      "749:\tlearn: 0.0598974\ttotal: 239ms\tremaining: 79.5ms\n",
      "750:\tlearn: 0.0597213\ttotal: 239ms\tremaining: 79.2ms\n",
      "751:\tlearn: 0.0594289\ttotal: 239ms\tremaining: 78.9ms\n",
      "752:\tlearn: 0.0590613\ttotal: 239ms\tremaining: 78.5ms\n",
      "753:\tlearn: 0.0589397\ttotal: 239ms\tremaining: 78.1ms\n",
      "754:\tlearn: 0.0585802\ttotal: 240ms\tremaining: 77.8ms\n",
      "755:\tlearn: 0.0584599\ttotal: 240ms\tremaining: 77.4ms\n",
      "756:\tlearn: 0.0583411\ttotal: 240ms\tremaining: 77.1ms\n",
      "757:\tlearn: 0.0580908\ttotal: 240ms\tremaining: 76.7ms\n",
      "758:\tlearn: 0.0579203\ttotal: 240ms\tremaining: 76.3ms\n",
      "759:\tlearn: 0.0576513\ttotal: 241ms\tremaining: 76ms\n",
      "760:\tlearn: 0.0574823\ttotal: 241ms\tremaining: 75.6ms\n",
      "761:\tlearn: 0.0572210\ttotal: 241ms\tremaining: 75.2ms\n",
      "762:\tlearn: 0.0570534\ttotal: 241ms\tremaining: 74.9ms\n",
      "763:\tlearn: 0.0567910\ttotal: 241ms\tremaining: 74.5ms\n",
      "764:\tlearn: 0.0566261\ttotal: 241ms\tremaining: 74.1ms\n",
      "765:\tlearn: 0.0564729\ttotal: 241ms\tremaining: 73.8ms\n",
      "766:\tlearn: 0.0563098\ttotal: 242ms\tremaining: 73.4ms\n",
      "767:\tlearn: 0.0559609\ttotal: 242ms\tremaining: 73ms\n",
      "768:\tlearn: 0.0556200\ttotal: 242ms\tremaining: 72.6ms\n",
      "769:\tlearn: 0.0553582\ttotal: 242ms\tremaining: 72.3ms\n",
      "770:\tlearn: 0.0552232\ttotal: 242ms\tremaining: 71.9ms\n",
      "771:\tlearn: 0.0550900\ttotal: 242ms\tremaining: 71.6ms\n",
      "772:\tlearn: 0.0548431\ttotal: 242ms\tremaining: 71.2ms\n",
      "773:\tlearn: 0.0546830\ttotal: 243ms\tremaining: 70.8ms\n",
      "774:\tlearn: 0.0544348\ttotal: 243ms\tremaining: 70.5ms\n",
      "775:\tlearn: 0.0541025\ttotal: 243ms\tremaining: 70.1ms\n",
      "776:\tlearn: 0.0537418\ttotal: 243ms\tremaining: 69.7ms\n",
      "777:\tlearn: 0.0533881\ttotal: 243ms\tremaining: 69.4ms\n",
      "778:\tlearn: 0.0530411\ttotal: 243ms\tremaining: 69ms\n",
      "779:\tlearn: 0.0528572\ttotal: 243ms\tremaining: 68.7ms\n",
      "780:\tlearn: 0.0525181\ttotal: 244ms\tremaining: 68.3ms\n",
      "781:\tlearn: 0.0521855\ttotal: 244ms\tremaining: 67.9ms\n",
      "782:\tlearn: 0.0519563\ttotal: 244ms\tremaining: 67.6ms\n",
      "783:\tlearn: 0.0516318\ttotal: 244ms\tremaining: 67.2ms\n",
      "784:\tlearn: 0.0513320\ttotal: 244ms\tremaining: 66.9ms\n",
      "785:\tlearn: 0.0510887\ttotal: 244ms\tremaining: 66.5ms\n",
      "786:\tlearn: 0.0507756\ttotal: 244ms\tremaining: 66.1ms\n",
      "787:\tlearn: 0.0504685\ttotal: 245ms\tremaining: 65.8ms\n",
      "788:\tlearn: 0.0503227\ttotal: 245ms\tremaining: 65.4ms\n",
      "789:\tlearn: 0.0500219\ttotal: 245ms\tremaining: 65.1ms\n",
      "790:\tlearn: 0.0498792\ttotal: 245ms\tremaining: 64.7ms\n",
      "791:\tlearn: 0.0497391\ttotal: 245ms\tremaining: 64.4ms\n",
      "792:\tlearn: 0.0494449\ttotal: 245ms\tremaining: 64ms\n",
      "793:\tlearn: 0.0493077\ttotal: 246ms\tremaining: 63.7ms\n",
      "794:\tlearn: 0.0490196\ttotal: 246ms\tremaining: 63.4ms\n",
      "795:\tlearn: 0.0488853\ttotal: 246ms\tremaining: 63.1ms\n",
      "796:\tlearn: 0.0487584\ttotal: 246ms\tremaining: 62.7ms\n",
      "797:\tlearn: 0.0485903\ttotal: 246ms\tremaining: 62.4ms\n",
      "798:\tlearn: 0.0484094\ttotal: 247ms\tremaining: 62.1ms\n",
      "799:\tlearn: 0.0482563\ttotal: 247ms\tremaining: 61.7ms\n",
      "800:\tlearn: 0.0481261\ttotal: 247ms\tremaining: 61.4ms\n",
      "801:\tlearn: 0.0480032\ttotal: 247ms\tremaining: 61ms\n",
      "802:\tlearn: 0.0478520\ttotal: 248ms\tremaining: 60.7ms\n",
      "803:\tlearn: 0.0477257\ttotal: 248ms\tremaining: 60.4ms\n",
      "804:\tlearn: 0.0475323\ttotal: 248ms\tremaining: 60.1ms\n",
      "805:\tlearn: 0.0474126\ttotal: 248ms\tremaining: 59.7ms\n",
      "806:\tlearn: 0.0472223\ttotal: 248ms\tremaining: 59.4ms\n",
      "807:\tlearn: 0.0470366\ttotal: 249ms\tremaining: 59.1ms\n",
      "808:\tlearn: 0.0469152\ttotal: 249ms\tremaining: 58.8ms\n",
      "809:\tlearn: 0.0467292\ttotal: 249ms\tremaining: 58.4ms\n",
      "810:\tlearn: 0.0466132\ttotal: 249ms\tremaining: 58.1ms\n",
      "811:\tlearn: 0.0464303\ttotal: 250ms\tremaining: 57.8ms\n",
      "812:\tlearn: 0.0463158\ttotal: 250ms\tremaining: 57.4ms\n",
      "813:\tlearn: 0.0461358\ttotal: 250ms\tremaining: 57.1ms\n",
      "814:\tlearn: 0.0460193\ttotal: 250ms\tremaining: 56.8ms\n",
      "815:\tlearn: 0.0458425\ttotal: 250ms\tremaining: 56.5ms\n",
      "816:\tlearn: 0.0456684\ttotal: 251ms\tremaining: 56.1ms\n",
      "817:\tlearn: 0.0455575\ttotal: 251ms\tremaining: 55.8ms\n",
      "818:\tlearn: 0.0454284\ttotal: 251ms\tremaining: 55.5ms\n",
      "819:\tlearn: 0.0451727\ttotal: 251ms\tremaining: 55.1ms\n",
      "820:\tlearn: 0.0449887\ttotal: 251ms\tremaining: 54.8ms\n",
      "821:\tlearn: 0.0447702\ttotal: 252ms\tremaining: 54.5ms\n",
      "822:\tlearn: 0.0445553\ttotal: 252ms\tremaining: 54.2ms\n",
      "823:\tlearn: 0.0443767\ttotal: 252ms\tremaining: 53.8ms\n",
      "824:\tlearn: 0.0441664\ttotal: 252ms\tremaining: 53.5ms\n",
      "825:\tlearn: 0.0439465\ttotal: 253ms\tremaining: 53.2ms\n",
      "826:\tlearn: 0.0437807\ttotal: 253ms\tremaining: 52.9ms\n",
      "827:\tlearn: 0.0436178\ttotal: 253ms\tremaining: 52.5ms\n",
      "828:\tlearn: 0.0434578\ttotal: 253ms\tremaining: 52.2ms\n",
      "829:\tlearn: 0.0433466\ttotal: 253ms\tremaining: 51.9ms\n",
      "830:\tlearn: 0.0431894\ttotal: 253ms\tremaining: 51.5ms\n",
      "831:\tlearn: 0.0430802\ttotal: 254ms\tremaining: 51.3ms\n",
      "832:\tlearn: 0.0429257\ttotal: 254ms\tremaining: 50.9ms\n",
      "833:\tlearn: 0.0428052\ttotal: 254ms\tremaining: 50.6ms\n",
      "834:\tlearn: 0.0426981\ttotal: 254ms\tremaining: 50.3ms\n",
      "835:\tlearn: 0.0425472\ttotal: 255ms\tremaining: 50ms\n",
      "836:\tlearn: 0.0424297\ttotal: 255ms\tremaining: 49.6ms\n",
      "837:\tlearn: 0.0423246\ttotal: 255ms\tremaining: 49.3ms\n",
      "838:\tlearn: 0.0421772\ttotal: 255ms\tremaining: 49ms\n",
      "839:\tlearn: 0.0420627\ttotal: 255ms\tremaining: 48.7ms\n",
      "840:\tlearn: 0.0419584\ttotal: 256ms\tremaining: 48.4ms\n",
      "841:\tlearn: 0.0418142\ttotal: 256ms\tremaining: 48ms\n",
      "842:\tlearn: 0.0417113\ttotal: 256ms\tremaining: 47.7ms\n",
      "843:\tlearn: 0.0415694\ttotal: 256ms\tremaining: 47.4ms\n",
      "844:\tlearn: 0.0414376\ttotal: 257ms\tremaining: 47.1ms\n",
      "845:\tlearn: 0.0412985\ttotal: 257ms\tremaining: 46.7ms\n",
      "846:\tlearn: 0.0411700\ttotal: 257ms\tremaining: 46.4ms\n",
      "847:\tlearn: 0.0410336\ttotal: 257ms\tremaining: 46.1ms\n",
      "848:\tlearn: 0.0409326\ttotal: 257ms\tremaining: 45.7ms\n",
      "849:\tlearn: 0.0408078\ttotal: 257ms\tremaining: 45.4ms\n",
      "850:\tlearn: 0.0406738\ttotal: 257ms\tremaining: 45.1ms\n",
      "851:\tlearn: 0.0405520\ttotal: 257ms\tremaining: 44.7ms\n",
      "852:\tlearn: 0.0404207\ttotal: 258ms\tremaining: 44.4ms\n",
      "853:\tlearn: 0.0403019\ttotal: 258ms\tremaining: 44.1ms\n",
      "854:\tlearn: 0.0401857\ttotal: 258ms\tremaining: 43.7ms\n",
      "855:\tlearn: 0.0400571\ttotal: 258ms\tremaining: 43.4ms\n",
      "856:\tlearn: 0.0399558\ttotal: 258ms\tremaining: 43.1ms\n",
      "857:\tlearn: 0.0398433\ttotal: 258ms\tremaining: 42.8ms\n",
      "858:\tlearn: 0.0397598\ttotal: 258ms\tremaining: 42.4ms\n",
      "859:\tlearn: 0.0396501\ttotal: 259ms\tremaining: 42.1ms\n",
      "860:\tlearn: 0.0395136\ttotal: 259ms\tremaining: 41.8ms\n",
      "861:\tlearn: 0.0394073\ttotal: 259ms\tremaining: 41.5ms\n",
      "862:\tlearn: 0.0392006\ttotal: 259ms\tremaining: 41.1ms\n",
      "863:\tlearn: 0.0390743\ttotal: 259ms\tremaining: 40.8ms\n",
      "864:\tlearn: 0.0388691\ttotal: 259ms\tremaining: 40.5ms\n",
      "865:\tlearn: 0.0386676\ttotal: 259ms\tremaining: 40.2ms\n",
      "866:\tlearn: 0.0384971\ttotal: 260ms\tremaining: 39.8ms\n",
      "867:\tlearn: 0.0384214\ttotal: 260ms\tremaining: 39.5ms\n",
      "868:\tlearn: 0.0382319\ttotal: 260ms\tremaining: 39.2ms\n",
      "869:\tlearn: 0.0381574\ttotal: 260ms\tremaining: 38.9ms\n",
      "870:\tlearn: 0.0379902\ttotal: 260ms\tremaining: 38.6ms\n",
      "871:\tlearn: 0.0378630\ttotal: 261ms\tremaining: 38.3ms\n",
      "872:\tlearn: 0.0376989\ttotal: 261ms\tremaining: 37.9ms\n",
      "873:\tlearn: 0.0376148\ttotal: 261ms\tremaining: 37.6ms\n",
      "874:\tlearn: 0.0374302\ttotal: 261ms\tremaining: 37.3ms\n",
      "875:\tlearn: 0.0373579\ttotal: 261ms\tremaining: 37ms\n",
      "876:\tlearn: 0.0371971\ttotal: 262ms\tremaining: 36.7ms\n",
      "877:\tlearn: 0.0371152\ttotal: 262ms\tremaining: 36.4ms\n",
      "878:\tlearn: 0.0369345\ttotal: 262ms\tremaining: 36.1ms\n",
      "879:\tlearn: 0.0368639\ttotal: 262ms\tremaining: 35.8ms\n",
      "880:\tlearn: 0.0367063\ttotal: 263ms\tremaining: 35.5ms\n",
      "881:\tlearn: 0.0366368\ttotal: 263ms\tremaining: 35.1ms\n",
      "882:\tlearn: 0.0364875\ttotal: 263ms\tremaining: 34.8ms\n",
      "883:\tlearn: 0.0364085\ttotal: 263ms\tremaining: 34.5ms\n",
      "884:\tlearn: 0.0362231\ttotal: 263ms\tremaining: 34.2ms\n",
      "885:\tlearn: 0.0360771\ttotal: 263ms\tremaining: 33.9ms\n",
      "886:\tlearn: 0.0360094\ttotal: 263ms\tremaining: 33.6ms\n",
      "887:\tlearn: 0.0358633\ttotal: 264ms\tremaining: 33.2ms\n",
      "888:\tlearn: 0.0357188\ttotal: 264ms\tremaining: 32.9ms\n",
      "889:\tlearn: 0.0355764\ttotal: 264ms\tremaining: 32.6ms\n",
      "890:\tlearn: 0.0354761\ttotal: 264ms\tremaining: 32.3ms\n",
      "891:\tlearn: 0.0353019\ttotal: 264ms\tremaining: 32ms\n",
      "892:\tlearn: 0.0351465\ttotal: 264ms\tremaining: 31.7ms\n",
      "893:\tlearn: 0.0350065\ttotal: 264ms\tremaining: 31.3ms\n",
      "894:\tlearn: 0.0349041\ttotal: 265ms\tremaining: 31ms\n",
      "895:\tlearn: 0.0347820\ttotal: 265ms\tremaining: 30.7ms\n",
      "896:\tlearn: 0.0346448\ttotal: 265ms\tremaining: 30.4ms\n",
      "897:\tlearn: 0.0345445\ttotal: 265ms\tremaining: 30.1ms\n",
      "898:\tlearn: 0.0344247\ttotal: 265ms\tremaining: 29.8ms\n",
      "899:\tlearn: 0.0342566\ttotal: 265ms\tremaining: 29.5ms\n",
      "900:\tlearn: 0.0341587\ttotal: 265ms\tremaining: 29.2ms\n",
      "901:\tlearn: 0.0340402\ttotal: 266ms\tremaining: 28.8ms\n",
      "902:\tlearn: 0.0339494\ttotal: 266ms\tremaining: 28.5ms\n",
      "903:\tlearn: 0.0337864\ttotal: 266ms\tremaining: 28.2ms\n",
      "904:\tlearn: 0.0336793\ttotal: 266ms\tremaining: 27.9ms\n",
      "905:\tlearn: 0.0335617\ttotal: 266ms\tremaining: 27.6ms\n",
      "906:\tlearn: 0.0335027\ttotal: 266ms\tremaining: 27.3ms\n",
      "907:\tlearn: 0.0333863\ttotal: 266ms\tremaining: 27ms\n",
      "908:\tlearn: 0.0332989\ttotal: 267ms\tremaining: 26.7ms\n",
      "909:\tlearn: 0.0331414\ttotal: 267ms\tremaining: 26.4ms\n",
      "910:\tlearn: 0.0330394\ttotal: 267ms\tremaining: 26.1ms\n",
      "911:\tlearn: 0.0329076\ttotal: 267ms\tremaining: 25.8ms\n",
      "912:\tlearn: 0.0328053\ttotal: 267ms\tremaining: 25.5ms\n",
      "913:\tlearn: 0.0326751\ttotal: 267ms\tremaining: 25.1ms\n",
      "914:\tlearn: 0.0326176\ttotal: 267ms\tremaining: 24.8ms\n",
      "915:\tlearn: 0.0325039\ttotal: 268ms\tremaining: 24.5ms\n",
      "916:\tlearn: 0.0323758\ttotal: 268ms\tremaining: 24.2ms\n",
      "917:\tlearn: 0.0322482\ttotal: 268ms\tremaining: 23.9ms\n",
      "918:\tlearn: 0.0321888\ttotal: 268ms\tremaining: 23.6ms\n",
      "919:\tlearn: 0.0320627\ttotal: 268ms\tremaining: 23.3ms\n",
      "920:\tlearn: 0.0319389\ttotal: 268ms\tremaining: 23ms\n",
      "921:\tlearn: 0.0318341\ttotal: 268ms\tremaining: 22.7ms\n",
      "922:\tlearn: 0.0317307\ttotal: 269ms\tremaining: 22.4ms\n",
      "923:\tlearn: 0.0316095\ttotal: 269ms\tremaining: 22.1ms\n",
      "924:\tlearn: 0.0315071\ttotal: 269ms\tremaining: 21.8ms\n",
      "925:\tlearn: 0.0314059\ttotal: 269ms\tremaining: 21.5ms\n",
      "926:\tlearn: 0.0313543\ttotal: 269ms\tremaining: 21.2ms\n",
      "927:\tlearn: 0.0312543\ttotal: 270ms\tremaining: 20.9ms\n",
      "928:\tlearn: 0.0312034\ttotal: 270ms\tremaining: 20.6ms\n",
      "929:\tlearn: 0.0311046\ttotal: 270ms\tremaining: 20.3ms\n",
      "930:\tlearn: 0.0310076\ttotal: 270ms\tremaining: 20ms\n",
      "931:\tlearn: 0.0309577\ttotal: 270ms\tremaining: 19.7ms\n",
      "932:\tlearn: 0.0308512\ttotal: 270ms\tremaining: 19.4ms\n",
      "933:\tlearn: 0.0308020\ttotal: 270ms\tremaining: 19.1ms\n",
      "934:\tlearn: 0.0307050\ttotal: 271ms\tremaining: 18.8ms\n",
      "935:\tlearn: 0.0304641\ttotal: 271ms\tremaining: 18.5ms\n",
      "936:\tlearn: 0.0303400\ttotal: 271ms\tremaining: 18.2ms\n",
      "937:\tlearn: 0.0302172\ttotal: 271ms\tremaining: 17.9ms\n",
      "938:\tlearn: 0.0300958\ttotal: 271ms\tremaining: 17.6ms\n",
      "939:\tlearn: 0.0299757\ttotal: 271ms\tremaining: 17.3ms\n",
      "940:\tlearn: 0.0298818\ttotal: 271ms\tremaining: 17ms\n",
      "941:\tlearn: 0.0297634\ttotal: 272ms\tremaining: 16.7ms\n",
      "942:\tlearn: 0.0296490\ttotal: 272ms\tremaining: 16.4ms\n",
      "943:\tlearn: 0.0295564\ttotal: 272ms\tremaining: 16.1ms\n",
      "944:\tlearn: 0.0294648\ttotal: 272ms\tremaining: 15.8ms\n",
      "945:\tlearn: 0.0293745\ttotal: 272ms\tremaining: 15.5ms\n",
      "946:\tlearn: 0.0292623\ttotal: 272ms\tremaining: 15.2ms\n",
      "947:\tlearn: 0.0291729\ttotal: 272ms\tremaining: 14.9ms\n",
      "948:\tlearn: 0.0290845\ttotal: 273ms\tremaining: 14.7ms\n",
      "949:\tlearn: 0.0290368\ttotal: 273ms\tremaining: 14.4ms\n",
      "950:\tlearn: 0.0289495\ttotal: 273ms\tremaining: 14.1ms\n",
      "951:\tlearn: 0.0289048\ttotal: 273ms\tremaining: 13.8ms\n",
      "952:\tlearn: 0.0288185\ttotal: 273ms\tremaining: 13.5ms\n",
      "953:\tlearn: 0.0287743\ttotal: 273ms\tremaining: 13.2ms\n",
      "954:\tlearn: 0.0286888\ttotal: 273ms\tremaining: 12.9ms\n",
      "955:\tlearn: 0.0285363\ttotal: 274ms\tremaining: 12.6ms\n",
      "956:\tlearn: 0.0284522\ttotal: 274ms\tremaining: 12.3ms\n",
      "957:\tlearn: 0.0283692\ttotal: 274ms\tremaining: 12ms\n",
      "958:\tlearn: 0.0282795\ttotal: 274ms\tremaining: 11.7ms\n",
      "959:\tlearn: 0.0281056\ttotal: 274ms\tremaining: 11.4ms\n",
      "960:\tlearn: 0.0280433\ttotal: 274ms\tremaining: 11.1ms\n",
      "961:\tlearn: 0.0278733\ttotal: 274ms\tremaining: 10.8ms\n",
      "962:\tlearn: 0.0278121\ttotal: 275ms\tremaining: 10.5ms\n",
      "963:\tlearn: 0.0277516\ttotal: 275ms\tremaining: 10.3ms\n",
      "964:\tlearn: 0.0276918\ttotal: 275ms\tremaining: 9.97ms\n",
      "965:\tlearn: 0.0275226\ttotal: 275ms\tremaining: 9.68ms\n",
      "966:\tlearn: 0.0274638\ttotal: 275ms\tremaining: 9.39ms\n",
      "967:\tlearn: 0.0273200\ttotal: 275ms\tremaining: 9.11ms\n",
      "968:\tlearn: 0.0271540\ttotal: 276ms\tremaining: 8.82ms\n",
      "969:\tlearn: 0.0270133\ttotal: 276ms\tremaining: 8.53ms\n",
      "970:\tlearn: 0.0268783\ttotal: 276ms\tremaining: 8.25ms\n",
      "971:\tlearn: 0.0267462\ttotal: 276ms\tremaining: 7.96ms\n",
      "972:\tlearn: 0.0266094\ttotal: 277ms\tremaining: 7.67ms\n",
      "973:\tlearn: 0.0264807\ttotal: 277ms\tremaining: 7.39ms\n",
      "974:\tlearn: 0.0263547\ttotal: 277ms\tremaining: 7.1ms\n",
      "975:\tlearn: 0.0262313\ttotal: 277ms\tremaining: 6.81ms\n",
      "976:\tlearn: 0.0261104\ttotal: 277ms\tremaining: 6.53ms\n",
      "977:\tlearn: 0.0259789\ttotal: 277ms\tremaining: 6.24ms\n",
      "978:\tlearn: 0.0258680\ttotal: 277ms\tremaining: 5.95ms\n",
      "979:\tlearn: 0.0257395\ttotal: 278ms\tremaining: 5.67ms\n",
      "980:\tlearn: 0.0256175\ttotal: 278ms\tremaining: 5.38ms\n",
      "981:\tlearn: 0.0255693\ttotal: 278ms\tremaining: 5.09ms\n",
      "982:\tlearn: 0.0255218\ttotal: 278ms\tremaining: 4.81ms\n",
      "983:\tlearn: 0.0254137\ttotal: 278ms\tremaining: 4.52ms\n",
      "984:\tlearn: 0.0253667\ttotal: 278ms\tremaining: 4.24ms\n",
      "985:\tlearn: 0.0253064\ttotal: 278ms\tremaining: 3.95ms\n",
      "986:\tlearn: 0.0251884\ttotal: 279ms\tremaining: 3.67ms\n",
      "987:\tlearn: 0.0251427\ttotal: 279ms\tremaining: 3.39ms\n",
      "988:\tlearn: 0.0250974\ttotal: 279ms\tremaining: 3.1ms\n",
      "989:\tlearn: 0.0250528\ttotal: 279ms\tremaining: 2.82ms\n",
      "990:\tlearn: 0.0249356\ttotal: 279ms\tremaining: 2.54ms\n",
      "991:\tlearn: 0.0248121\ttotal: 279ms\tremaining: 2.25ms\n",
      "992:\tlearn: 0.0247606\ttotal: 280ms\tremaining: 1.97ms\n",
      "993:\tlearn: 0.0246394\ttotal: 280ms\tremaining: 1.69ms\n",
      "994:\tlearn: 0.0245352\ttotal: 280ms\tremaining: 1.41ms\n",
      "995:\tlearn: 0.0244167\ttotal: 280ms\tremaining: 1.12ms\n",
      "996:\tlearn: 0.0243146\ttotal: 280ms\tremaining: 842us\n",
      "997:\tlearn: 0.0242706\ttotal: 280ms\tremaining: 561us\n",
      "998:\tlearn: 0.0241513\ttotal: 280ms\tremaining: 280us\n",
      "999:\tlearn: 0.0241083\ttotal: 281ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Run the algorithms ... create metrics and plots\n",
    "for algorithm_name, algorithm in algorithms.items():\n",
    "\n",
    "    # Train model\n",
    "    algorithm.fit(X_train, y_train)\n",
    "\n",
    "    # Train predictions\n",
    "    y_train_pred = algorithm.predict(X_train)\n",
    "\n",
    "    # Test predictions\n",
    "    y_test_pred = algorithm.predict(X_test)\n",
    "\n",
    "    # Train metrics\n",
    "    r2_train = algorithm.score(X_train, y_train)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    # Test metrics\n",
    "    r2_test = algorithm.score(X_test, y_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "    # Additional metrics using statsmodels for all algorithms\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    residuals_test = y_test - y_test_pred\n",
    "\n",
    "    durbin_watson_stat_train = sm.stats.durbin_watson(residuals_train)\n",
    "    jb_stat_train, jb_p_value_train, _, _ = sm.stats.jarque_bera(residuals_train)\n",
    "\n",
    "    durbin_watson_stat_test = sm.stats.durbin_watson(residuals_test)\n",
    "    jb_stat_test, jb_p_value_test, _, _ = sm.stats.jarque_bera(residuals_test)\n",
    "\n",
    "    # Update metric tables\n",
    "    metric_table_train.at[algorithm_name, 'MAE'] = mae_train\n",
    "    metric_table_train.at[algorithm_name, 'R-squared'] = r2_train\n",
    "    metric_table_train.at[algorithm_name, 'MSE'] = mse_train\n",
    "    metric_table_train.at[algorithm_name, 'Durbin-Watson'] = durbin_watson_stat_train\n",
    "    metric_table_train.at[algorithm_name, 'Jarque-Bera'] = jb_stat_train\n",
    "    metric_table_train.at[algorithm_name, 'JB P-value'] = jb_p_value_train\n",
    "\n",
    "    metric_table_test.at[algorithm_name, 'MAE'] = mae_test\n",
    "    metric_table_test.at[algorithm_name, 'R-squared'] = r2_test\n",
    "    metric_table_test.at[algorithm_name, 'MSE'] = mse_test\n",
    "    metric_table_test.at[algorithm_name, 'Durbin-Watson'] = durbin_watson_stat_test\n",
    "    metric_table_test.at[algorithm_name, 'Jarque-Bera'] = jb_stat_test\n",
    "    metric_table_test.at[algorithm_name, 'JB P-value'] = jb_p_value_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics - Train Data:\n",
      "\n",
      "                             MAE  R-squared           MSE  Durbin-Watson  Jarque-Bera  JB P-value\n",
      "Linear Regression       1.063210   0.524669  1.993781e+00       1.805952     3.304594    0.191609\n",
      "SVM Regression          1.659379   0.006534  4.167102e+00       2.160462     1.546792    0.461443\n",
      "RandomForest            0.518348   0.902557  4.087245e-01       2.046413     1.520581    0.467530\n",
      "Gradient Boost          0.097018   0.996643  1.408186e-02       1.685949     0.556744    0.757015\n",
      "knn                     1.535455   0.195645  3.373873e+00       2.005720     0.549904    0.759609\n",
      "LGBM                    1.019968   0.591431  1.713745e+00       2.165197     1.670418    0.433784\n",
      "CatBoost                0.019508   0.999861  5.812096e-04       2.079517     2.621409    0.269630\n",
      "Kernel Ridge Regressor  1.191355   0.457044  2.277433e+00       1.801973     2.534097    0.281662\n",
      "Elastic Net             1.335692   0.350977  2.722334e+00       2.007490     2.512784    0.284679\n",
      "Bayesian Ridge          1.340098   0.341698  2.761252e+00       2.026687     1.844689    0.397586\n",
      "XG Boost                0.000425   1.000000  3.598999e-07       2.025507     9.256556    0.009772\n",
      "-------------------------------------------------\n",
      "Metrics - Test Data:\n",
      "\n",
      "                             MAE  R-squared       MSE  Durbin-Watson  Jarque-Bera  JB P-value\n",
      "Linear Regression       1.368004   0.242284  2.913016       1.633835     0.436373    0.803976\n",
      "SVM Regression          1.717834  -0.215742  4.673887       1.229545     0.586127    0.745975\n",
      "RandomForest            1.211207   0.390853  2.341848       1.791718     0.175631    0.915930\n",
      "Gradient Boost          1.229399   0.331811  2.568834       1.714354     0.288211    0.865796\n",
      "knn                     1.474483  -0.048772  4.031972       1.095800     0.591292    0.744051\n",
      "LGBM                    1.311901   0.254226  2.867108       1.695553     0.377232    0.828105\n",
      "CatBoost                1.245639   0.311006  2.648816       1.528213     0.064924    0.968059\n",
      "Kernel Ridge Regressor  1.284958   0.275819  2.784091       1.695446     0.019228    0.990432\n",
      "Elastic Net             1.426441   0.116192  3.397774       1.624416     0.014768    0.992643\n",
      "Bayesian Ridge          1.413371   0.124262  3.366750       1.580646     0.027070    0.986556\n",
      "XG Boost                1.444475   0.202582  3.065650       1.605093     0.574822    0.750203\n"
     ]
    }
   ],
   "source": [
    "# Display metrics in tables\n",
    "print(\"Metrics - Train Data:\\n\")\n",
    "print(metric_table_train.to_string())\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"Metrics - Test Data:\\n\")\n",
    "print(metric_table_test.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bd141\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bd141_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_bd141_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bd141_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_bd141_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bd141_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_bd141_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bd141_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_bd141_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bd141_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_bd141_row3_col1\" class=\"data row3 col1\" >(95, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bd141_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_bd141_row4_col1\" class=\"data row4 col1\" >(95, 13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_bd141_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_bd141_row5_col1\" class=\"data row5 col1\" >(66, 13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_bd141_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_bd141_row6_col1\" class=\"data row6 col1\" >(29, 13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_bd141_row7_col0\" class=\"data row7 col0\" >Ignore features</td>\n",
       "      <td id=\"T_bd141_row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd141_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_bd141_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_bd141_row8_col1\" class=\"data row8 col1\" >12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f913e0ed9c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "s = setup(complete_data, target='label', ignore_features=['number'], preprocess=False, session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ea766 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ea766_row0_col0, #T_ea766_row0_col1, #T_ea766_row0_col2, #T_ea766_row0_col3, #T_ea766_row0_col5, #T_ea766_row0_col6, #T_ea766_row1_col0, #T_ea766_row1_col1, #T_ea766_row1_col2, #T_ea766_row1_col3, #T_ea766_row1_col4, #T_ea766_row1_col5, #T_ea766_row1_col6, #T_ea766_row2_col0, #T_ea766_row2_col4, #T_ea766_row3_col0, #T_ea766_row3_col1, #T_ea766_row3_col2, #T_ea766_row3_col3, #T_ea766_row3_col4, #T_ea766_row3_col5, #T_ea766_row3_col6, #T_ea766_row4_col0, #T_ea766_row4_col1, #T_ea766_row4_col2, #T_ea766_row4_col3, #T_ea766_row4_col4, #T_ea766_row4_col5, #T_ea766_row4_col6, #T_ea766_row5_col0, #T_ea766_row5_col1, #T_ea766_row5_col2, #T_ea766_row5_col3, #T_ea766_row5_col4, #T_ea766_row5_col5, #T_ea766_row5_col6, #T_ea766_row6_col0, #T_ea766_row6_col1, #T_ea766_row6_col2, #T_ea766_row6_col3, #T_ea766_row6_col4, #T_ea766_row6_col5, #T_ea766_row6_col6, #T_ea766_row7_col0, #T_ea766_row7_col1, #T_ea766_row7_col2, #T_ea766_row7_col3, #T_ea766_row7_col4, #T_ea766_row7_col5, #T_ea766_row7_col6, #T_ea766_row8_col0, #T_ea766_row8_col1, #T_ea766_row8_col2, #T_ea766_row8_col3, #T_ea766_row8_col4, #T_ea766_row8_col5, #T_ea766_row8_col6, #T_ea766_row9_col0, #T_ea766_row9_col1, #T_ea766_row9_col2, #T_ea766_row9_col3, #T_ea766_row9_col4, #T_ea766_row9_col5, #T_ea766_row9_col6, #T_ea766_row10_col0, #T_ea766_row10_col1, #T_ea766_row10_col2, #T_ea766_row10_col3, #T_ea766_row10_col4, #T_ea766_row10_col5, #T_ea766_row10_col6, #T_ea766_row11_col0, #T_ea766_row11_col1, #T_ea766_row11_col2, #T_ea766_row11_col3, #T_ea766_row11_col4, #T_ea766_row11_col5, #T_ea766_row11_col6, #T_ea766_row12_col0, #T_ea766_row12_col1, #T_ea766_row12_col2, #T_ea766_row12_col3, #T_ea766_row12_col4, #T_ea766_row12_col5, #T_ea766_row12_col6, #T_ea766_row13_col0, #T_ea766_row13_col1, #T_ea766_row13_col2, #T_ea766_row13_col3, #T_ea766_row13_col4, #T_ea766_row13_col5, #T_ea766_row13_col6, #T_ea766_row14_col0, #T_ea766_row14_col1, #T_ea766_row14_col2, #T_ea766_row14_col3, #T_ea766_row14_col4, #T_ea766_row14_col5, #T_ea766_row14_col6, #T_ea766_row15_col0, #T_ea766_row15_col1, #T_ea766_row15_col2, #T_ea766_row15_col3, #T_ea766_row15_col4, #T_ea766_row15_col5, #T_ea766_row15_col6, #T_ea766_row16_col0, #T_ea766_row16_col1, #T_ea766_row16_col2, #T_ea766_row16_col3, #T_ea766_row16_col4, #T_ea766_row16_col5, #T_ea766_row16_col6, #T_ea766_row17_col0, #T_ea766_row17_col1, #T_ea766_row17_col2, #T_ea766_row17_col3, #T_ea766_row17_col4, #T_ea766_row17_col5, #T_ea766_row17_col6, #T_ea766_row18_col0, #T_ea766_row18_col1, #T_ea766_row18_col2, #T_ea766_row18_col3, #T_ea766_row18_col4, #T_ea766_row18_col5, #T_ea766_row18_col6, #T_ea766_row19_col0, #T_ea766_row19_col1, #T_ea766_row19_col2, #T_ea766_row19_col3, #T_ea766_row19_col4, #T_ea766_row19_col5, #T_ea766_row19_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ea766_row0_col4, #T_ea766_row2_col1, #T_ea766_row2_col2, #T_ea766_row2_col3, #T_ea766_row2_col5, #T_ea766_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_ea766_row0_col7, #T_ea766_row1_col7, #T_ea766_row2_col7, #T_ea766_row3_col7, #T_ea766_row4_col7, #T_ea766_row5_col7, #T_ea766_row6_col7, #T_ea766_row7_col7, #T_ea766_row8_col7, #T_ea766_row9_col7, #T_ea766_row10_col7, #T_ea766_row12_col7, #T_ea766_row14_col7, #T_ea766_row16_col7, #T_ea766_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_ea766_row11_col7, #T_ea766_row13_col7, #T_ea766_row15_col7, #T_ea766_row18_col7, #T_ea766_row19_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ea766\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ea766_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ea766_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_ea766_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_ea766_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_ea766_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_ea766_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_ea766_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_ea766_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n",
       "      <td id=\"T_ea766_row0_col0\" class=\"data row0 col0\" >CatBoost Regressor</td>\n",
       "      <td id=\"T_ea766_row0_col1\" class=\"data row0 col1\" >1.3557</td>\n",
       "      <td id=\"T_ea766_row0_col2\" class=\"data row0 col2\" >2.9166</td>\n",
       "      <td id=\"T_ea766_row0_col3\" class=\"data row0 col3\" >1.6097</td>\n",
       "      <td id=\"T_ea766_row0_col4\" class=\"data row0 col4\" >0.2896</td>\n",
       "      <td id=\"T_ea766_row0_col5\" class=\"data row0 col5\" >0.1328</td>\n",
       "      <td id=\"T_ea766_row0_col6\" class=\"data row0 col6\" >0.1249</td>\n",
       "      <td id=\"T_ea766_row0_col7\" class=\"data row0 col7\" >0.2940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row1\" class=\"row_heading level0 row1\" >et</th>\n",
       "      <td id=\"T_ea766_row1_col0\" class=\"data row1 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_ea766_row1_col1\" class=\"data row1 col1\" >1.3130</td>\n",
       "      <td id=\"T_ea766_row1_col2\" class=\"data row1 col2\" >2.8634</td>\n",
       "      <td id=\"T_ea766_row1_col3\" class=\"data row1 col3\" >1.6207</td>\n",
       "      <td id=\"T_ea766_row1_col4\" class=\"data row1 col4\" >0.2094</td>\n",
       "      <td id=\"T_ea766_row1_col5\" class=\"data row1 col5\" >0.1352</td>\n",
       "      <td id=\"T_ea766_row1_col6\" class=\"data row1 col6\" >0.1226</td>\n",
       "      <td id=\"T_ea766_row1_col7\" class=\"data row1 col7\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row2\" class=\"row_heading level0 row2\" >ada</th>\n",
       "      <td id=\"T_ea766_row2_col0\" class=\"data row2 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_ea766_row2_col1\" class=\"data row2 col1\" >1.2650</td>\n",
       "      <td id=\"T_ea766_row2_col2\" class=\"data row2 col2\" >2.5954</td>\n",
       "      <td id=\"T_ea766_row2_col3\" class=\"data row2 col3\" >1.5529</td>\n",
       "      <td id=\"T_ea766_row2_col4\" class=\"data row2 col4\" >0.1831</td>\n",
       "      <td id=\"T_ea766_row2_col5\" class=\"data row2 col5\" >0.1274</td>\n",
       "      <td id=\"T_ea766_row2_col6\" class=\"data row2 col6\" >0.1166</td>\n",
       "      <td id=\"T_ea766_row2_col7\" class=\"data row2 col7\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_ea766_row3_col0\" class=\"data row3 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_ea766_row3_col1\" class=\"data row3 col1\" >1.3223</td>\n",
       "      <td id=\"T_ea766_row3_col2\" class=\"data row3 col2\" >2.6930</td>\n",
       "      <td id=\"T_ea766_row3_col3\" class=\"data row3 col3\" >1.5742</td>\n",
       "      <td id=\"T_ea766_row3_col4\" class=\"data row3 col4\" >0.1696</td>\n",
       "      <td id=\"T_ea766_row3_col5\" class=\"data row3 col5\" >0.1302</td>\n",
       "      <td id=\"T_ea766_row3_col6\" class=\"data row3 col6\" >0.1224</td>\n",
       "      <td id=\"T_ea766_row3_col7\" class=\"data row3 col7\" >0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row4\" class=\"row_heading level0 row4\" >gbr</th>\n",
       "      <td id=\"T_ea766_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_ea766_row4_col1\" class=\"data row4 col1\" >1.3952</td>\n",
       "      <td id=\"T_ea766_row4_col2\" class=\"data row4 col2\" >2.9293</td>\n",
       "      <td id=\"T_ea766_row4_col3\" class=\"data row4 col3\" >1.6416</td>\n",
       "      <td id=\"T_ea766_row4_col4\" class=\"data row4 col4\" >0.1427</td>\n",
       "      <td id=\"T_ea766_row4_col5\" class=\"data row4 col5\" >0.1375</td>\n",
       "      <td id=\"T_ea766_row4_col6\" class=\"data row4 col6\" >0.1287</td>\n",
       "      <td id=\"T_ea766_row4_col7\" class=\"data row4 col7\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "      <td id=\"T_ea766_row5_col0\" class=\"data row5 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_ea766_row5_col1\" class=\"data row5 col1\" >1.3623</td>\n",
       "      <td id=\"T_ea766_row5_col2\" class=\"data row5 col2\" >3.0392</td>\n",
       "      <td id=\"T_ea766_row5_col3\" class=\"data row5 col3\" >1.6702</td>\n",
       "      <td id=\"T_ea766_row5_col4\" class=\"data row5 col4\" >0.1062</td>\n",
       "      <td id=\"T_ea766_row5_col5\" class=\"data row5 col5\" >0.1361</td>\n",
       "      <td id=\"T_ea766_row5_col6\" class=\"data row5 col6\" >0.1240</td>\n",
       "      <td id=\"T_ea766_row5_col7\" class=\"data row5 col7\" >0.1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row6\" class=\"row_heading level0 row6\" >huber</th>\n",
       "      <td id=\"T_ea766_row6_col0\" class=\"data row6 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_ea766_row6_col1\" class=\"data row6 col1\" >1.4067</td>\n",
       "      <td id=\"T_ea766_row6_col2\" class=\"data row6 col2\" >3.1594</td>\n",
       "      <td id=\"T_ea766_row6_col3\" class=\"data row6 col3\" >1.7074</td>\n",
       "      <td id=\"T_ea766_row6_col4\" class=\"data row6 col4\" >0.0997</td>\n",
       "      <td id=\"T_ea766_row6_col5\" class=\"data row6 col5\" >0.1391</td>\n",
       "      <td id=\"T_ea766_row6_col6\" class=\"data row6 col6\" >0.1279</td>\n",
       "      <td id=\"T_ea766_row6_col7\" class=\"data row6 col7\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row7\" class=\"row_heading level0 row7\" >lasso</th>\n",
       "      <td id=\"T_ea766_row7_col0\" class=\"data row7 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_ea766_row7_col1\" class=\"data row7 col1\" >1.4120</td>\n",
       "      <td id=\"T_ea766_row7_col2\" class=\"data row7 col2\" >3.1648</td>\n",
       "      <td id=\"T_ea766_row7_col3\" class=\"data row7 col3\" >1.7026</td>\n",
       "      <td id=\"T_ea766_row7_col4\" class=\"data row7 col4\" >0.0995</td>\n",
       "      <td id=\"T_ea766_row7_col5\" class=\"data row7 col5\" >0.1400</td>\n",
       "      <td id=\"T_ea766_row7_col6\" class=\"data row7 col6\" >0.1288</td>\n",
       "      <td id=\"T_ea766_row7_col7\" class=\"data row7 col7\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row8\" class=\"row_heading level0 row8\" >llar</th>\n",
       "      <td id=\"T_ea766_row8_col0\" class=\"data row8 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_ea766_row8_col1\" class=\"data row8 col1\" >1.4120</td>\n",
       "      <td id=\"T_ea766_row8_col2\" class=\"data row8 col2\" >3.1650</td>\n",
       "      <td id=\"T_ea766_row8_col3\" class=\"data row8 col3\" >1.7027</td>\n",
       "      <td id=\"T_ea766_row8_col4\" class=\"data row8 col4\" >0.0995</td>\n",
       "      <td id=\"T_ea766_row8_col5\" class=\"data row8 col5\" >0.1400</td>\n",
       "      <td id=\"T_ea766_row8_col6\" class=\"data row8 col6\" >0.1288</td>\n",
       "      <td id=\"T_ea766_row8_col7\" class=\"data row8 col7\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row9\" class=\"row_heading level0 row9\" >lightgbm</th>\n",
       "      <td id=\"T_ea766_row9_col0\" class=\"data row9 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_ea766_row9_col1\" class=\"data row9 col1\" >1.4247</td>\n",
       "      <td id=\"T_ea766_row9_col2\" class=\"data row9 col2\" >3.2860</td>\n",
       "      <td id=\"T_ea766_row9_col3\" class=\"data row9 col3\" >1.7117</td>\n",
       "      <td id=\"T_ea766_row9_col4\" class=\"data row9 col4\" >0.0842</td>\n",
       "      <td id=\"T_ea766_row9_col5\" class=\"data row9 col5\" >0.1402</td>\n",
       "      <td id=\"T_ea766_row9_col6\" class=\"data row9 col6\" >0.1296</td>\n",
       "      <td id=\"T_ea766_row9_col7\" class=\"data row9 col7\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row10\" class=\"row_heading level0 row10\" >en</th>\n",
       "      <td id=\"T_ea766_row10_col0\" class=\"data row10 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_ea766_row10_col1\" class=\"data row10 col1\" >1.4152</td>\n",
       "      <td id=\"T_ea766_row10_col2\" class=\"data row10 col2\" >3.1802</td>\n",
       "      <td id=\"T_ea766_row10_col3\" class=\"data row10 col3\" >1.7069</td>\n",
       "      <td id=\"T_ea766_row10_col4\" class=\"data row10 col4\" >0.0812</td>\n",
       "      <td id=\"T_ea766_row10_col5\" class=\"data row10 col5\" >0.1402</td>\n",
       "      <td id=\"T_ea766_row10_col6\" class=\"data row10 col6\" >0.1290</td>\n",
       "      <td id=\"T_ea766_row10_col7\" class=\"data row10 col7\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row11\" class=\"row_heading level0 row11\" >br</th>\n",
       "      <td id=\"T_ea766_row11_col0\" class=\"data row11 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_ea766_row11_col1\" class=\"data row11 col1\" >1.4183</td>\n",
       "      <td id=\"T_ea766_row11_col2\" class=\"data row11 col2\" >3.2425</td>\n",
       "      <td id=\"T_ea766_row11_col3\" class=\"data row11 col3\" >1.7243</td>\n",
       "      <td id=\"T_ea766_row11_col4\" class=\"data row11 col4\" >0.0768</td>\n",
       "      <td id=\"T_ea766_row11_col5\" class=\"data row11 col5\" >0.1419</td>\n",
       "      <td id=\"T_ea766_row11_col6\" class=\"data row11 col6\" >0.1295</td>\n",
       "      <td id=\"T_ea766_row11_col7\" class=\"data row11 col7\" >0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row12\" class=\"row_heading level0 row12\" >xgboost</th>\n",
       "      <td id=\"T_ea766_row12_col0\" class=\"data row12 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_ea766_row12_col1\" class=\"data row12 col1\" >1.4372</td>\n",
       "      <td id=\"T_ea766_row12_col2\" class=\"data row12 col2\" >2.9167</td>\n",
       "      <td id=\"T_ea766_row12_col3\" class=\"data row12 col3\" >1.6590</td>\n",
       "      <td id=\"T_ea766_row12_col4\" class=\"data row12 col4\" >0.0171</td>\n",
       "      <td id=\"T_ea766_row12_col5\" class=\"data row12 col5\" >0.1392</td>\n",
       "      <td id=\"T_ea766_row12_col6\" class=\"data row12 col6\" >0.1322</td>\n",
       "      <td id=\"T_ea766_row12_col7\" class=\"data row12 col7\" >0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_ea766_row13_col0\" class=\"data row13 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_ea766_row13_col1\" class=\"data row13 col1\" >1.7746</td>\n",
       "      <td id=\"T_ea766_row13_col2\" class=\"data row13 col2\" >4.5818</td>\n",
       "      <td id=\"T_ea766_row13_col3\" class=\"data row13 col3\" >2.0761</td>\n",
       "      <td id=\"T_ea766_row13_col4\" class=\"data row13 col4\" >-0.1992</td>\n",
       "      <td id=\"T_ea766_row13_col5\" class=\"data row13 col5\" >0.1700</td>\n",
       "      <td id=\"T_ea766_row13_col6\" class=\"data row13 col6\" >0.1622</td>\n",
       "      <td id=\"T_ea766_row13_col7\" class=\"data row13 col7\" >0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row14\" class=\"row_heading level0 row14\" >lr</th>\n",
       "      <td id=\"T_ea766_row14_col0\" class=\"data row14 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_ea766_row14_col1\" class=\"data row14 col1\" >1.4723</td>\n",
       "      <td id=\"T_ea766_row14_col2\" class=\"data row14 col2\" >4.4682</td>\n",
       "      <td id=\"T_ea766_row14_col3\" class=\"data row14 col3\" >1.9510</td>\n",
       "      <td id=\"T_ea766_row14_col4\" class=\"data row14 col4\" >-0.2240</td>\n",
       "      <td id=\"T_ea766_row14_col5\" class=\"data row14 col5\" >0.1695</td>\n",
       "      <td id=\"T_ea766_row14_col6\" class=\"data row14 col6\" >0.1385</td>\n",
       "      <td id=\"T_ea766_row14_col7\" class=\"data row14 col7\" >0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row15\" class=\"row_heading level0 row15\" >omp</th>\n",
       "      <td id=\"T_ea766_row15_col0\" class=\"data row15 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_ea766_row15_col1\" class=\"data row15 col1\" >1.7968</td>\n",
       "      <td id=\"T_ea766_row15_col2\" class=\"data row15 col2\" >4.6795</td>\n",
       "      <td id=\"T_ea766_row15_col3\" class=\"data row15 col3\" >2.1008</td>\n",
       "      <td id=\"T_ea766_row15_col4\" class=\"data row15 col4\" >-0.2346</td>\n",
       "      <td id=\"T_ea766_row15_col5\" class=\"data row15 col5\" >0.1721</td>\n",
       "      <td id=\"T_ea766_row15_col6\" class=\"data row15 col6\" >0.1644</td>\n",
       "      <td id=\"T_ea766_row15_col7\" class=\"data row15 col7\" >0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row16\" class=\"row_heading level0 row16\" >knn</th>\n",
       "      <td id=\"T_ea766_row16_col0\" class=\"data row16 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_ea766_row16_col1\" class=\"data row16 col1\" >1.8380</td>\n",
       "      <td id=\"T_ea766_row16_col2\" class=\"data row16 col2\" >5.3227</td>\n",
       "      <td id=\"T_ea766_row16_col3\" class=\"data row16 col3\" >2.2467</td>\n",
       "      <td id=\"T_ea766_row16_col4\" class=\"data row16 col4\" >-0.5341</td>\n",
       "      <td id=\"T_ea766_row16_col5\" class=\"data row16 col5\" >0.1838</td>\n",
       "      <td id=\"T_ea766_row16_col6\" class=\"data row16 col6\" >0.1678</td>\n",
       "      <td id=\"T_ea766_row16_col7\" class=\"data row16 col7\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row17\" class=\"row_heading level0 row17\" >dt</th>\n",
       "      <td id=\"T_ea766_row17_col0\" class=\"data row17 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_ea766_row17_col1\" class=\"data row17 col1\" >1.8081</td>\n",
       "      <td id=\"T_ea766_row17_col2\" class=\"data row17 col2\" >5.0609</td>\n",
       "      <td id=\"T_ea766_row17_col3\" class=\"data row17 col3\" >2.1207</td>\n",
       "      <td id=\"T_ea766_row17_col4\" class=\"data row17 col4\" >-0.8711</td>\n",
       "      <td id=\"T_ea766_row17_col5\" class=\"data row17 col5\" >0.1773</td>\n",
       "      <td id=\"T_ea766_row17_col6\" class=\"data row17 col6\" >0.1657</td>\n",
       "      <td id=\"T_ea766_row17_col7\" class=\"data row17 col7\" >0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row18\" class=\"row_heading level0 row18\" >par</th>\n",
       "      <td id=\"T_ea766_row18_col0\" class=\"data row18 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_ea766_row18_col1\" class=\"data row18 col1\" >2.4817</td>\n",
       "      <td id=\"T_ea766_row18_col2\" class=\"data row18 col2\" >9.0003</td>\n",
       "      <td id=\"T_ea766_row18_col3\" class=\"data row18 col3\" >2.8859</td>\n",
       "      <td id=\"T_ea766_row18_col4\" class=\"data row18 col4\" >-1.5246</td>\n",
       "      <td id=\"T_ea766_row18_col5\" class=\"data row18 col5\" >0.2405</td>\n",
       "      <td id=\"T_ea766_row18_col6\" class=\"data row18 col6\" >0.2240</td>\n",
       "      <td id=\"T_ea766_row18_col7\" class=\"data row18 col7\" >0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea766_level0_row19\" class=\"row_heading level0 row19\" >lar</th>\n",
       "      <td id=\"T_ea766_row19_col0\" class=\"data row19 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_ea766_row19_col1\" class=\"data row19 col1\" >260.3008</td>\n",
       "      <td id=\"T_ea766_row19_col2\" class=\"data row19 col2\" >3597581.6008</td>\n",
       "      <td id=\"T_ea766_row19_col3\" class=\"data row19 col3\" >607.5326</td>\n",
       "      <td id=\"T_ea766_row19_col4\" class=\"data row19 col4\" >-868388.2561</td>\n",
       "      <td id=\"T_ea766_row19_col5\" class=\"data row19 col5\" >0.8284</td>\n",
       "      <td id=\"T_ea766_row19_col6\" class=\"data row19 col6\" >31.1022</td>\n",
       "      <td id=\"T_ea766_row19_col7\" class=\"data row19 col7\" >0.0020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9142d8a6b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_r = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostRegressor object at 0x7f9138d28430>\n"
     ]
    }
   ],
   "source": [
    "print(best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d665ee69ec9149b0b1a7b21b36a4fe42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_71398\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_71398_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_71398_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_71398_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_71398_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_71398_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_71398_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_71398_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_71398_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_71398_row0_col0\" class=\"data row0 col0\" >CatBoost Regressor</td>\n",
       "      <td id=\"T_71398_row0_col1\" class=\"data row0 col1\" >1.1598</td>\n",
       "      <td id=\"T_71398_row0_col2\" class=\"data row0 col2\" >2.1582</td>\n",
       "      <td id=\"T_71398_row0_col3\" class=\"data row0 col3\" >1.4691</td>\n",
       "      <td id=\"T_71398_row0_col4\" class=\"data row0 col4\" >0.4291</td>\n",
       "      <td id=\"T_71398_row0_col5\" class=\"data row0 col5\" >0.1159</td>\n",
       "      <td id=\"T_71398_row0_col6\" class=\"data row0 col6\" >0.1009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f913e160310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_r</th>\n",
       "      <th>mean_g</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>mean_rg</th>\n",
       "      <th>HHR</th>\n",
       "      <th>Ent</th>\n",
       "      <th>B</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>G4</th>\n",
       "      <th>G5</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>175.925720</td>\n",
       "      <td>126.581451</td>\n",
       "      <td>154.250595</td>\n",
       "      <td>50.055267</td>\n",
       "      <td>0.190272</td>\n",
       "      <td>16804.599609</td>\n",
       "      <td>144.484924</td>\n",
       "      <td>7.679888</td>\n",
       "      <td>3.663984</td>\n",
       "      <td>1.346695</td>\n",
       "      <td>4.461142</td>\n",
       "      <td>200.818848</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.730712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>138.608643</td>\n",
       "      <td>77.041153</td>\n",
       "      <td>115.367226</td>\n",
       "      <td>62.658043</td>\n",
       "      <td>0.109568</td>\n",
       "      <td>13782.414062</td>\n",
       "      <td>99.836166</td>\n",
       "      <td>8.414496</td>\n",
       "      <td>4.539408</td>\n",
       "      <td>1.326535</td>\n",
       "      <td>5.021771</td>\n",
       "      <td>203.675323</td>\n",
       "      <td>13.8</td>\n",
       "      <td>12.013835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>158.704285</td>\n",
       "      <td>86.480194</td>\n",
       "      <td>126.543617</td>\n",
       "      <td>72.431419</td>\n",
       "      <td>0.270784</td>\n",
       "      <td>11816.129883</td>\n",
       "      <td>112.631630</td>\n",
       "      <td>7.364720</td>\n",
       "      <td>4.027808</td>\n",
       "      <td>1.136500</td>\n",
       "      <td>4.335993</td>\n",
       "      <td>153.293381</td>\n",
       "      <td>9.7</td>\n",
       "      <td>11.319360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>167.599197</td>\n",
       "      <td>95.245903</td>\n",
       "      <td>128.758453</td>\n",
       "      <td>72.956291</td>\n",
       "      <td>0.247920</td>\n",
       "      <td>16235.455078</td>\n",
       "      <td>120.707909</td>\n",
       "      <td>7.797136</td>\n",
       "      <td>3.970320</td>\n",
       "      <td>1.341445</td>\n",
       "      <td>4.696663</td>\n",
       "      <td>195.005295</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.395563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>168.967224</td>\n",
       "      <td>92.357147</td>\n",
       "      <td>130.296432</td>\n",
       "      <td>77.023102</td>\n",
       "      <td>0.238656</td>\n",
       "      <td>16160.344727</td>\n",
       "      <td>119.596275</td>\n",
       "      <td>7.965248</td>\n",
       "      <td>3.984880</td>\n",
       "      <td>1.349547</td>\n",
       "      <td>4.707871</td>\n",
       "      <td>188.017883</td>\n",
       "      <td>13.4</td>\n",
       "      <td>12.405707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174.038376</td>\n",
       "      <td>113.084953</td>\n",
       "      <td>149.969147</td>\n",
       "      <td>61.577065</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>16105.892578</td>\n",
       "      <td>135.513290</td>\n",
       "      <td>7.608624</td>\n",
       "      <td>3.746800</td>\n",
       "      <td>1.337888</td>\n",
       "      <td>4.442797</td>\n",
       "      <td>189.553619</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.085646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>169.107239</td>\n",
       "      <td>98.704597</td>\n",
       "      <td>135.013550</td>\n",
       "      <td>70.810814</td>\n",
       "      <td>0.147504</td>\n",
       "      <td>15583.392578</td>\n",
       "      <td>123.901398</td>\n",
       "      <td>7.465680</td>\n",
       "      <td>3.809648</td>\n",
       "      <td>1.253673</td>\n",
       "      <td>4.413886</td>\n",
       "      <td>204.016464</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.679743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>162.976715</td>\n",
       "      <td>75.856606</td>\n",
       "      <td>105.529968</td>\n",
       "      <td>88.623070</td>\n",
       "      <td>0.320928</td>\n",
       "      <td>14526.099609</td>\n",
       "      <td>104.785522</td>\n",
       "      <td>8.321152</td>\n",
       "      <td>5.164864</td>\n",
       "      <td>1.130252</td>\n",
       "      <td>4.980634</td>\n",
       "      <td>160.791092</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.728972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>153.740143</td>\n",
       "      <td>86.112801</td>\n",
       "      <td>121.020012</td>\n",
       "      <td>68.748116</td>\n",
       "      <td>0.137424</td>\n",
       "      <td>15083.416992</td>\n",
       "      <td>110.341164</td>\n",
       "      <td>8.306480</td>\n",
       "      <td>4.422640</td>\n",
       "      <td>1.350149</td>\n",
       "      <td>5.048759</td>\n",
       "      <td>201.483841</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.984407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>177.905777</td>\n",
       "      <td>123.975029</td>\n",
       "      <td>161.672729</td>\n",
       "      <td>54.421707</td>\n",
       "      <td>0.077872</td>\n",
       "      <td>16069.750000</td>\n",
       "      <td>144.409607</td>\n",
       "      <td>7.497120</td>\n",
       "      <td>3.580656</td>\n",
       "      <td>1.342270</td>\n",
       "      <td>4.405998</td>\n",
       "      <td>202.220474</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9.711666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>172.783295</td>\n",
       "      <td>133.084534</td>\n",
       "      <td>168.796432</td>\n",
       "      <td>44.377064</td>\n",
       "      <td>0.074336</td>\n",
       "      <td>16194.949219</td>\n",
       "      <td>149.047729</td>\n",
       "      <td>7.697904</td>\n",
       "      <td>3.872560</td>\n",
       "      <td>1.297648</td>\n",
       "      <td>4.496145</td>\n",
       "      <td>209.191177</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.484579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>162.069107</td>\n",
       "      <td>102.783356</td>\n",
       "      <td>141.932098</td>\n",
       "      <td>59.853676</td>\n",
       "      <td>0.115920</td>\n",
       "      <td>16559.763672</td>\n",
       "      <td>124.974556</td>\n",
       "      <td>7.771200</td>\n",
       "      <td>3.955488</td>\n",
       "      <td>1.301328</td>\n",
       "      <td>4.591011</td>\n",
       "      <td>194.547684</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.189140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>187.326706</td>\n",
       "      <td>109.675491</td>\n",
       "      <td>142.919464</td>\n",
       "      <td>78.905037</td>\n",
       "      <td>0.289536</td>\n",
       "      <td>16501.617188</td>\n",
       "      <td>136.656052</td>\n",
       "      <td>7.739552</td>\n",
       "      <td>4.132352</td>\n",
       "      <td>1.260791</td>\n",
       "      <td>4.554437</td>\n",
       "      <td>197.023972</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.973085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>161.042984</td>\n",
       "      <td>89.584312</td>\n",
       "      <td>124.399689</td>\n",
       "      <td>71.872284</td>\n",
       "      <td>0.227360</td>\n",
       "      <td>16407.742188</td>\n",
       "      <td>114.892723</td>\n",
       "      <td>8.123680</td>\n",
       "      <td>4.176384</td>\n",
       "      <td>1.342741</td>\n",
       "      <td>4.862789</td>\n",
       "      <td>182.684479</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.934044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>143.585129</td>\n",
       "      <td>82.280014</td>\n",
       "      <td>119.277916</td>\n",
       "      <td>61.903305</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>16174.514648</td>\n",
       "      <td>104.803139</td>\n",
       "      <td>8.539952</td>\n",
       "      <td>4.847280</td>\n",
       "      <td>1.282311</td>\n",
       "      <td>5.118147</td>\n",
       "      <td>193.650314</td>\n",
       "      <td>13.7</td>\n",
       "      <td>12.716135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>182.003494</td>\n",
       "      <td>121.810455</td>\n",
       "      <td>156.413620</td>\n",
       "      <td>60.917912</td>\n",
       "      <td>0.307792</td>\n",
       "      <td>16170.614258</td>\n",
       "      <td>143.766724</td>\n",
       "      <td>7.503168</td>\n",
       "      <td>3.816624</td>\n",
       "      <td>1.260384</td>\n",
       "      <td>4.436771</td>\n",
       "      <td>194.234543</td>\n",
       "      <td>11.7</td>\n",
       "      <td>11.095383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>172.090820</td>\n",
       "      <td>109.961693</td>\n",
       "      <td>145.433868</td>\n",
       "      <td>62.959633</td>\n",
       "      <td>0.104544</td>\n",
       "      <td>14135.641602</td>\n",
       "      <td>132.613571</td>\n",
       "      <td>7.387440</td>\n",
       "      <td>3.400896</td>\n",
       "      <td>1.350907</td>\n",
       "      <td>4.311368</td>\n",
       "      <td>216.402985</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.718620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>167.591919</td>\n",
       "      <td>119.042137</td>\n",
       "      <td>155.516602</td>\n",
       "      <td>49.284084</td>\n",
       "      <td>0.105408</td>\n",
       "      <td>15990.248047</td>\n",
       "      <td>137.734756</td>\n",
       "      <td>7.814672</td>\n",
       "      <td>4.012352</td>\n",
       "      <td>1.295106</td>\n",
       "      <td>4.593637</td>\n",
       "      <td>208.555420</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.345141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>171.420700</td>\n",
       "      <td>113.947998</td>\n",
       "      <td>149.083221</td>\n",
       "      <td>58.141979</td>\n",
       "      <td>0.128752</td>\n",
       "      <td>11654.578125</td>\n",
       "      <td>135.123337</td>\n",
       "      <td>9.450240</td>\n",
       "      <td>5.762848</td>\n",
       "      <td>1.240956</td>\n",
       "      <td>5.797179</td>\n",
       "      <td>170.292252</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.837523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>138.032043</td>\n",
       "      <td>64.668198</td>\n",
       "      <td>93.880859</td>\n",
       "      <td>74.397598</td>\n",
       "      <td>0.204880</td>\n",
       "      <td>15207.328125</td>\n",
       "      <td>89.965492</td>\n",
       "      <td>7.456784</td>\n",
       "      <td>3.715696</td>\n",
       "      <td>1.281333</td>\n",
       "      <td>4.417950</td>\n",
       "      <td>196.360336</td>\n",
       "      <td>14.3</td>\n",
       "      <td>12.382096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>148.967651</td>\n",
       "      <td>84.223297</td>\n",
       "      <td>124.716103</td>\n",
       "      <td>65.377151</td>\n",
       "      <td>0.128624</td>\n",
       "      <td>16221.200195</td>\n",
       "      <td>108.203285</td>\n",
       "      <td>9.011344</td>\n",
       "      <td>5.197136</td>\n",
       "      <td>1.285285</td>\n",
       "      <td>5.424688</td>\n",
       "      <td>186.141510</td>\n",
       "      <td>17.1</td>\n",
       "      <td>13.443024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>150.304230</td>\n",
       "      <td>77.287430</td>\n",
       "      <td>110.446320</td>\n",
       "      <td>73.512154</td>\n",
       "      <td>0.155584</td>\n",
       "      <td>16226.857422</td>\n",
       "      <td>102.906479</td>\n",
       "      <td>7.208336</td>\n",
       "      <td>3.524768</td>\n",
       "      <td>1.271504</td>\n",
       "      <td>4.246171</td>\n",
       "      <td>193.520599</td>\n",
       "      <td>11.2</td>\n",
       "      <td>12.098174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>116.478134</td>\n",
       "      <td>80.697281</td>\n",
       "      <td>104.621857</td>\n",
       "      <td>44.265514</td>\n",
       "      <td>0.191408</td>\n",
       "      <td>15253.376953</td>\n",
       "      <td>94.358368</td>\n",
       "      <td>7.550208</td>\n",
       "      <td>4.545760</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>4.736102</td>\n",
       "      <td>195.246109</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.349543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>160.450226</td>\n",
       "      <td>99.285355</td>\n",
       "      <td>141.965363</td>\n",
       "      <td>61.919617</td>\n",
       "      <td>0.074880</td>\n",
       "      <td>15260.442383</td>\n",
       "      <td>122.457008</td>\n",
       "      <td>8.823792</td>\n",
       "      <td>5.045024</td>\n",
       "      <td>1.284459</td>\n",
       "      <td>5.296274</td>\n",
       "      <td>208.044388</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.782734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>153.143478</td>\n",
       "      <td>88.999878</td>\n",
       "      <td>125.723816</td>\n",
       "      <td>65.196289</td>\n",
       "      <td>0.154960</td>\n",
       "      <td>15623.010742</td>\n",
       "      <td>112.367874</td>\n",
       "      <td>8.567216</td>\n",
       "      <td>4.814560</td>\n",
       "      <td>1.322004</td>\n",
       "      <td>5.181715</td>\n",
       "      <td>197.955475</td>\n",
       "      <td>11.9</td>\n",
       "      <td>13.440616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>166.610931</td>\n",
       "      <td>95.269539</td>\n",
       "      <td>136.429520</td>\n",
       "      <td>71.720146</td>\n",
       "      <td>0.143056</td>\n",
       "      <td>14886.086914</td>\n",
       "      <td>121.307571</td>\n",
       "      <td>8.059120</td>\n",
       "      <td>4.136768</td>\n",
       "      <td>1.350224</td>\n",
       "      <td>4.785073</td>\n",
       "      <td>200.220642</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11.422693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>151.634308</td>\n",
       "      <td>104.242531</td>\n",
       "      <td>136.884018</td>\n",
       "      <td>48.814838</td>\n",
       "      <td>0.098656</td>\n",
       "      <td>15075.935547</td>\n",
       "      <td>122.139740</td>\n",
       "      <td>7.817600</td>\n",
       "      <td>3.858368</td>\n",
       "      <td>1.340805</td>\n",
       "      <td>4.678740</td>\n",
       "      <td>207.462921</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.824318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>159.340103</td>\n",
       "      <td>81.754608</td>\n",
       "      <td>118.568344</td>\n",
       "      <td>78.393295</td>\n",
       "      <td>0.128752</td>\n",
       "      <td>12140.647461</td>\n",
       "      <td>109.166695</td>\n",
       "      <td>7.453632</td>\n",
       "      <td>3.590352</td>\n",
       "      <td>1.319963</td>\n",
       "      <td>4.443782</td>\n",
       "      <td>217.051361</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.820837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>161.147034</td>\n",
       "      <td>84.156761</td>\n",
       "      <td>120.976151</td>\n",
       "      <td>77.844841</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>14728.014648</td>\n",
       "      <td>111.384903</td>\n",
       "      <td>7.602720</td>\n",
       "      <td>3.883520</td>\n",
       "      <td>1.299104</td>\n",
       "      <td>4.495942</td>\n",
       "      <td>206.186661</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.380561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_r      mean_g      mean_b    mean_rg       HHR           Ent  \\\n",
       "71  175.925720  126.581451  154.250595  50.055267  0.190272  16804.599609   \n",
       "62  138.608643   77.041153  115.367226  62.658043  0.109568  13782.414062   \n",
       "29  158.704285   86.480194  126.543617  72.431419  0.270784  11816.129883   \n",
       "53  167.599197   95.245903  128.758453  72.956291  0.247920  16235.455078   \n",
       "90  168.967224   92.357147  130.296432  77.023102  0.238656  16160.344727   \n",
       "4   174.038376  113.084953  149.969147  61.577065  0.077600  16105.892578   \n",
       "31  169.107239   98.704597  135.013550  70.810814  0.147504  15583.392578   \n",
       "77  162.976715   75.856606  105.529968  88.623070  0.320928  14526.099609   \n",
       "79  153.740143   86.112801  121.020012  68.748116  0.137424  15083.416992   \n",
       "70  177.905777  123.975029  161.672729  54.421707  0.077872  16069.750000   \n",
       "33  172.783295  133.084534  168.796432  44.377064  0.074336  16194.949219   \n",
       "51  162.069107  102.783356  141.932098  59.853676  0.115920  16559.763672   \n",
       "8   187.326706  109.675491  142.919464  78.905037  0.289536  16501.617188   \n",
       "63  161.042984   89.584312  124.399689  71.872284  0.227360  16407.742188   \n",
       "85  143.585129   82.280014  119.277916  61.903305  0.101168  16174.514648   \n",
       "35  182.003494  121.810455  156.413620  60.917912  0.307792  16170.614258   \n",
       "28  172.090820  109.961693  145.433868  62.959633  0.104544  14135.641602   \n",
       "75  167.591919  119.042137  155.516602  49.284084  0.105408  15990.248047   \n",
       "50  171.420700  113.947998  149.083221  58.141979  0.128752  11654.578125   \n",
       "41  138.032043   64.668198   93.880859  74.397598  0.204880  15207.328125   \n",
       "65  148.967651   84.223297  124.716103  65.377151  0.128624  16221.200195   \n",
       "23  150.304230   77.287430  110.446320  73.512154  0.155584  16226.857422   \n",
       "64  116.478134   80.697281  104.621857  44.265514  0.191408  15253.376953   \n",
       "56  160.450226   99.285355  141.965363  61.919617  0.074880  15260.442383   \n",
       "89  153.143478   88.999878  125.723816  65.196289  0.154960  15623.010742   \n",
       "24  166.610931   95.269539  136.429520  71.720146  0.143056  14886.086914   \n",
       "82  151.634308  104.242531  136.884018  48.814838  0.098656  15075.935547   \n",
       "9   159.340103   81.754608  118.568344  78.393295  0.128752  12140.647461   \n",
       "21  161.147034   84.156761  120.976151  77.844841  0.174960  14728.014648   \n",
       "\n",
       "             B        G1        G2        G3        G4          G5  label  \\\n",
       "71  144.484924  7.679888  3.663984  1.346695  4.461142  200.818848    9.1   \n",
       "62   99.836166  8.414496  4.539408  1.326535  5.021771  203.675323   13.8   \n",
       "29  112.631630  7.364720  4.027808  1.136500  4.335993  153.293381    9.7   \n",
       "53  120.707909  7.797136  3.970320  1.341445  4.696663  195.005295   12.5   \n",
       "90  119.596275  7.965248  3.984880  1.349547  4.707871  188.017883   13.4   \n",
       "4   135.513290  7.608624  3.746800  1.337888  4.442797  189.553619   10.6   \n",
       "31  123.901398  7.465680  3.809648  1.253673  4.413886  204.016464   11.1   \n",
       "77  104.785522  8.321152  5.164864  1.130252  4.980634  160.791092   13.0   \n",
       "79  110.341164  8.306480  4.422640  1.350149  5.048759  201.483841   11.0   \n",
       "70  144.409607  7.497120  3.580656  1.342270  4.405998  202.220474   12.3   \n",
       "33  149.047729  7.697904  3.872560  1.297648  4.496145  209.191177    8.3   \n",
       "51  124.974556  7.771200  3.955488  1.301328  4.591011  194.547684    8.8   \n",
       "8   136.656052  7.739552  4.132352  1.260791  4.554437  197.023972   11.5   \n",
       "63  114.892723  8.123680  4.176384  1.342741  4.862789  182.684479   14.0   \n",
       "85  104.803139  8.539952  4.847280  1.282311  5.118147  193.650314   13.7   \n",
       "35  143.766724  7.503168  3.816624  1.260384  4.436771  194.234543   11.7   \n",
       "28  132.613571  7.387440  3.400896  1.350907  4.311368  216.402985    8.7   \n",
       "75  137.734756  7.814672  4.012352  1.295106  4.593637  208.555420   10.3   \n",
       "50  135.123337  9.450240  5.762848  1.240956  5.797179  170.292252   10.5   \n",
       "41   89.965492  7.456784  3.715696  1.281333  4.417950  196.360336   14.3   \n",
       "65  108.203285  9.011344  5.197136  1.285285  5.424688  186.141510   17.1   \n",
       "23  102.906479  7.208336  3.524768  1.271504  4.246171  193.520599   11.2   \n",
       "64   94.358368  7.550208  4.545760  1.038370  4.736102  195.246109   12.0   \n",
       "56  122.457008  8.823792  5.045024  1.284459  5.296274  208.044388   12.2   \n",
       "89  112.367874  8.567216  4.814560  1.322004  5.181715  197.955475   11.9   \n",
       "24  121.307571  8.059120  4.136768  1.350224  4.785073  200.220642   12.6   \n",
       "82  122.139740  7.817600  3.858368  1.340805  4.678740  207.462921    9.5   \n",
       "9   109.166695  7.453632  3.590352  1.319963  4.443782  217.051361   10.1   \n",
       "21  111.384903  7.602720  3.883520  1.299104  4.495942  206.186661   12.4   \n",
       "\n",
       "    prediction_label  \n",
       "71          9.730712  \n",
       "62         12.013835  \n",
       "29         11.319360  \n",
       "53         12.395563  \n",
       "90         12.405707  \n",
       "4          11.085646  \n",
       "31         11.679743  \n",
       "77         12.728972  \n",
       "79         11.984407  \n",
       "70          9.711666  \n",
       "33         10.484579  \n",
       "51         10.189140  \n",
       "8          11.973085  \n",
       "63         11.934044  \n",
       "85         12.716135  \n",
       "35         11.095383  \n",
       "28         11.718620  \n",
       "75         10.345141  \n",
       "50         10.837523  \n",
       "41         12.382096  \n",
       "65         13.443024  \n",
       "23         12.098174  \n",
       "64         10.349543  \n",
       "56         12.782734  \n",
       "89         13.440616  \n",
       "24         11.422693  \n",
       "82          9.824318  \n",
       "9          10.820837  \n",
       "21         12.380561  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(best_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_90593_row10_col0, #T_90593_row10_col1, #T_90593_row10_col2, #T_90593_row10_col3, #T_90593_row10_col4, #T_90593_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_90593\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_90593_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_90593_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_90593_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_90593_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_90593_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_90593_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_90593_row0_col0\" class=\"data row0 col0\" >0.6608</td>\n",
       "      <td id=\"T_90593_row0_col1\" class=\"data row0 col1\" >0.8368</td>\n",
       "      <td id=\"T_90593_row0_col2\" class=\"data row0 col2\" >0.9148</td>\n",
       "      <td id=\"T_90593_row0_col3\" class=\"data row0 col3\" >-0.0470</td>\n",
       "      <td id=\"T_90593_row0_col4\" class=\"data row0 col4\" >0.0739</td>\n",
       "      <td id=\"T_90593_row0_col5\" class=\"data row0 col5\" >0.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_90593_row1_col0\" class=\"data row1 col0\" >1.0392</td>\n",
       "      <td id=\"T_90593_row1_col1\" class=\"data row1 col1\" >1.3260</td>\n",
       "      <td id=\"T_90593_row1_col2\" class=\"data row1 col2\" >1.1515</td>\n",
       "      <td id=\"T_90593_row1_col3\" class=\"data row1 col3\" >0.5269</td>\n",
       "      <td id=\"T_90593_row1_col4\" class=\"data row1 col4\" >0.1035</td>\n",
       "      <td id=\"T_90593_row1_col5\" class=\"data row1 col5\" >0.1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_90593_row2_col0\" class=\"data row2 col0\" >1.3840</td>\n",
       "      <td id=\"T_90593_row2_col1\" class=\"data row2 col1\" >3.9871</td>\n",
       "      <td id=\"T_90593_row2_col2\" class=\"data row2 col2\" >1.9968</td>\n",
       "      <td id=\"T_90593_row2_col3\" class=\"data row2 col3\" >0.0305</td>\n",
       "      <td id=\"T_90593_row2_col4\" class=\"data row2 col4\" >0.1863</td>\n",
       "      <td id=\"T_90593_row2_col5\" class=\"data row2 col5\" >0.1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_90593_row3_col0\" class=\"data row3 col0\" >1.5990</td>\n",
       "      <td id=\"T_90593_row3_col1\" class=\"data row3 col1\" >3.7668</td>\n",
       "      <td id=\"T_90593_row3_col2\" class=\"data row3 col2\" >1.9408</td>\n",
       "      <td id=\"T_90593_row3_col3\" class=\"data row3 col3\" >0.5680</td>\n",
       "      <td id=\"T_90593_row3_col4\" class=\"data row3 col4\" >0.1576</td>\n",
       "      <td id=\"T_90593_row3_col5\" class=\"data row3 col5\" >0.1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_90593_row4_col0\" class=\"data row4 col0\" >1.2905</td>\n",
       "      <td id=\"T_90593_row4_col1\" class=\"data row4 col1\" >2.3188</td>\n",
       "      <td id=\"T_90593_row4_col2\" class=\"data row4 col2\" >1.5228</td>\n",
       "      <td id=\"T_90593_row4_col3\" class=\"data row4 col3\" >0.4403</td>\n",
       "      <td id=\"T_90593_row4_col4\" class=\"data row4 col4\" >0.1339</td>\n",
       "      <td id=\"T_90593_row4_col5\" class=\"data row4 col5\" >0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_90593_row5_col0\" class=\"data row5 col0\" >0.8231</td>\n",
       "      <td id=\"T_90593_row5_col1\" class=\"data row5 col1\" >1.1801</td>\n",
       "      <td id=\"T_90593_row5_col2\" class=\"data row5 col2\" >1.0863</td>\n",
       "      <td id=\"T_90593_row5_col3\" class=\"data row5 col3\" >0.5836</td>\n",
       "      <td id=\"T_90593_row5_col4\" class=\"data row5 col4\" >0.0983</td>\n",
       "      <td id=\"T_90593_row5_col5\" class=\"data row5 col5\" >0.0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_90593_row6_col0\" class=\"data row6 col0\" >0.8861</td>\n",
       "      <td id=\"T_90593_row6_col1\" class=\"data row6 col1\" >1.2887</td>\n",
       "      <td id=\"T_90593_row6_col2\" class=\"data row6 col2\" >1.1352</td>\n",
       "      <td id=\"T_90593_row6_col3\" class=\"data row6 col3\" >0.2976</td>\n",
       "      <td id=\"T_90593_row6_col4\" class=\"data row6 col4\" >0.0862</td>\n",
       "      <td id=\"T_90593_row6_col5\" class=\"data row6 col5\" >0.0705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_90593_row7_col0\" class=\"data row7 col0\" >1.8433</td>\n",
       "      <td id=\"T_90593_row7_col1\" class=\"data row7 col1\" >3.7446</td>\n",
       "      <td id=\"T_90593_row7_col2\" class=\"data row7 col2\" >1.9351</td>\n",
       "      <td id=\"T_90593_row7_col3\" class=\"data row7 col3\" >0.4376</td>\n",
       "      <td id=\"T_90593_row7_col4\" class=\"data row7 col4\" >0.1555</td>\n",
       "      <td id=\"T_90593_row7_col5\" class=\"data row7 col5\" >0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_90593_row8_col0\" class=\"data row8 col0\" >0.9761</td>\n",
       "      <td id=\"T_90593_row8_col1\" class=\"data row8 col1\" >1.2521</td>\n",
       "      <td id=\"T_90593_row8_col2\" class=\"data row8 col2\" >1.1190</td>\n",
       "      <td id=\"T_90593_row8_col3\" class=\"data row8 col3\" >0.6469</td>\n",
       "      <td id=\"T_90593_row8_col4\" class=\"data row8 col4\" >0.0807</td>\n",
       "      <td id=\"T_90593_row8_col5\" class=\"data row8 col5\" >0.0767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_90593_row9_col0\" class=\"data row9 col0\" >1.7020</td>\n",
       "      <td id=\"T_90593_row9_col1\" class=\"data row9 col1\" >3.5913</td>\n",
       "      <td id=\"T_90593_row9_col2\" class=\"data row9 col2\" >1.8951</td>\n",
       "      <td id=\"T_90593_row9_col3\" class=\"data row9 col3\" >0.2406</td>\n",
       "      <td id=\"T_90593_row9_col4\" class=\"data row9 col4\" >0.1533</td>\n",
       "      <td id=\"T_90593_row9_col5\" class=\"data row9 col5\" >0.1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_90593_row10_col0\" class=\"data row10 col0\" >1.2204</td>\n",
       "      <td id=\"T_90593_row10_col1\" class=\"data row10 col1\" >2.3292</td>\n",
       "      <td id=\"T_90593_row10_col2\" class=\"data row10 col2\" >1.4697</td>\n",
       "      <td id=\"T_90593_row10_col3\" class=\"data row10 col3\" >0.3725</td>\n",
       "      <td id=\"T_90593_row10_col4\" class=\"data row10 col4\" >0.1229</td>\n",
       "      <td id=\"T_90593_row10_col5\" class=\"data row10 col5\" >0.1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90593_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_90593_row11_col0\" class=\"data row11 col0\" >0.3834</td>\n",
       "      <td id=\"T_90593_row11_col1\" class=\"data row11 col1\" >1.2332</td>\n",
       "      <td id=\"T_90593_row11_col2\" class=\"data row11 col2\" >0.4112</td>\n",
       "      <td id=\"T_90593_row11_col3\" class=\"data row11 col3\" >0.2251</td>\n",
       "      <td id=\"T_90593_row11_col4\" class=\"data row11 col4\" >0.0372</td>\n",
       "      <td id=\"T_90593_row11_col5\" class=\"data row11 col5\" >0.0366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9142d8bbb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "tuned_catboost = tune_model(best_r, fold = 10, n_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c412275e2b54aa4b88d4533352dbd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(tuned_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e842f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e842f_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e842f_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_e842f_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_e842f_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_e842f_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_e842f_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_e842f_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e842f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e842f_row0_col0\" class=\"data row0 col0\" >CatBoost Regressor</td>\n",
       "      <td id=\"T_e842f_row0_col1\" class=\"data row0 col1\" >1.1978</td>\n",
       "      <td id=\"T_e842f_row0_col2\" class=\"data row0 col2\" >2.2488</td>\n",
       "      <td id=\"T_e842f_row0_col3\" class=\"data row0 col3\" >1.4996</td>\n",
       "      <td id=\"T_e842f_row0_col4\" class=\"data row0 col4\" >0.4051</td>\n",
       "      <td id=\"T_e842f_row0_col5\" class=\"data row0 col5\" >0.1181</td>\n",
       "      <td id=\"T_e842f_row0_col6\" class=\"data row0 col6\" >0.1044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f90edbde710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_r</th>\n",
       "      <th>mean_g</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>mean_rg</th>\n",
       "      <th>HHR</th>\n",
       "      <th>Ent</th>\n",
       "      <th>B</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>G4</th>\n",
       "      <th>G5</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>175.925720</td>\n",
       "      <td>126.581451</td>\n",
       "      <td>154.250595</td>\n",
       "      <td>50.055267</td>\n",
       "      <td>0.190272</td>\n",
       "      <td>16804.599609</td>\n",
       "      <td>144.484924</td>\n",
       "      <td>7.679888</td>\n",
       "      <td>3.663984</td>\n",
       "      <td>1.346695</td>\n",
       "      <td>4.461142</td>\n",
       "      <td>200.818848</td>\n",
       "      <td>9.1</td>\n",
       "      <td>10.006741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>138.608643</td>\n",
       "      <td>77.041153</td>\n",
       "      <td>115.367226</td>\n",
       "      <td>62.658043</td>\n",
       "      <td>0.109568</td>\n",
       "      <td>13782.414062</td>\n",
       "      <td>99.836166</td>\n",
       "      <td>8.414496</td>\n",
       "      <td>4.539408</td>\n",
       "      <td>1.326535</td>\n",
       "      <td>5.021771</td>\n",
       "      <td>203.675323</td>\n",
       "      <td>13.8</td>\n",
       "      <td>11.671827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>158.704285</td>\n",
       "      <td>86.480194</td>\n",
       "      <td>126.543617</td>\n",
       "      <td>72.431419</td>\n",
       "      <td>0.270784</td>\n",
       "      <td>11816.129883</td>\n",
       "      <td>112.631630</td>\n",
       "      <td>7.364720</td>\n",
       "      <td>4.027808</td>\n",
       "      <td>1.136500</td>\n",
       "      <td>4.335993</td>\n",
       "      <td>153.293381</td>\n",
       "      <td>9.7</td>\n",
       "      <td>10.893827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>167.599197</td>\n",
       "      <td>95.245903</td>\n",
       "      <td>128.758453</td>\n",
       "      <td>72.956291</td>\n",
       "      <td>0.247920</td>\n",
       "      <td>16235.455078</td>\n",
       "      <td>120.707909</td>\n",
       "      <td>7.797136</td>\n",
       "      <td>3.970320</td>\n",
       "      <td>1.341445</td>\n",
       "      <td>4.696663</td>\n",
       "      <td>195.005295</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.539658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>168.967224</td>\n",
       "      <td>92.357147</td>\n",
       "      <td>130.296432</td>\n",
       "      <td>77.023102</td>\n",
       "      <td>0.238656</td>\n",
       "      <td>16160.344727</td>\n",
       "      <td>119.596275</td>\n",
       "      <td>7.965248</td>\n",
       "      <td>3.984880</td>\n",
       "      <td>1.349547</td>\n",
       "      <td>4.707871</td>\n",
       "      <td>188.017883</td>\n",
       "      <td>13.4</td>\n",
       "      <td>12.487544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174.038376</td>\n",
       "      <td>113.084953</td>\n",
       "      <td>149.969147</td>\n",
       "      <td>61.577065</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>16105.892578</td>\n",
       "      <td>135.513290</td>\n",
       "      <td>7.608624</td>\n",
       "      <td>3.746800</td>\n",
       "      <td>1.337888</td>\n",
       "      <td>4.442797</td>\n",
       "      <td>189.553619</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.800099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>169.107239</td>\n",
       "      <td>98.704597</td>\n",
       "      <td>135.013550</td>\n",
       "      <td>70.810814</td>\n",
       "      <td>0.147504</td>\n",
       "      <td>15583.392578</td>\n",
       "      <td>123.901398</td>\n",
       "      <td>7.465680</td>\n",
       "      <td>3.809648</td>\n",
       "      <td>1.253673</td>\n",
       "      <td>4.413886</td>\n",
       "      <td>204.016464</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.250892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>162.976715</td>\n",
       "      <td>75.856606</td>\n",
       "      <td>105.529968</td>\n",
       "      <td>88.623070</td>\n",
       "      <td>0.320928</td>\n",
       "      <td>14526.099609</td>\n",
       "      <td>104.785522</td>\n",
       "      <td>8.321152</td>\n",
       "      <td>5.164864</td>\n",
       "      <td>1.130252</td>\n",
       "      <td>4.980634</td>\n",
       "      <td>160.791092</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.522781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>153.740143</td>\n",
       "      <td>86.112801</td>\n",
       "      <td>121.020012</td>\n",
       "      <td>68.748116</td>\n",
       "      <td>0.137424</td>\n",
       "      <td>15083.416992</td>\n",
       "      <td>110.341164</td>\n",
       "      <td>8.306480</td>\n",
       "      <td>4.422640</td>\n",
       "      <td>1.350149</td>\n",
       "      <td>5.048759</td>\n",
       "      <td>201.483841</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.687661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>177.905777</td>\n",
       "      <td>123.975029</td>\n",
       "      <td>161.672729</td>\n",
       "      <td>54.421707</td>\n",
       "      <td>0.077872</td>\n",
       "      <td>16069.750000</td>\n",
       "      <td>144.409607</td>\n",
       "      <td>7.497120</td>\n",
       "      <td>3.580656</td>\n",
       "      <td>1.342270</td>\n",
       "      <td>4.405998</td>\n",
       "      <td>202.220474</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9.783463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>172.783295</td>\n",
       "      <td>133.084534</td>\n",
       "      <td>168.796432</td>\n",
       "      <td>44.377064</td>\n",
       "      <td>0.074336</td>\n",
       "      <td>16194.949219</td>\n",
       "      <td>149.047729</td>\n",
       "      <td>7.697904</td>\n",
       "      <td>3.872560</td>\n",
       "      <td>1.297648</td>\n",
       "      <td>4.496145</td>\n",
       "      <td>209.191177</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.876443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>162.069107</td>\n",
       "      <td>102.783356</td>\n",
       "      <td>141.932098</td>\n",
       "      <td>59.853676</td>\n",
       "      <td>0.115920</td>\n",
       "      <td>16559.763672</td>\n",
       "      <td>124.974556</td>\n",
       "      <td>7.771200</td>\n",
       "      <td>3.955488</td>\n",
       "      <td>1.301328</td>\n",
       "      <td>4.591011</td>\n",
       "      <td>194.547684</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.875788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>187.326706</td>\n",
       "      <td>109.675491</td>\n",
       "      <td>142.919464</td>\n",
       "      <td>78.905037</td>\n",
       "      <td>0.289536</td>\n",
       "      <td>16501.617188</td>\n",
       "      <td>136.656052</td>\n",
       "      <td>7.739552</td>\n",
       "      <td>4.132352</td>\n",
       "      <td>1.260791</td>\n",
       "      <td>4.554437</td>\n",
       "      <td>197.023972</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.359994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>161.042984</td>\n",
       "      <td>89.584312</td>\n",
       "      <td>124.399689</td>\n",
       "      <td>71.872284</td>\n",
       "      <td>0.227360</td>\n",
       "      <td>16407.742188</td>\n",
       "      <td>114.892723</td>\n",
       "      <td>8.123680</td>\n",
       "      <td>4.176384</td>\n",
       "      <td>1.342741</td>\n",
       "      <td>4.862789</td>\n",
       "      <td>182.684479</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.193541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>143.585129</td>\n",
       "      <td>82.280014</td>\n",
       "      <td>119.277916</td>\n",
       "      <td>61.903305</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>16174.514648</td>\n",
       "      <td>104.803139</td>\n",
       "      <td>8.539952</td>\n",
       "      <td>4.847280</td>\n",
       "      <td>1.282311</td>\n",
       "      <td>5.118147</td>\n",
       "      <td>193.650314</td>\n",
       "      <td>13.7</td>\n",
       "      <td>13.039119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>182.003494</td>\n",
       "      <td>121.810455</td>\n",
       "      <td>156.413620</td>\n",
       "      <td>60.917912</td>\n",
       "      <td>0.307792</td>\n",
       "      <td>16170.614258</td>\n",
       "      <td>143.766724</td>\n",
       "      <td>7.503168</td>\n",
       "      <td>3.816624</td>\n",
       "      <td>1.260384</td>\n",
       "      <td>4.436771</td>\n",
       "      <td>194.234543</td>\n",
       "      <td>11.7</td>\n",
       "      <td>10.700960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>172.090820</td>\n",
       "      <td>109.961693</td>\n",
       "      <td>145.433868</td>\n",
       "      <td>62.959633</td>\n",
       "      <td>0.104544</td>\n",
       "      <td>14135.641602</td>\n",
       "      <td>132.613571</td>\n",
       "      <td>7.387440</td>\n",
       "      <td>3.400896</td>\n",
       "      <td>1.350907</td>\n",
       "      <td>4.311368</td>\n",
       "      <td>216.402985</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.453603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>167.591919</td>\n",
       "      <td>119.042137</td>\n",
       "      <td>155.516602</td>\n",
       "      <td>49.284084</td>\n",
       "      <td>0.105408</td>\n",
       "      <td>15990.248047</td>\n",
       "      <td>137.734756</td>\n",
       "      <td>7.814672</td>\n",
       "      <td>4.012352</td>\n",
       "      <td>1.295106</td>\n",
       "      <td>4.593637</td>\n",
       "      <td>208.555420</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.768969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>171.420700</td>\n",
       "      <td>113.947998</td>\n",
       "      <td>149.083221</td>\n",
       "      <td>58.141979</td>\n",
       "      <td>0.128752</td>\n",
       "      <td>11654.578125</td>\n",
       "      <td>135.123337</td>\n",
       "      <td>9.450240</td>\n",
       "      <td>5.762848</td>\n",
       "      <td>1.240956</td>\n",
       "      <td>5.797179</td>\n",
       "      <td>170.292252</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.793377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>138.032043</td>\n",
       "      <td>64.668198</td>\n",
       "      <td>93.880859</td>\n",
       "      <td>74.397598</td>\n",
       "      <td>0.204880</td>\n",
       "      <td>15207.328125</td>\n",
       "      <td>89.965492</td>\n",
       "      <td>7.456784</td>\n",
       "      <td>3.715696</td>\n",
       "      <td>1.281333</td>\n",
       "      <td>4.417950</td>\n",
       "      <td>196.360336</td>\n",
       "      <td>14.3</td>\n",
       "      <td>13.245913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>148.967651</td>\n",
       "      <td>84.223297</td>\n",
       "      <td>124.716103</td>\n",
       "      <td>65.377151</td>\n",
       "      <td>0.128624</td>\n",
       "      <td>16221.200195</td>\n",
       "      <td>108.203285</td>\n",
       "      <td>9.011344</td>\n",
       "      <td>5.197136</td>\n",
       "      <td>1.285285</td>\n",
       "      <td>5.424688</td>\n",
       "      <td>186.141510</td>\n",
       "      <td>17.1</td>\n",
       "      <td>13.194889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>150.304230</td>\n",
       "      <td>77.287430</td>\n",
       "      <td>110.446320</td>\n",
       "      <td>73.512154</td>\n",
       "      <td>0.155584</td>\n",
       "      <td>16226.857422</td>\n",
       "      <td>102.906479</td>\n",
       "      <td>7.208336</td>\n",
       "      <td>3.524768</td>\n",
       "      <td>1.271504</td>\n",
       "      <td>4.246171</td>\n",
       "      <td>193.520599</td>\n",
       "      <td>11.2</td>\n",
       "      <td>12.717451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>116.478134</td>\n",
       "      <td>80.697281</td>\n",
       "      <td>104.621857</td>\n",
       "      <td>44.265514</td>\n",
       "      <td>0.191408</td>\n",
       "      <td>15253.376953</td>\n",
       "      <td>94.358368</td>\n",
       "      <td>7.550208</td>\n",
       "      <td>4.545760</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>4.736102</td>\n",
       "      <td>195.246109</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.005073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>160.450226</td>\n",
       "      <td>99.285355</td>\n",
       "      <td>141.965363</td>\n",
       "      <td>61.919617</td>\n",
       "      <td>0.074880</td>\n",
       "      <td>15260.442383</td>\n",
       "      <td>122.457008</td>\n",
       "      <td>8.823792</td>\n",
       "      <td>5.045024</td>\n",
       "      <td>1.284459</td>\n",
       "      <td>5.296274</td>\n",
       "      <td>208.044388</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.448585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>153.143478</td>\n",
       "      <td>88.999878</td>\n",
       "      <td>125.723816</td>\n",
       "      <td>65.196289</td>\n",
       "      <td>0.154960</td>\n",
       "      <td>15623.010742</td>\n",
       "      <td>112.367874</td>\n",
       "      <td>8.567216</td>\n",
       "      <td>4.814560</td>\n",
       "      <td>1.322004</td>\n",
       "      <td>5.181715</td>\n",
       "      <td>197.955475</td>\n",
       "      <td>11.9</td>\n",
       "      <td>13.712287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>166.610931</td>\n",
       "      <td>95.269539</td>\n",
       "      <td>136.429520</td>\n",
       "      <td>71.720146</td>\n",
       "      <td>0.143056</td>\n",
       "      <td>14886.086914</td>\n",
       "      <td>121.307571</td>\n",
       "      <td>8.059120</td>\n",
       "      <td>4.136768</td>\n",
       "      <td>1.350224</td>\n",
       "      <td>4.785073</td>\n",
       "      <td>200.220642</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.156513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>151.634308</td>\n",
       "      <td>104.242531</td>\n",
       "      <td>136.884018</td>\n",
       "      <td>48.814838</td>\n",
       "      <td>0.098656</td>\n",
       "      <td>15075.935547</td>\n",
       "      <td>122.139740</td>\n",
       "      <td>7.817600</td>\n",
       "      <td>3.858368</td>\n",
       "      <td>1.340805</td>\n",
       "      <td>4.678740</td>\n",
       "      <td>207.462921</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.747807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>159.340103</td>\n",
       "      <td>81.754608</td>\n",
       "      <td>118.568344</td>\n",
       "      <td>78.393295</td>\n",
       "      <td>0.128752</td>\n",
       "      <td>12140.647461</td>\n",
       "      <td>109.166695</td>\n",
       "      <td>7.453632</td>\n",
       "      <td>3.590352</td>\n",
       "      <td>1.319963</td>\n",
       "      <td>4.443782</td>\n",
       "      <td>217.051361</td>\n",
       "      <td>10.1</td>\n",
       "      <td>11.134631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>161.147034</td>\n",
       "      <td>84.156761</td>\n",
       "      <td>120.976151</td>\n",
       "      <td>77.844841</td>\n",
       "      <td>0.174960</td>\n",
       "      <td>14728.014648</td>\n",
       "      <td>111.384903</td>\n",
       "      <td>7.602720</td>\n",
       "      <td>3.883520</td>\n",
       "      <td>1.299104</td>\n",
       "      <td>4.495942</td>\n",
       "      <td>206.186661</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.124163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_r      mean_g      mean_b    mean_rg       HHR           Ent  \\\n",
       "71  175.925720  126.581451  154.250595  50.055267  0.190272  16804.599609   \n",
       "62  138.608643   77.041153  115.367226  62.658043  0.109568  13782.414062   \n",
       "29  158.704285   86.480194  126.543617  72.431419  0.270784  11816.129883   \n",
       "53  167.599197   95.245903  128.758453  72.956291  0.247920  16235.455078   \n",
       "90  168.967224   92.357147  130.296432  77.023102  0.238656  16160.344727   \n",
       "4   174.038376  113.084953  149.969147  61.577065  0.077600  16105.892578   \n",
       "31  169.107239   98.704597  135.013550  70.810814  0.147504  15583.392578   \n",
       "77  162.976715   75.856606  105.529968  88.623070  0.320928  14526.099609   \n",
       "79  153.740143   86.112801  121.020012  68.748116  0.137424  15083.416992   \n",
       "70  177.905777  123.975029  161.672729  54.421707  0.077872  16069.750000   \n",
       "33  172.783295  133.084534  168.796432  44.377064  0.074336  16194.949219   \n",
       "51  162.069107  102.783356  141.932098  59.853676  0.115920  16559.763672   \n",
       "8   187.326706  109.675491  142.919464  78.905037  0.289536  16501.617188   \n",
       "63  161.042984   89.584312  124.399689  71.872284  0.227360  16407.742188   \n",
       "85  143.585129   82.280014  119.277916  61.903305  0.101168  16174.514648   \n",
       "35  182.003494  121.810455  156.413620  60.917912  0.307792  16170.614258   \n",
       "28  172.090820  109.961693  145.433868  62.959633  0.104544  14135.641602   \n",
       "75  167.591919  119.042137  155.516602  49.284084  0.105408  15990.248047   \n",
       "50  171.420700  113.947998  149.083221  58.141979  0.128752  11654.578125   \n",
       "41  138.032043   64.668198   93.880859  74.397598  0.204880  15207.328125   \n",
       "65  148.967651   84.223297  124.716103  65.377151  0.128624  16221.200195   \n",
       "23  150.304230   77.287430  110.446320  73.512154  0.155584  16226.857422   \n",
       "64  116.478134   80.697281  104.621857  44.265514  0.191408  15253.376953   \n",
       "56  160.450226   99.285355  141.965363  61.919617  0.074880  15260.442383   \n",
       "89  153.143478   88.999878  125.723816  65.196289  0.154960  15623.010742   \n",
       "24  166.610931   95.269539  136.429520  71.720146  0.143056  14886.086914   \n",
       "82  151.634308  104.242531  136.884018  48.814838  0.098656  15075.935547   \n",
       "9   159.340103   81.754608  118.568344  78.393295  0.128752  12140.647461   \n",
       "21  161.147034   84.156761  120.976151  77.844841  0.174960  14728.014648   \n",
       "\n",
       "             B        G1        G2        G3        G4          G5  label  \\\n",
       "71  144.484924  7.679888  3.663984  1.346695  4.461142  200.818848    9.1   \n",
       "62   99.836166  8.414496  4.539408  1.326535  5.021771  203.675323   13.8   \n",
       "29  112.631630  7.364720  4.027808  1.136500  4.335993  153.293381    9.7   \n",
       "53  120.707909  7.797136  3.970320  1.341445  4.696663  195.005295   12.5   \n",
       "90  119.596275  7.965248  3.984880  1.349547  4.707871  188.017883   13.4   \n",
       "4   135.513290  7.608624  3.746800  1.337888  4.442797  189.553619   10.6   \n",
       "31  123.901398  7.465680  3.809648  1.253673  4.413886  204.016464   11.1   \n",
       "77  104.785522  8.321152  5.164864  1.130252  4.980634  160.791092   13.0   \n",
       "79  110.341164  8.306480  4.422640  1.350149  5.048759  201.483841   11.0   \n",
       "70  144.409607  7.497120  3.580656  1.342270  4.405998  202.220474   12.3   \n",
       "33  149.047729  7.697904  3.872560  1.297648  4.496145  209.191177    8.3   \n",
       "51  124.974556  7.771200  3.955488  1.301328  4.591011  194.547684    8.8   \n",
       "8   136.656052  7.739552  4.132352  1.260791  4.554437  197.023972   11.5   \n",
       "63  114.892723  8.123680  4.176384  1.342741  4.862789  182.684479   14.0   \n",
       "85  104.803139  8.539952  4.847280  1.282311  5.118147  193.650314   13.7   \n",
       "35  143.766724  7.503168  3.816624  1.260384  4.436771  194.234543   11.7   \n",
       "28  132.613571  7.387440  3.400896  1.350907  4.311368  216.402985    8.7   \n",
       "75  137.734756  7.814672  4.012352  1.295106  4.593637  208.555420   10.3   \n",
       "50  135.123337  9.450240  5.762848  1.240956  5.797179  170.292252   10.5   \n",
       "41   89.965492  7.456784  3.715696  1.281333  4.417950  196.360336   14.3   \n",
       "65  108.203285  9.011344  5.197136  1.285285  5.424688  186.141510   17.1   \n",
       "23  102.906479  7.208336  3.524768  1.271504  4.246171  193.520599   11.2   \n",
       "64   94.358368  7.550208  4.545760  1.038370  4.736102  195.246109   12.0   \n",
       "56  122.457008  8.823792  5.045024  1.284459  5.296274  208.044388   12.2   \n",
       "89  112.367874  8.567216  4.814560  1.322004  5.181715  197.955475   11.9   \n",
       "24  121.307571  8.059120  4.136768  1.350224  4.785073  200.220642   12.6   \n",
       "82  122.139740  7.817600  3.858368  1.340805  4.678740  207.462921    9.5   \n",
       "9   109.166695  7.453632  3.590352  1.319963  4.443782  217.051361   10.1   \n",
       "21  111.384903  7.602720  3.883520  1.299104  4.495942  206.186661   12.4   \n",
       "\n",
       "    prediction_label  \n",
       "71         10.006741  \n",
       "62         11.671827  \n",
       "29         10.893827  \n",
       "53         12.539658  \n",
       "90         12.487544  \n",
       "4          10.800099  \n",
       "31         11.250892  \n",
       "77         13.522781  \n",
       "79         11.687661  \n",
       "70          9.783463  \n",
       "33         10.876443  \n",
       "51          9.875788  \n",
       "8          12.359994  \n",
       "63         12.193541  \n",
       "85         13.039119  \n",
       "35         10.700960  \n",
       "28         11.453603  \n",
       "75         10.768969  \n",
       "50         10.793377  \n",
       "41         13.245913  \n",
       "65         13.194889  \n",
       "23         12.717451  \n",
       "64         10.005073  \n",
       "56         13.448585  \n",
       "89         13.712287  \n",
       "24         12.156513  \n",
       "82          9.747807  \n",
       "9          11.134631  \n",
       "21         13.124163  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(tuned_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression to Classification\n",
    "\n",
    "--> <11.0 --> Anemic\n",
    "\n",
    "--> >=11.0 ---> Non-Anemic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_dc902\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dc902_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_dc902_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_dc902_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_dc902_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_dc902_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_dc902_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_dc902_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dc902_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dc902_row0_col0\" class=\"data row0 col0\" >CatBoost Regressor</td>\n",
       "      <td id=\"T_dc902_row0_col1\" class=\"data row0 col1\" >1.1978</td>\n",
       "      <td id=\"T_dc902_row0_col2\" class=\"data row0 col2\" >2.2488</td>\n",
       "      <td id=\"T_dc902_row0_col3\" class=\"data row0 col3\" >1.4996</td>\n",
       "      <td id=\"T_dc902_row0_col4\" class=\"data row0 col4\" >0.4051</td>\n",
       "      <td id=\"T_dc902_row0_col5\" class=\"data row0 col5\" >0.1181</td>\n",
       "      <td id=\"T_dc902_row0_col6\" class=\"data row0 col6\" >0.1044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f913e160310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_predict = predict_model(tuned_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean_r', 'mean_g', 'mean_b', 'mean_rg', 'HHR', 'Ent', 'B', 'G1',\n",
       "       'G2', 'G3', 'G4', 'G5', 'label', 'prediction_label'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_predict.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_tuned = (tuned_predict['label']<11.0).tolist()\n",
    "predicted_tuned = (tuned_predict['prediction_label']<11.0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8275862068965517\n",
      "Precision = 0.7272727272727273\n",
      "Sensitivity = 0.8\n",
      "Specificity = 0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "TP=TN=FN=FP = 0\n",
    "for i in range(len(actual_tuned)):\n",
    "    if(actual_tuned[i]==True and predicted_tuned[i]==True):\n",
    "        TP +=1\n",
    "    if(actual_tuned[i]==False and predicted_tuned[i]==False):\n",
    "        TN +=1\n",
    "    if(actual_tuned[i]==True and predicted_tuned[i]==False):\n",
    "        FN +=1\n",
    "    if(actual_tuned[i]==False and predicted_tuned[i]==True):\n",
    "        FP +=1\n",
    "\n",
    "print(f\"Accuracy = {(TP+TN)/(TP+TN+FP+FN)}\")\n",
    "print(f\"Precision = {(TP)/(TP+FP)}\")\n",
    "print(f\"Sensitivity = {(TP)/(TP+FN)}\")\n",
    "print(f\"Specificity = {(TN)/(TN+FP)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
